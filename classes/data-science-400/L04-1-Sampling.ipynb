{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"instructions\" style=\"border-radius: 5px; background-color:#f5f5f5;\" >\n",
    "<h1>Instructions</h1>\n",
    "<p>Look for the <b>3 Your Turn</b> sections to complete the code and/or answer questions.<p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4 - Sampling and Law of Large Numbers\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Sampling is a fundamental process in the collection of data. Sampling is important because we can almost never look at the whole population. Some key points to keep in mind about sampling are:\n",
    "- An understanding of sampling is essential to ensure that analyses performed are representative of the entire population. \n",
    "- You will use inferences on the sample to say something about the population.\n",
    "- You will need estimates of variances on the sample calculations to say something about the population.\n",
    "\n",
    "Let's look at some examples of sampling.\n",
    "\n",
    "| Use Case | Sample | Population |\n",
    "|---|---|---|\n",
    "| A/B Testing | The users we show either web sites A or B | All possible users, past present and future|\n",
    "|World Cup Soccer | 32 teams which qualify in one season | All national teams in past, present and future years|\n",
    "|Average height of data science students | Students in UW Data Science Program | All students taking data science classes world wide|\n",
    "\n",
    "Notice, that in several cases it is not only impractical, but impossible to collect data from the entire population. Hence, we must work with correctly collected samples. \n",
    "\n",
    "## Sampling Strategies\n",
    "\n",
    "At the conclusion of this lesson, you should be able to apply a number of commonly used sampling strategies: \n",
    "\n",
    "- Bernoulli Sampling\n",
    "- Stratified Sampling\n",
    "- Cluster Sampling\n",
    "- Systematic Sampling\n",
    "\n",
    "\n",
    "### Bernoulli Sampling\n",
    "\n",
    "Bernoulli sampling has the following properties:\n",
    "\n",
    "- All population members have equal an chance of being part of the sample. \n",
    "- The sample sizes in Bernoulli sampling are not fixed, because each sample is considered separately. \n",
    "An example would be to randomly products in a factory to ensure quality.\n",
    "Let's look at an example. The code in the cell below creates a data frame with 200 random samples of a normal distribution, divided into 4 groups. Run this code and examine the summary of the sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as nr\n",
    "import pandas as pd\n",
    "nr.seed(345)\n",
    "data = pd.DataFrame({\"var\":nr.normal(size = 200), \n",
    "                     \"group\":nr.choice(range(4), size= 200, p = [0.1,0.3,0.4,0.2])})\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def count_mean(dat):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    groups = dat.groupby('group') # Create the groups\n",
    "    ## Create a data frame with the counts and the means of the groups\n",
    "    return pd.DataFrame({'count': groups.size(), \n",
    "                        'mean': groups.aggregate(np.mean).loc[:, 'var']})\n",
    "count_mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Bernoulli sample these data by running the code in the cell below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = 0.1\n",
    "bernoulli = data.iloc[nr.choice(range(200), size = int(p * 200)), :]\n",
    "count_mean(bernoulli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the total number of samples is approximately 10%. Further, you can see that some of the mean estimates are further from zero.   \n",
    "\n",
    "## Your Turn 1\n",
    "You can also use the numpy.random `choice` method to Bernoulli sample a data frame. Create the code to Bernoulli **sample 20 cases** from the population and print the summary statistics of number and mean by group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results. Do the numbers of samples appear representative of the population? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in both cases you have tried, in both samples the number of cases for some groups can be rather small. Compare the means by groups of the two samples and the population, and notice how much variation there is. Clearly, Bernoulli sampling is far from ideal if the data have a group structure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Sampling\n",
    "\n",
    "Stratified sampling strategies are used when data are organized in groups or **Strata**. The idea is simple: sample each group in such a way that the sample includes a representative number of cases from each group. The simplest version of stratified sampling creates a sample with the same number of cases from each group.\n",
    "\n",
    "Some examples of stratified sampling include:\n",
    "\n",
    "- Sample equal numbers of men and women.\n",
    "- Sample equal numbers of people in different income categories.\n",
    "- Sample equal numbers of people from towns of different sizes.\n",
    "\n",
    "Execute the code in the cell below to sample our population uniformly, and verify the result. The comments can help you understand the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = 0.05\n",
    "def stratify(dat, p):\n",
    "    groups = dat.groupby('group') # Create the groups\n",
    "    nums = min(groups.size()) # Find the size of the smallest group\n",
    "    num = int(p * dat.shape[0]) # Compute the desired number of samples per group\n",
    "    if num <= nums: # If sufficient group size, sample each group and return. \n",
    "        return groups.apply(lambda x: x.sample(n=num))\n",
    "    else: # Oops. p is to large\n",
    "        pmax = nums / dat.shape[0]\n",
    "        print('The maximum value of p = ' + str(pmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified = stratify(data, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified.reset_index(inplace=True, drop=True)\n",
    "count_mean(stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 5 samples from each strata. Notice that the mean estimates of each group are closer those for the population. Stratified sampling ensures the samples for each group are more representative of the groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Sampling\n",
    "\n",
    "When sampling is expensive, a strategy is required to reduce the cost, yet still keep randomized sampling. Some examples of data that is expensive to collect includes:\n",
    "\n",
    "- Surveys of customers at a chain of stores\n",
    "- Door-to-door survey of homeowners\n",
    "\n",
    "In these cases, the population can be divided into clusters and a random selection of clusters sampled. The process of cluster sampling follows these steps:\n",
    "\n",
    "- Define the clusters and divide the data.\n",
    "- Randomly select some clusters.\n",
    "- Sample from the selected clusters.\n",
    "- Optionally, stratify the sample from the clusters.\n",
    "\n",
    "As an example, you can select a few store locations and Bernoulli sample customers at these locations.\n",
    "\n",
    "The code in the cell bellow divides a population into clusters, randomly selects 3 clusters, and computes and prints some summary statistics. Run this code and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## First compute the clusters\n",
    "num_clusters = 10\n",
    "num_vals = 200\n",
    "## Create a data frame with randomly sampled cluster numbers\n",
    "clusters = pd.DataFrame({'group': range(num_clusters)}).sample(n = num_vals, replace = True)\n",
    "## Add a column to the data frame with Normally distributed values\n",
    "clusters.loc[:, 'var'] = nr.normal(size = num_vals)\n",
    "clusters.head(10) # Print the head to get a feel for these data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we have a basis of comparison, we will compute the count and mean of each group in our population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_mean(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results. Notice that the number of samples in each group, and that the means are close to, but never exactly, zero. \n",
    "\n",
    "Next we randomly sample 3 of the clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Randomly sample the group numbers, making sure we sample from \n",
    "## unique values of the group numbers. \n",
    "clusters_samples = nr.choice(clusters.loc[:, 'group'].unique(), \n",
    "                             size = 3, replace = False)\n",
    "## Now sample all rows with the selected cluster numbers\n",
    "clus_samples = clusters.loc[clusters.loc[:, 'group'].isin(clusters_samples), :]\n",
    "print('cluster sampled are: ')\n",
    "[print(x) for x in clusters_samples] \n",
    "clus_samples.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the  3 clusters of 20 cases each which have been selected.\n",
    "\n",
    "Recalling that the population contains groups the sample from the clusters can be summarized by group by running the code in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mean(clus_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn 2\n",
    "In many cases, cluster sampling is often combined with random sampling to reduce the size of the sub-samples. Reducing the sample sizes can be important if the clusters are large or if the collection of data is expensive. \n",
    "\n",
    "Create a stratified sample of the three clusters with `p = 0.1` can then compute and display the count of the samples and the mean using the `count_mean` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stratified = stratify(                 )  #fill in the parameters\n",
    "count_mean(cluster_stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the results. Are these samples reasonably representative of the full cluster samples and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematic Sampling\n",
    "\n",
    "**WARNING: systematic sampling is a form of convenience sampling. Convenience sampling almost always leads to problems!**\n",
    "\n",
    "In systematic sampling every kth case of the population is selected. As you can imagine, this approach is not a random sampling method, but rather a case of convenience sampling. \n",
    "\n",
    "The code in the cell bellow systematically samples the population by simply taking every 5th value as a sample. Run this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Systematic sampling every kth item.\n",
    "k = 5\n",
    "sys_sample = data.iloc[range(0, data.shape[0], k), :]\n",
    "sys_sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the number of samples and the means of each group based on these samples. Execute the code in the cell below and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mean(sys_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the differing sizes of the sample in each group and the bias in the mean estimates. This illustrates the hazards of convenience sampling. \n",
    "\n",
    "### A few more thoughts on sampling:\n",
    "\n",
    "- Whenever you are planing to sample data, make sure you have a clear sampling plan. \n",
    "- Know number of clusters, strata, samples in advance.\n",
    "- Don’t stop sampling when desired result is achieved: e.g., error measure! \n",
    "- Note that random sampling, if done properly, controls for database effects, like indexing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and the Law of Large Numbers\n",
    "\n",
    "The **law of large numbers** is a theorem that states that statistics of independent samples converge to the population values as additional unbiased experiments are performed. We can write this mathematically for the **expected value** of the mean as:\n",
    "\n",
    "$$Let\\ \\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i\\\\\n",
    "then\\ by\\ the\\ law\\ of\\ Large\\ Numbers\\\\\n",
    "\\bar{X} \\rightarrow E(X) = \\mu\\\\\n",
    "as\\\\\n",
    "n \\rightarrow \\infty$$\n",
    "\n",
    "The law of large numbers is foundational to statistics. We rely on the law of large numbers whenever we work with samples of data. We can rest assured that larger samples will be more representatives of the population we are sampling. This theorem is the foundation of not only sampling theory, but modern computation methods including, simulation, bootstrap resampling, and Monte Carlo methods. If the real world did not follow this theorem much of statistics, to say nothing of science and technology, would fail badly. \n",
    "\n",
    "Given this great importance, it should not be surprising that the law of large numbers has a long history. Jacob Bernoulli posthumously published the first proof for the Binomial distribution in 1713. In fact the law of large numbers is sometimes referred to as **Bernoulli's theorem**. A more general proof was published by Poisson in 1837.\n",
    "\n",
    "Let's think about a simple example. The mean of 50 coin flips (0,1)=(T,H) is usually farther away from the true mean of 0.5 than the mean of 5,000 coin flips. The code in the cell below computes and then samples a population of 1,000,000 Bernoulli trials with $p=0.5$. Run this code and  examine the results. Does the expected value, or mean converge to 0.5 as `n` increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(3457)\n",
    "n = 1\n",
    "p = 0.5\n",
    "size = 1000000\n",
    "# Create a large binomial distributed population. \n",
    "pop = pd.DataFrame({'var':nr.binomial(n, p, size)}) \n",
    "# Sample the population for different sizes and compute the mean\n",
    "out = [pop.sample(n = x).mean(axis = 0) for x in [5, 50, 500, 5000]] \n",
    "for x in out: print(\"%.2f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence of Bernoulli Trials \n",
    "\n",
    "Next, let's use the series of Bernoulli trials to examine the convergence of the estimated probability, $p$, for a number of flips of a fair coin. This series should converge to $p = 0.5$ as the number of samples increases. The code in the cell below computes the running mean of the realization of Bernoulli trials as the sample size increases. Run this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot a running average of N-trials of flipping a fair coin\n",
    "import numpy as np\n",
    "num_samps = 5000\n",
    "running_average = pd.DataFrame({'num_samples': range(1, num_samps), \n",
    "                                'mean':np.concatenate([np.mean(pop.sample(n = x)) for x in range(1, num_samps)]).ravel().tolist()}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the code in the cell below to plot $p$ for the different sample sizes. Do the results appear to be converging to $p$ as $n \\rightarrow \\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_samples(df, num_plot):\n",
    "    import matplotlib.pyplot as plt\n",
    "    running_average.iloc[:num_plot, :].plot(x = 'num_samples', y = 'mean')\n",
    "    plt.ylabel('Mean estimate')\n",
    "    plt.xlabel('Number of samples')\n",
    "    plt.title('Mean estimate vs. number of samples')\n",
    "plot_samples(running_average, 500)\n",
    "plot_samples(running_average, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergance for a Normal Distribution\n",
    "\n",
    "As we sample from a normal distribution, the mean of the sample will converge to the population mean and the sample standard deviation will converge to the population standard deviation. The standard error of the sample mean should converge as:\n",
    "\n",
    "$$se = \\frac{sd}{\\sqrt(n)}$$\n",
    "\n",
    "The code in the cell below computes the mean and standard error of the mean estimate for 10 to 10,000 samples of a normal distribution. Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot means and SE for 10000 Normal distributions\n",
    "import math\n",
    "start = 10\n",
    "end = 10000\n",
    "step = 10\n",
    "norms = pd.DataFrame({'num_samples':range(start, end, step),\n",
    "                      'mean': [np.mean(nr.normal(size = x)) for x in range(start, end, step)],\n",
    "                       'se_up':[1/math.sqrt(n) for n in range(start, end, step)],\n",
    "                       'se_dn':[-1/math.sqrt(n) for n in range(start, end, step)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code in the cell below to plot the convergence of the sample mean as the number of samples increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_se(df):\n",
    "    import matplotlib.pyplot as plt\n",
    "    ax = plt.figure(figsize=(6, 6)).gca() # define axis\n",
    "    df.plot.scatter(x = 'num_samples', y = 'mean', alpha = 0.2, style=\"o\", ax = ax)\n",
    "    df.plot(x = 'num_samples', y = 'se_up', c = 'red', ax = ax) \n",
    "    df.plot(x = 'num_samples', y = 'se_dn', c = 'red', ax = ax) \n",
    "    ax.set_ylabel('Mean estimate')\n",
    "    ax.set_xlabel('Number of samples')\n",
    "    ax.set_title('Mean estimate vs. number of samples')\n",
    "plot_se(norms)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn 3\n",
    "In the cell below, create and execute code to plot the convergence of the sample standard deviation. Try to include lines showing the expected bounds on the standard error. **Hint:** you will need to add `1.0` to the standard error of the sample standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds = pd.DataFrame(                     )#fill in the parameters\n",
    "\n",
    "def plot_sd(df):\n",
    "    import matplotlib.pyplot as plt\n",
    "    ax = plt.figure(figsize=(6, 6)).gca() # define axis\n",
    "    print(df.columns)\n",
    "    df.plot.scatter(x = 'num_samples', y = 'sd', alpha = 0.2, style=\"o\", ax = ax)\n",
    "    df.plot(x = 'num_samples', y = 'se_up', c = 'red', ax = ax) \n",
    "    df.plot(x = 'num_samples', y = 'se_dn', c = 'red', ax = ax) \n",
    "    ax.set_ylabel('Standard deviation estimate')\n",
    "    ax.set_xlabel('Number of samples')\n",
    "    ax.set_title('Standard deviation estimate vs. number of samples')\n",
    "plot_sd(sds)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Examine this result. Does the estimate of the standard deviation appear to converge as expected as the number of samples increase? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In the lesson you have explored the concepts of sampling and how sampling relates to the law of large numbers. Nearly all the data we work with as data scientists is sampled from larger populations. It is therefore important to have an understanding of sampling methods and the convergence of statistical estimates. \n",
    "\n",
    "Specifically in this lesson you have done the following:\n",
    "- Used Bernoulli sampling to generate randomized samples of a population.\n",
    "- Applied stratified sampling to populations with unequal numbers of members. \n",
    "- Used cluster sampling to reduce the number of samples required for cases where data collection is expensive.\n",
    "- Investigated the convergence of sample estimated statistics as the sample size grows. This convergence is referred to as *The Law of Large Numbers*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div id=\"reminder\" style=\"border-radius: 5px; background-color:#f5f5f5;\" >\n",
    "<h3>Reminder</h3>\n",
    "<p>Use this notebook to answer the quiz questions related to the <b>Your Turn</b> sections.<p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
