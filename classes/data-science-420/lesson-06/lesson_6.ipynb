{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we learn about ensemble modeling, which is a technique for training multiple ML algorithms (referred to as `base learners`) and combining their learning into one. Two very common ways of doing this are **bagging** and **boosting**.\n",
    "\n",
    "## Reading and processing data\n",
    "\n",
    "Let begin by reading our data. In this case, our data is already split into training and testing. How convenient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"data/adult_train.csv\", sep = \",\", header = 0)\n",
    "df_test = pd.read_csv(\"data/adult_test.csv\", sep = \",\", skiprows = 2, names = df_train.columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our column types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "fnlwgt             int64\n",
       "education         object\n",
       "education-num      int64\n",
       "marital-status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital-gain       int64\n",
       "capital-loss       int64\n",
       "hours-per-week     int64\n",
       "native-country    object\n",
       "income            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a list of our categorical columns. Here keep every column whose data types is `object`, but we may need to narrow the list down even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native-country']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars = df_train.select_dtypes('object').columns.to_list()\n",
    "cat_vars.pop() # removes `income` from cat_vars\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these columns look like they would be good candidates type `category`, but we covered that in a previous notebook and no need to return to that. We will take them as-is.\n",
    "\n",
    "Let's drop any rows with missing data from the training and test sets. This is a very conservative approach and if we don't have a lot of data to begin with we may want to try a different approach such as imputing the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(axis = 0)\n",
    "df_test = df_test.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data into features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns = 'income')\n",
    "Y_train = df_train['income']\n",
    "\n",
    "X_test = df_test.drop(columns = 'income')\n",
    "Y_test = df_test['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of data pre-processing, we need to one-hot-encode the categorical features. We already learned how to use `OneHotEncoder` in `sklearn.preprocessing`, but we will use another `OneHotEncoder` this time in the `category_encoders` library. It's important to know that `sklearn` is not the only library for ML in Python, so this will give us a change to try a new one. You should not be surprised to find out that the two have a lot in common, but also some slight additions that make things easier for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying it to the data, let's create a very small train and test data with two rows and two columns and intentiall modify them slightly, just to learn how `OneHotEncoder` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     race    sex\n",
       "2   White   Male\n",
       "3   Black    NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_small_train = X_train.loc[2:3, [\"race\", \"sex\"]]\n",
    "X_small_train.iloc[1, 1] = np.nan # introduce a nan to see what happens\n",
    "X_small_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     race      sex\n",
       "4   Black   Female\n",
       "5   White   Female"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small_test = X_train.loc[4:5, [\"race\", \"sex\"]]\n",
    "X_small_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `OneHotEncoder` class has two very important arguments called `handle_missing` and `handle_unknown` ethier of which can be set to `\"error\"`, `\"return_nan\"`, `\"value\"` or `\"indicator\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.2.2-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 1.9 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.21.1 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.11.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.22.2.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2019.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.1->category_encoders) (1.14.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "handle = 'return_nan' # options are: 'error', 'return_nan', 'value', and 'indicator'\n",
    "onehoter =  ce.OneHotEncoder(return_df = True, \n",
    "                             cols = [\"race\", \"sex\"], \n",
    "                             drop_invariant = True,\n",
    "                             use_cat_names = True, \n",
    "                             handle_missing = handle, \n",
    "                             handle_unknown = handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's examing the following settings and describe what happens when you run `onehoter.fit` on `X_small_train` and then run `onehoter.transform` on `X_small_train` and `X_small_test`.\n",
    "\n",
    "- Set `handle = \"indicator\"` and `drop_invariant = False`.\n",
    "- Set `handle = \"error\"`.\n",
    "- Set `handle = \"value\"` and `drop_invariant = True`.\n",
    "- Set `handle = \"value\"` and `drop_invariant = False`.\n",
    "- Set `handle = \"return_nan\"` and `drop_invariant = True`.\n",
    "- Set `handle = \"return_nan\"` and `drop_invariant = False`.\n",
    "\n",
    "Which settings do you think are better in production? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     race    sex\n",
       "2   White   Male\n",
       "3   Black    NaN"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_ White</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>sex_ Male</th>\n",
       "      <th>sex_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   race_ White  race_ Black  sex_ Male  sex_nan\n",
       "2          1.0          0.0        1.0      0.0\n",
       "3          0.0          1.0        NaN      NaN"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehoter.fit_transform(X_small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     race      sex\n",
       "4   Black   Female\n",
       "5   White   Female"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>race_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   race_ Black  race_ White  race_nan\n",
       "4          1.0          0.0       0.0\n",
       "5          0.0          1.0       0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehoter.fit_transform(X_small_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run `OneHotEncoder` on the data. We create an instance of the class, which we call `onehoter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "handle = \"value\" # options are: 'error', 'return_nan', 'value', and 'indicator'\n",
    "onehoter =  ce.OneHotEncoder(return_df = True, \n",
    "                             cols = cat_vars, \n",
    "                             drop_invariant = False,\n",
    "                             use_cat_names = True, \n",
    "                             handle_missing = handle, \n",
    "                             handle_unknown = handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we appy `onehoter` it to the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehoter.fit(X_train)\n",
    "X_train_encoded = onehoter.transform(X_train)\n",
    "X_test_encoded = onehoter.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (32561, 14)\n",
      "X_train_encoded shape = (32561, 108)\n",
      "X_test shape = (16281, 14)\n",
      "X_test_encoded shape = (16281, 108)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape = {}\".format(X_train.shape))\n",
    "print(\"X_train_encoded shape = {}\".format(X_train_encoded.shape))\n",
    "\n",
    "print(\"X_test shape = {}\".format(X_test.shape))\n",
    "print(\"X_test_encoded shape = {}\".format(X_test_encoded.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be a good idea to ensure that the training and test sets have the same number of columns before proceeding to the next step. This is one way to ensure that we have consistency between the two. We can use `assert` to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(X_train_encoded.shape[1] == X_test_encoded.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to train models on the one-hot-encoded data. Let's start with a random forest model. Notice that the `RandomForestClassifier` class below has several hyper-parameters such as `n_estimators`, `max_features`, `max_depth` and `min_leaf_size`. The latter two were inherited from the decision tree. For reasons that will become apparent later, we store these hyper-parameters in a dictionary called `hypers` and then pass them to the classifier. When we have a dictionary whose keys match a fuction's argument names, there is a neat functionality in Python that allows us to pass the dictionary to the function using `**` followed by the name of the dictionary. This saves us from having to type the argument names twice: once in the dictionary and once when calling the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "hypers = {\"n_estimators\": 100, \"max_features\": \"sqrt\", \"max_depth\": 20, \"min_samples_leaf\": 10}\n",
    "clf_rf = RandomForestClassifier(random_state = 0, verbose = True, **hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0,\n",
       "                       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.fit(X_train_encoded, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see a message about using a sequential backend, it's because a random forest is an algorithm that can easily run in parallel by just training many trees concurrently. Since we don't have a large data set we don't need to bother with that here, but it's useful to know about this in case we need to speed up the training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One by product of tree-based models is that they provide us with a list showing the relative importance of each feature to the model. So even if we're not interested in the trained model the random forest returns, we can still use it for **feature selection**: namely train the random forest on the whole data to get the top $n$ most important features and later pass only those features to another algorithm we wish to use to train a model. Note that because we one-hot-encoded the data, a feature here is not just one of the categorical columns, but each category of each categorical column is its own feature. We can find the feature importance values in `clf_rf.feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf_rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the feature importance values in a `DataFrame` and use `seaborn` to visualize the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_var_imp = pd.DataFrame({\"feature\": X_train_encoded.columns, \n",
    "                           \"importance\": clf_rf.feature_importances_})\n",
    "df_var_imp.sort_values(by = \"importance\", ascending = False, inplace = True)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.barplot(x = \"importance\", y = \"feature\", data = df_var_imp.head(10), color = \"lightblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get predictions from the trained model, we simply call the `predict` method and pass it the data. To check if we're overfitting or not, we can get predictions for both the training and the test data. Once we have the predictions, we can call the `accuracy_score` function to get the accuracy on the training and test data, assuming that accuracy is a good metric to use here.\n",
    "\n",
    "We're already written the code there for you. But there's a problem with it. Your job is to run it and see if you can debug it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "Y_hat_train = clf_rf.predict(X_train_encoded)\n",
    "Y_hat_test = clf_rf.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     <=50K\n",
       "1     <=50K\n",
       "2     <=50K\n",
       "3     <=50K\n",
       "4     <=50K\n",
       "Name: income, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     <=50K.\n",
       "1     <=50K.\n",
       "2      >50K.\n",
       "3      >50K.\n",
       "4     <=50K.\n",
       "Name: income, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight discrepancy between the labels as they show up in the training data and the test data: the labels in the test data end with a period. So we need to remove the period when we evaluate the model. We do so using `.str.replace(\"\\\\.$\", \"\")` in the cell below, where `\"\\\\.$\"` is a regular expression that searches for a period at the end of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "acc_test = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be storing some important results in a table we call `results`. If this table doesn't exist (first time we run it) it will initialized by the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    results # checks if this object exists or not\n",
    "except NameError:\n",
    "    results = pd.DataFrame(columns = [\"algo\", \"acc_train\", \"acc_test\"]) # initiates it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every row of the table will store accuracy metrics for one training iteration given one set of hyper-parameters (also listed in the table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = str(clf_rf.__class__).split('.')[-1].strip(\"\\\"\\'>\")\n",
    "results.loc[len(results), 0:3] = [model_name, acc_train, acc_test]\n",
    "\n",
    "for hp in hypers.keys():\n",
    "    results.loc[len(results) - 1, hp] = hypers[hp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.865852</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     algo acc_train  acc_test  n_estimators max_features  \\\n",
       "0  RandomForestClassifier  0.865852  0.861126         100.0         sqrt   \n",
       "\n",
       "   max_depth  min_samples_leaf  \n",
       "0       20.0              10.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go back up to where we trained the random forest classifier and change its hyper-parameters, retrain it, re-evaluate it, and finally store the results as a new row in the `results` table. This way we can compare our different runs. But to avoid navigating up and down the notebook, we're going to make things even easier: Let's take the code that needs to rerun every time we change the hyper-parameters and dump it in a python file called `train_evaluate.py`. We can use the `%%writefile` magic to do this from a cell, as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_evaluate.py\n",
    "model.fit(X_train_encoded, Y_train)\n",
    "\n",
    "Y_hat_train = model.predict(X_train_encoded)\n",
    "Y_hat_test = model.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "acc_test = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test)\n",
    "\n",
    "try:\n",
    "    results # checks if this object exists or not\n",
    "except NameError:\n",
    "    results = pd.DataFrame(columns = [\"algo\", \"acc_train\", \"acc_test\"]) # initiates it\n",
    "\n",
    "model_name = str(model.__class__).split('.')[-1].strip(\"\\\"\\'>\")\n",
    "results.loc[len(results), 0:3] = [model_name, acc_train, acc_test]\n",
    "\n",
    "for hp in hypers.keys():\n",
    "    results.loc[len(results) - 1, hp] = hypers[hp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here's all we have to do: In the next cell we're going to change the hyper-parameters to whatever we want to try next. We can even add new hyper-parameters to `hypers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\"n_estimators\": 200, \"max_features\": \"sqrt\", \"max_depth\": 5, \"min_samples_leaf\": 10}\n",
    "model = RandomForestClassifier(random_state = 0, **hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the `train_evaluate.py` script using the new hyper-parameters values. We can run an external Python script from inside the notebook using the `%run` magic. It is important to use the `-i` switch (stands for interactive), which runs the script using the **same** Python session that the notebook is hosting. Without the `-i` switch, the script would run in a new Python session and would not be aware of the variables we are providing above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i train_evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we do a new run, a new row will be added to `results`, and we can compare it to all the runs so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.865852</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.865698</td>\n",
       "      <td>0.861679</td>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.838856</td>\n",
       "      <td>0.838093</td>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     algo acc_train  acc_test  n_estimators max_features  \\\n",
       "0  RandomForestClassifier  0.865852  0.861126         100.0         sqrt   \n",
       "1  RandomForestClassifier  0.865698  0.861679         200.0         sqrt   \n",
       "2  RandomForestClassifier  0.838856  0.838093         200.0         sqrt   \n",
       "\n",
       "   max_depth  min_samples_leaf  \n",
       "0       20.0              10.0  \n",
       "1       20.0              10.0  \n",
       "2        5.0              10.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a gradient boosted classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a gradient boosted classifier. Shrinkage is controlled by `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "hypers = {\"n_estimators\": 100, \"max_features\": \"sqrt\", \"max_depth\": 20, \"min_samples_leaf\": 10, \"learning_rate\": 0.5}\n",
    "clf_gb = GradientBoostingClassifier(loss = 'deviance', verbose = True, **hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One again we train the classifier by calling `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7669            6.27s\n",
      "         2           0.6581            6.86s\n",
      "         3           0.5942            7.24s\n",
      "         4           0.5572            6.92s\n",
      "         5           0.5275            6.80s\n",
      "         6           0.5078            6.61s\n",
      "         7           0.4863            6.56s\n",
      "         8           0.4704            6.32s\n",
      "         9           0.4541            6.25s\n",
      "        10           0.4461            5.99s\n",
      "        20           0.3658            5.03s\n",
      "        30           0.3004            4.41s\n",
      "        40           0.2615            3.76s\n",
      "        50           0.2252            3.14s\n",
      "        60           0.4636            2.51s\n",
      "        70  4149380818.5624            1.89s\n",
      "        80  4149408361.5125            1.24s\n",
      "        90 2529277821008990.0000            0.62s\n",
      "       100 25600531157725773849033008733193130127945220218109646575908760941004906520544694648296953229155433121915727406392372234992654221312.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.5, loss='deviance', max_depth=20,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=10, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=True,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gb.fit(X_train_encoded, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the variable importance plot for a gradient boosted classifier as well. The results should not look very different from using random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEGCAYAAADFbPcfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZhcVbn+/e9NICZMYVJeUDSgESQQAoQwCkFxAlEUNCIg4TAcR0QO+tODQ8DhKPo7ICAicBBERGaNxMMgJkwhkIGQgUEU4uvAKyAYAUNiwv3+sVfLpuihmu6u7k7uz3X11bvWXsOzd6dST629qrZsExEREdEqa/R3ABEREbF6SfIRERERLZXkIyIiIloqyUdERES0VJKPiIiIaKk1+zuAiIFuk0028ciRI/s7jIiIQWXOnDlP2H5le/uSfER0YeTIkcyePbu/w4iIGFQk/b6jfbnsEhERES2VmY+ILixZupypixb3dxgRES11wOiRfdZ3Zj4iIiKipZJ8REREREsl+YiIiIiWSvIRERERLZXkIyIiIloqyUc/kTRd0rgu6pwgae3a419K2qAXY5gs6aQO9s3ohf5fdIySRkpa2Bt99RZJkySd3dv9RkREx5J89BFVenp+TwD+lXzY3t/233rYZ1Ns79GKcSIiYvWT5KMXlXf290s6B5gLbCHp7ZLulDRX0pWS1m2n3fclzZa0SNIppex4YHNgmqRppWyxpE3K9omSFpafExrGP7/0daOk4W39SbpP0nxJP60Nv22ZVXi4jNkW0zPl9wRJt0q6trQ/txeSqpfMOEi6row1RNJF5bgWSPpMrdnhkmaUfeNLu/Gl7J7ye+ta/9dIul7SQ5JOq411lKTfSLoF2LOD+I4rf5PZS576a08PNyIiavIlY71va+Ao2x8vicIXgf1sPyvp/wAnAqc2tDnZ9pOShgA3Sxpj+0xJJwL72n6iXlnSzsBRwK6AgLvKC+lTwCjgUNvHSroCOBj4MfB5YEvbyxou3WwD7AusBzwo6fu2/9kQ33hgW+D3wPXA+4Grmjwfl0paWraHAs93UX8s8Grb25Vjrce6ju09JO0NXAhsBzwA7G17haT9gG+UY27ra0dgWTm2s4AVwCnAzsASYBpwT2MQts8DzgMYNXqMmzzWiIhoQmY+et/vbc8s27tRvWjfIWkecCTwunbafFDSXKoXwdGlTWf2Aq61/aztZ4BrgDeXfY/Ynle25wAjy/Z8qkTgcKoX4DZTbS8rCc5jwKbtjHe37YdtrwQuK+M36zDbY22PBfZvov7DwFaSzpL0TuDvtX2XAdi+FVi/JCYjgCvLWpLTqc5fm5ttL7H9HHAf1bnfFZhu+3Hby4HLu3EsERHRC5J89L5na9sCbmp78bW9re2j65UlbQmcBLzV9hhgKjCsizHUyb5lte2VvDC7dQDwPap3/HMkrdlF/brGd/69MROwghf/+xsGYPspYAdgOvAJ4IIu4vgqMK3MlBzIi89dR8eWmYyIiH6U5KNvzQT2lPQGAElrS3pjQ531qRKWJZI2Bd5V2/c01eWQRrcCB5X+1gHeB9zWURBljcYWtqcBnwM2AF6y9qQT4yVtWfqZCNzejbYdWQyMlbSGpC2oLu1QLlWtYftq4EvATrU2E0udvYAltpdQzXz8qeyf1MS4dwETJG0saS3gA71wLBER0Q1Z89GHbD8uaRJwmaRXlOIvAr+p1blX0j3AIqpLDnfUujgP+F9Jj9ret9ZmrqSLgLtL0QW275E0soNQhgA/ljSCatbkdNt/kzqbQHmRO4FvAttTJT7XNtuwE3cAjwALgIVUC3QBXg38sLao9Qu1Nk+p+gjw+sC/lbLTgIvL+phfdzWo7UclTaY6pkfLuEN6digREdEdsjMDHR2TNAE4yfa7+zuW/jJq9BifccWU/g4jIqKlenpXW0lzbLf7/Uy57BIREREtlcsu0Snb06kWf76IpLuAVzQUH2F7QQvCioiIQSzJR7wstnft7xhaZcTwoT2efoyIiBfksktERES0VJKPiIiIaKkkHxEREdFSWfMR0YUlS5czddHi/g4jIqIlWrHGLTMfERER0VJJPiIiIqKlknxERERESyX5iIiIiJZK8hEREREtleQj+pykzSVdVbbHStq/iTYTJF3XS+OPk3Rmb/QVERE9l4/aRp+z/WfgkPJwLDAO+GULx58NzG7VeBER0bnMfESXJH1E0nxJ90q6RNKBku6SdI+kX0natNSbXPb/WtJDko4t5SMlLZQ0FDgVmChpnqSJksZLmlH6miFp6ybi2V/SA5Jul3Rm2wxJR33VZ1FKjBdKmi7pYUnH99V5i4iI9mXmIzolaTRwMrCn7SckbQQY2M22JR0DfA74j9JkDLAbsA5wj6SpbX3ZXi7py8A4258s/a8P7G17haT9gG8AB3cSzzDgB6XNI5Iuq+1+oMm+tgH2BdYDHpT0fdv/bBjnOOA4gFdutnkTZyoiIpqV5CO68hbgKttPANh+UtL2wOWSNgOGAo/U6v/c9lJgqaRpwHhgXif9jwAuljSKKqlZq4t4tgEett025mWUJKEbfU21vQxYJukxYFPgj/UKts8DzgMYNXqMu4gpIiK6IZddoiuieiGvOws42/b2wL8Dw2r7Gut29cL9VWCa7e2AAxv6qgKQbiiXaS4o8bzsvoplte2VJAmPiGipJB/RlZuBD0raGKBcdhkB/KnsP7Kh/nslDSv1JwCzGvY/TXW5o029r0ntBWD7HbbH2j6G6tLKVpJGlt0Tu9NXRET0vyQf0Snbi4CvA7dIuhf4b2AycKWk24AnGprcDUwFZgJfLZ90qZsGbNu24BQ4DfgvSXcAQ5qIZynwceB6SbcDfwGWlN3d6isiIvqH7FzOjt4haTLwjO3v9PE469p+RpKA7wEP2T69r8YbNXqMz7hiSl91HxExoPTWXW0lzbE9rr19mfmIwehYSfOARVSXWn7Qz/FEREQ3ZKFd9Brbk1s0zulAn810RERE38rMR0RERLRUZj4iujBi+NBeuwYaERGZ+YiIiIgWS/IRERERLZXkIyIiIloqaz4iurBk6XKmLlrc32FEDEhZDxUvR2Y+IiIioqWSfERERERLJfmIiIiIlkryERERES2V5CMiIiJaKslHREREtFSSj4iIiGipJB8x6En6maQ5khZJOq6UHS3pN5KmSzpf0tml/JWSrpY0q/zs2b/RR0SsfvIlY7Eq+DfbT0oaDsySNBX4ErAT8DTwa+DeUve7wOm2b5f0WuAG4E2NHZYk5jiAV262eQsOISJi9ZHkI1YFx0t6X9neAjgCuMX2kwCSrgTeWPbvB2wrqa3t+pLWs/10vUPb5wHnAYwaPcZ9HH9ExGolyUcMapImUCUUu9v+h6TpwIO0M5tRrFHqLm1NhBER0ShrPmKwGwE8VRKPbYDdgLWBfSRtKGlN4OBa/RuBT7Y9kDS2pdFGRESSjxj0rgfWlDQf+CowE/gT8A3gLuBXwH3AklL/eGCcpPmS7gM+2vqQIyJWb7nsEoOa7WXAuxrLJc22fV6Z+biWasYD208AE1sbZURE1GXmI1ZVkyXNAxYCjwA/6+d4IiKiyMxHrJJsn9TfMURERPuSfER0YcTwoRwwemR/hxERscrIZZeIiIhoqSQfERER0VJJPiIiIqKlknxERERES2XBaUQXlixdztRFi/s7jIg+kwXV0WqZ+YiIiIiWSvIRERERLZXkIyIiIloqyUdERES0VJKPGFAkHS/pfkmXdlLnmV4YZ5KkzXvaT0REdF8+7RIDzceBd9l+pI/HmUR107k/9/E4ERHRIDMfMWBIOhfYCpgiaYmkCyVNl/SwpOPbqX+OpPeU7WslXVi2j5b0tbL9JUkPSLpJ0mWSTpJ0CDAOuFTSPEnDW3eUERGR5CMGDNsfpZqJ2Bc4HdgGeAcwHviKpLUamtwKvLlsvxrYtmzvBdwmaRxwMLAj8H6qhAPbVwGzgcNsj7W9tDEWScdJmi1p9pKn/tqLRxkREUk+YiCbanuZ7SeAx4BNG/bfBrxZ0rbAfcBfJG0G7A7MoEpCfm57qe2ngV80O7Dt82yPsz1uxIYb98rBREREJWs+YiBbVtteScO/V9t/krQh8E6qWZCNgA8Cz9h+WpJaFmlERDQtMx8x2N0JnECVfNwGnFR+A9wOHChpmKR1gQNq7Z4G1mtloBERUUnyEYPdbcCatn8LzKWa/bgNwPYsYApwL3AN1TqPJaXdRcC5WXAaEdF6st3fMUT0GUnr2n5G0tpUsyPH2Z7bnT5GjR7jM66Y0jcBRgwAubFc9AVJc2yPa29f1nzEqu68siB1GHBxdxOPiIjofUk+YpVm+8P9HUNERLxY1nxERERES2XmI6ILI4YPzTXxiIhelJmPiIiIaKkkHxEREdFSST4iIiKipZJ8REREREtlwWlEF5YsXc7URYv7O4xYzWXRc6xKMvMRERERLZXkIyIiIloqyUdERES0VJfJh6RNJf2PpP8tj7eVdHTfhxYRERGromZmPi4CbgA2L49/A5zQVwFFa0maJOnsXu7zoHIzt7bHp0rarzfHiIiIwauZ5GMT21cAzwPYXgGs7NOoYrA7CPhX8mH7y7Z/1Y/xRETEANJM8vGspI0BA0jaDVjSp1FFr5F0uKS7Jc2T9ANJQyQdJek3km4B9qzVvUjSIbXHz9S2PydpgaR7JX2zlB0raVYpu1rS2pL2AN4DfLuM+fp6v5LeKume0teFkl5RyhdLOkXS3LJvmw6Op916kiZLOqlWb6GkkeXnAUkXlLJLJe0n6Q5JD0ka36snPCIiutRM8nEiMAV4vaQ7gB8Bn+rTqKJXSHoTMBHY0/ZYqhmrw4FTqJKOt1Gboeikn3dRzWbsansH4LSy6xrbu5Sy+4Gjbc+g+vfyWdtjbf+u1s8wqst4E21vT/U9Mx+rDfWE7Z2A7wMn0bFm67V5A/BdYAywDfBhYK/S9j87OObjJM2WNHvJU39tYoiIiGhWp8mHpDWAYcA+wB7AvwOjbc9vQWzRc28FdgZmSZpXHn8GmG77cdvLgcub6Gc/4Ie2/wFg+8lSvp2k2yQtAA4DRnfRz9bAI7Z/Ux5fDOxd239N+T0HGNlJP83Wa/OI7QW2nwcWATfbNrCgo/a2z7M9zva4ERtu3MQQERHRrE6Tj/Kf9f+1vcL2ItsLbf+zRbFFzwm4uMxAjLW9NTCZcgmtHSso/yYkCRha66e9NhcBnyyzGKdQJapdxdOZZeX3Ssq370q6oVy+uaCzevXYi2Ht1Idq7dKy2na+5TciosWauexyo6SDy4tRDC43A4dIehWApI2Ae4AJkjaWtBbwgVr9xVQzJQDvBdYq2zcC/yZp7Vo/AOsBj5Z+Dqv183TZ1+gBYKSkN5THRwC3dHYAtt9REqdjujjWxcBOJb6dgC27qB8REf2kmXd9JwLrACskPUd5F2x7/T6NLHrM9n2SvkiVQK4B/BP4BNXsx53Ao8BcYEhpcj7wc0l3UyUuz5Z+rpc0FpgtaTnwS6q1El8C7gJ+T3UJoy3h+ClwvqTjgX8tYLX9nKSjgCslrQnMAs7tpcO9GvhIubw0i+oj4RERMQCpuvQdER0ZNXqMz7hiSn+HEau53FguBhtJc2yPa29flzMfkvZur9z2rT0NLCIiIlY/zVx2+WxtexgwnupTBm/pk4giIiJildZl8mH7wPpjSVvwwvc8RERERHTLy/mY4R+B7Xo7kIiBasTwobneHhHRi5pZ83EWL3zHwxrAWODevgwqIiIiVl3NzHzMrm2vAC6zfUcfxRMRERGruGaSjw1sf7deIOnTjWURERERzWgm+TiS6qZcdZPaKYtYJS1Zupypixb3dxgxiGSNUETnOkw+JB1KdffPLSXVv2FpPSC3+YyIiIiXpbOZjxlUX7+9CfB/a+VPA7mrbURERLwsHSYftn9Pdc+O3VsXTkRERKzquryrraTdJM2S9Iyk5ZJWSvp7K4KLiIiIVU+XyQdwNnAo8BAwHDgGOKsvg4qIiIhVVzPJB7Z/CwyxvdL2D4F9+zas6AlJIyUt7O84BipJiyVt0t9xRESsrpr5qO0/JA0F5kk6jWoR6jp9G1YMNJLWtL2iBeMMsb2yr8eJiIj+08zMxxGl3ieBZ4EtgIP7MqjoFUMknS9pkaQbJQ2XNFbSTEnzJV0raUMASdMljSvbm0haXLYnSbpS0i+AGyVtJulWSfMkLZT05sZBS5ufS7pe0oOSvlLbd7iku0v7H0gaUsqfkXSqpLtoWOAs6RxJ7ynb10q6sGwfLelrXfT7dkl3SppbjmPdhr6HlziP7aVzHhERTegy+SifehGwme1TbJ9YLsPEwDYK+J7t0cDfqBLGHwH/x/YYYAHwlU7at9kdONL2W6i+9+UG22OBHYB5HbQZDxxGdR+gD0gaJ+lNwERgz9J+ZakD1UzaQtu72r69oa9bgbYk59XAtmV7L+C2jvotl1W+COxneyeq2wScWOt3XeAXwE9sn994AJKOkzRb0uwlT+VrbSIielMzN5Y7EPgOMJTqC8fGAqfafk9fBxc98ojttuRgDvB6qq/Kv6WUXQxc2UQ/N9l+smzPAi6UtBbws1r/7bX5K4Cka6gShRXAzsAsSVAtXn6s1F8JXN1BX7cBJ0jaFrgP2FDSZlRJ0fFU38DbXr+7USUqd5TyocCdtX5/Dpxm+9L2BrV9HnAewKjRY9xenYiIeHmaWfMxmeqd7HQA2/MkjeyziKK3LKttrwQ26KTuCl6YBRvWsO/Ztg3bt0raGzgAuETSt6m+dK5tBuWYtqoNfZhq9uxi219oZ/zn2tZ5SNoV+EEp/7LtKeXy0DupZkE2Aj4IPGP7aVWZxUv6LUnzTbYP7eCY7wDeJekntpNcRES0UDNrPlbYXtLnkURfWwI8VVuncQTQNguymGr2AOCQjjqQ9DrgsXKZ4n+AnWxfa3ts+Wm7A/LbJG0kaThwENUL/c3AIZJeVfraqPT3IrbvqvXX9rX+dwInUCUftwEnld900u9MYE9Jbyjla0t6Y22oL1PdJuCczk5aRET0vmaSj4WSPky1gHGUpLOovno9Bp8jgW9Lmk+1HuPUUv4d4GOSZlB9nX5HJlB96ukeqjUkHd1c8HbgEqo1IVfbnm37Pqo1GDeW8W8CNmsy7tuANctao7lUsx+3AXTUr+3HqW6AeFkpnwls09DvCcCw8imuiIhoEXU04yzpEttHSPpPqgWBb6eaOr8B+Krt51oXZgwWkiYB42x/sr9j6S2jRo/xGVdM6bpiRJG72kaApDm2x7W3r7M1HzuX6euJVF8qVr+53NpAko+IiIjots6Sj3OB64GtqD6m2EZUCwi36sO4YpCyfRFwUT+HERERA1iHaz5sn2n7TcCFtreq/WxpO4lHREREvCxdftTW9sdaEUjEQDVi+NBcw4+I6EVN3VguIiIiorck+YiIiIiWSvIRERERLdXM16tHrNaWLF3O1EWL+zuM1ULW1kSsHjLzERERES2V5CMiIiJaKslHREREtFSSj4iIiGipJB8RERHRUkk+VjGSpktq9y6CtTonSFq79viXkjboxRgmSzqpg30zetj3eyX9rPb4C5J+W3t8oKQpZftfxyXpeEn3S7q0J+NHRETPJfkYZFTp6d/tBKo7EwNge3/bf+thn02xvUcPu5gB7F57vDvwd0mvKo/3AO4oY9WP6+PA/rYP6+H4ERHRQ0k+BgFJI8u79nOAucAWkt4u6U5JcyVdKWnddtp9X9JsSYsknVLKjgc2B6ZJmlbKFkvapGyfKGlh+TmhYfzzS183Shre1p+k+yTNl/TT2vDbllmYh8uYbTE9U35PkHSrpGtL+3ObSapsPw4skfSGUvRq4GqqpIPye0b9uCSdS3UX5imSPiNpHUkXSpol6R5J723qDxEREb0iycfgsTXwI9s7As8CXwT2s70TMBs4sZ02J9seB4wB9pE0xvaZwJ+BfW3vW68saWfgKGBXYDfgWEk7lt2jgO/ZHg38DTi4lH8e2NH2GOCjte62Ad4BjAe+ImmtduIbD/wHsD3weuD9TZ6LGcAekrYGHgJmlsdrlmOdVa9s+6O1Yz4dOBn4te1dgH2Bb0tap+FcHFcSt9lLnvprk2FFREQzknwMHr+3PbNs7wZsC9whaR5wJPC6dtp8UNJc4B5gdGnTmb2Aa20/a/sZ4BrgzWXfI7bnle05wMiyPR+4VNLhwIpaX1NtL7P9BPAYsGk7491t+2HbK4HLyvjNuINqhmMP4E7gbqqEaUfgQdvPddH+7cDny7mbDgwDXluvYPs82+Nsjxux4cZNhhUREc3I16sPHs/WtgXcZPvQjipL2hI4CdjF9lOSLqJ6ke2MOtm3rLa9Ehhetg8A9gbeA3xJ0ugO6rf3b81dPO7IDOBTwBDgfNtPSxoGTKCs9+iCgINtP9jkeBER0Ysy8zE4zQT2bFv3IGltSW9sqLM+VcKyRNKmwLtq+54G1mun31uBg0p/6wDvA27rKIiyRmML29OAzwEbAC9Ze9KJ8ZK2LP1MBG5vst19VOtW3kw1qwMwj+qyTzOfprkB+JQkAdQuLUVERAsk+RiEyqLLScBlkuZTJSPbNNS5l+qFeRFwIS+eETgP+N+2Bae1NnOBi6guY9wFXGD7Hjo2BPixpAVlrNO7+amZO4FvAguBR4Brm2lk2yW+J2z/s9bXVjSXfHwVWAuYL2lheRwRES2i6v/xiNaSNAE4yfa7+zuWrowaPcZnXDGlv8NYLeSuthGrDklzyoceXiIzHxEREdFSWXAa/cL2dKpPmryIpLuAVzQUH2F7QQvCioiIFkjyEQOK7V37O4ZGI4YPzeWAiIhelMsuERER0VJJPiIiIqKlknxERERESyX5iIiIiJbKgtOILixZupypixb3dxiDRhbnRkRXMvMRERERLZXkIyIiIloqyUdERES0VJKPiIiIaKkkH9EykjaXdFXZHitp/ybaTJB0XQf7pktq96ZFERExcCX5iJax/Wfbh5SHY4Euk4+IiFj1JPmIpkn6iKT5ku6VdImkAyXdJekeSb+StGmpN7ns/7WkhyQdW8pHSlooaShwKjBR0jxJEyWNlzSj9DVD0tbdjO1QSQtK/98qZUMkXVTKFkj6TCk/XtJ95Vh+2rtnKSIiupLv+YimSBoNnAzsafsJSRsBBnazbUnHAJ8D/qM0GQPsBqwD3CNpaltftpdL+jIwzvYnS//rA3vbXiFpP+AbwMFNxrY58C1gZ+Ap4EZJBwF/AF5te7tSb4PS5PPAlraX1coa+zwOOA7glZtt3kwYERHRpMx8RLPeAlxl+wkA208CrwFukLQA+Cwwulb/57aXlvrTgPFd9D8CuFLSQuD0hr66sgsw3fbjtlcAlwJ7Aw8DW0k6S9I7gb+X+vOBSyUdDqxor0Pb59keZ3vciA037kYoERHRlSQf0SxRzXTUnQWcbXt74N+BYbV9jXUbHzf6KjCtzFIc2NBXFYB0Q7lMc0E7sb2E7aeAHYDpwCeAtnYHAN+jmimZIykzgBERLZTkI5p1M/BBSRsDlMsuI4A/lf1HNtR/r6Rhpf4EYFbD/qeB9WqP631Nai8A2++wPdb2MQ277gL2kbSJpCHAocAtkjYB1rB9NfAlYCdJawBb2J5GdZloA2DdLo8+IiJ6Td7xRVNsL5L0daoX9ZXAPcBkqkslfwJmAlvWmtwNTAVeC3zV9p8ljaztnwZ8XtI84L+A04CLJZ0I/LqbsT0q6QulTwG/tP1zSTsAPywJB8AXgCHAjyWNKHVPt/237owXERE9I7ur2fCI7pE0GXjG9nf6O5beMGr0GJ9xxZT+DmPQyI3lIgJA0hzb7X4XUy67REREREvlskv0OtuT+zuGiIgYuDLzERERES2VmY+ILowYPjTrGCIielFmPiIiIqKlknxERERESyX5iIiIiJbKmo+ILixZupypixb3dxg9kjUrETGQZOYjIiIiWirJR0RERLRUko+IiIhoqSQfERER0VJJPiIiIqKlknxERERESyX56EWSxkrav/b4PZI+34fjrZQ0r/bTZ2MNRpIukLRtF3WmS2r3ls8REdE38j0fvWssMA74JYDtKcCUPhxvqe2xfdj/oCVpiO1j+juOiIh4qUE/8yHpREkLy88JtfKPSJov6V5Jl5SyTSVdW8rulbSHpJGSFtbanSRpctmeLukMSTNK/+NL+fhSdk/5vbWkocCpwMQyCzFR0iRJZ5c2r5N0c4npZkmvLeUXSTqz9POwpEN6eD5GSHpQ0tbl8WWSji3bb5d0p6S5kq6UtG4p36WMf6+kuyWt106/0yWdLulWSfeXNtdIekjS12r1fiZpjqRFko6rlT8j6etljJmSNi3lB0q6q5zLX9XKXynpphLrDyT9XtImZd/hJc55Zd+Q2hinSroL2L0+qyHp+5Jml7hOaeI8Hlfqz17y1F9f9t8jIiJealAnH5J2Bo4CdgV2A46VtKOk0cDJwFts7wB8ujQ5E7illO0ELGpimHVs7wF8HLiwlD0A7G17R+DLwDdsLy/bl9sea/vyhn7OBn5kewxwaYmlzWbAXsC7gW82fwYY3nDZZaLtJcAngYskfQjY0Pb55YX7i8B+tncCZgMnlqTpcuDT5bzsByztYLzltvcGzgV+DnwC2A6YJGnjUuffbO9MNQN0fK18HWBmGeNW4NhSfjuwWzmXPwU+V8q/Avy6xHot0JasvQmYCOxZZn1WAofVxlhoe1fbtzfEfrLtccAYYB9JYzo7sbbPsz3O9rgRG27cWdWIiOimwX7ZZS/gWtvPAki6BngzYOAq208A2H6y1H8L8JFSthJYImnDLsa4rNS/VdL6kjYA1gMuljSqjLVWE7HuDry/bF8CnFbb9zPbzwP3tb3zb1K7l11s3yTpA8D3gB1K8W7AtsAdkgCGAncCWwOP2p5V2v69k/HaLiEtABbZfhRA0sPAFsBfqRKO95V6WwCjSvly4LpSPgd4W9l+DXC5pM1KTI+U8r2A95WYrpf0VCl/K7AzMKscx3DgsbJvJXB1B7F/sMzErEmV7G0LzO/kWCMioo8M9uRDnZS7yT5W8OIZoGEN+xv7MfBVYJrt90kaCUxvcqyO+l1W2+7omJomaQ3gTVQzGARd6vIAAA/1SURBVBsBfyz93mT70Ia6Y2jnXEn6IbAj8GfbbYto2+J8viHm54E1JU2gmjnZ3fY/JE3nhfP5T9tt46zkhX97ZwH/bXtKaT+5LYSODg+42PYX2tn3XEkqG49lS+AkYBfbT0m6iJf+nSMiokUG9WUXqun7gyStLWkdqnfKtwE3U73T3RhA0kal/s3Ax0rZEEnrA38BXiVpY0mvoLr0UTex1N8LWFIua4wA/lT2T6rVfZpqVqQ9M4APle3DqC439JXPAPcDhwIXSloLmAnsKekNAOWcvZHqEtLmknYp5etJWtP2UeXy0f4djNGeEcBTJfHYhmq2pZk2befyyFr57cAHS0xvB9pmqG4GDpH0qrJvI0mv62KM9YFnqWa6NgXe1czBRERE3xjUyYftucBFwN3AXcAFtu+xvQj4OnCLpHuB/y5NPg3sK2kB1dT/aNv/pFooehfVZYEHGoZ5StIMqnUOR5ey04D/knQHMKRWdxqwbdv6i4Z+jgeOkjQfOIIX1qH0ROOaj2+WhOIY4D9s30aVoH3R9uNUidJlJYaZwDZlrcpE4Kxyrm7i5c8KXE81AzKfanZoZhNtJgNXSroNeKJWfgrwdklzqZKFR4Gnbd9HtXblxjLOTVSXUTpk+17gHqo1PhcCd3TnoCIionfphZnwaFQuG5xke3Z/x7K6KbNQK22vkLQ78P3++ljxqNFjfMYVffmJ6b53wOiR/R1CRKxmJM0pC/1fYrCv+YhV12uBK8r6leW88OmYiIgY5JJ8dML2hP4YV9L2VJ+IqVtme9f+iKc/2H6IasFrRESsYpJ8DEC2F1B9W2oMACOGD81li4iIXjSoF5xGRETE4JPkIyIiIloqyUdERES0VNZ8RHRhydLlTF20uL/DaErWpkTEYJCZj4iIiGipJB8RERHRUkk+IiIioqWSfERERERLJfmIiIiIlkryERERES01KJIPSZtLuqpsj5W0fxNtJki6rhtjHCRp296q93JJWlxuL18vmydpYS/0/UtJG3Sj/iRJZ3ej/nskff7lRRcREauLAZ98SFrT9p9tH1KKxgJdJh8vw0FAM0lFs/V6Yj1JWwBIelN3G0sa0vBYktawvb/tv/VWkI1sT7H9zb7qPyIiVg19knxIGinpAUkXSFoo6VJJ+0m6Q9JDksaXeuMlzZB0T/m9dSmfJOlKSb8Abiz9LZQ0FDgVmFhmAyZ21EcX8X1T0n2S5kv6jqQ9gPcA3y79vl7SsZJmSbpX0tWS1u6g3nRJ40q/m0haXLZHS7q71JsvaVQ3TuEVwMSyfShwWcO5vU3S3PKzRymfIGmapJ8AC0q9+yWdA8wFtiizKpuU+ofX4vtBW8Ii6ShJv5F0C7BnJ+fwnWX8eyXdXMomSTpb0ogy1hqlfG1Jf5C0VkMf60iaWvpYKGliKV8s6VslvrslvaGUv07SzeV83izptaX8IkmH1Pp9pvzeTNKtbTNHkt5cyt8u6c4S/5WS1m3n+I6TNFvS7CVP/bXpP1xERHStL2c+3gB8FxgDbAN8GNgLOAn4z1LnAWBv2zsCXwa+UWu/O3Ck7be0FdheXupdbnus7cu76OMlJG0EvA8YbXsM8DXbM4ApwGdLv78DrrG9i+0dgPuBozuo15GPAt+1PRYYB/yx07P1YlcB7y/bBwK/qO17DHib7Z2oEpQza/vGAyfbbpuZ2Rr4ke0dbf++dg7eVNruWeJbCRwmaTPgFKqk4210MMMj6ZXA+cDB5fx8oL7f9hLgXmCf2jHcYPufDV29E/iz7R1sbwdcX9v3d9vjgbOBM0rZ2eV4xgCXNhx7ez5cxh0L7ADMK8nXF4H9yjmcDZzY2ND2ebbH2R43YsONuxgmIiK6oy+/Xv2Rcmt4JC0CbrZtSQuAkaXOCODiMitgoP7O+CbbTzYxTmd9tOfvwHPABZKmAh2tC9lO0teADYB1gRuaiKXuTuBkSa+hSmQe6kbbJ4GnJH2IKvH5R23fWsDZktqShjfW9t1t+5Ha49/bntlO/28FdgZmSQIYTpXU7ApMt/04gKTLG/pvsxtwa9tYHfydLqdKcKYBHwLOaafOAuA7kr4FXGe7vtblstrv08v27ryQlF0CnNZOn3WzgAvLjMvPbM+TtA9VUnVHOfahVH+riIhokb6c+VhW236+9vh5Xkh6vgpMK+96DwSG1do82+Q4nfUBgKQbytT7BbZXUM0QXE21fuP6xvrFRcAnbW9PNRvwkn6LFbxwHv9Vx/ZPqC7RLAVukPSWdtp25nLge9QuuRSfAf5C9U5+HNWLZ5vGc9bRORRwcZm9GWt7a9uT20J/SWVpSDl/8ySdWtq/pF6DKcC7ykzTzsCvJW1R6+ejtn9T9i0A/kvSl2vt3cE27ZT/62+gKqMYCmD7VmBv4E/AJZI+UmK/qXbs29o+uotjiYiIXtTfC05HUL0wAExqss3TwHrd6cP2O8oLzTHl+v4I278ETqBawNpev+sBj5Z3zYd1Mv5iqhdQgPq6g62Ah22fSfVCPKbJ42tzLdU7+8YZlxHAo7afB44AhjQ2bMLNwCGSXlVi3UjS64C7gAmSNi7H/QEA2ytrL9Zfppop2EfSlm3tGwew/QxwN9Wlt+tKH3+o9XOupM2Bf9j+MfAdYKdaFxNrv9tmJmZQzaJA9Te5vWwv5oW/wXsps1/lmB6zfT7wP6X/mcCetXUka0tqb3YnIiL6SH8nH6dRveO9g+ZfRKcB25Z3zxNfRh/rAddJmg/cQjWTAPBT4LOqFq6+HvgS1YvxTVTrSuig3neAj0maAWxSqzcRWChpHtWalx81eXwA2H7a9rfKOpe6c4AjJc2kuiTS7AxRve/7qNY93FjOw03AZrYfBSZTvdj/imqhanvtHweOA66RdC/VLE17LgcO72T/9sDd5RydDHyttu8Vku4CPs0Lf6PjgaNKzEeUfVCtP9lH0t1Ul47azskEqnUe9wAHU63BeZwqSb2s9DOT6u8TEREtIrur2fOI1lL1iaFxtp/o71gARo0e4zOumNLfYTTlgNEj+zuEiAgAJM2xPa69ff098xERERGrmb78tEvUSNqYaq1Fo7fazhdJ1Nge2d8xRERE30ny0SIlwRjbZcUYcEYMH5rLGRERvSiXXSIiIqKlsuA0oguSngYe7O84mrQJMCAW6nZhsMQJgyfWxNn7BkusAzXO19l+ZXs7ctklomsPdrRie6CRNHswxDpY4oTBE2vi7H2DJdbBEmddLrtERERESyX5iIiIiJZK8hHRtfP6O4BuGCyxDpY4YfDEmjh732CJdbDE+S9ZcBoREREtlZmPiIiIaKkkHxEREdFSST5itSbpnZIelPRbSZ9vZ78knVn2z5e0U7NtB0KckraQNE3S/ZIWSfr0S3sfGLHW9g8pd42+bqDGKWkDSVdJeqCc290HaJyfKX/3hZIukzSsr+JsMtZtJN0paZmkk7rTdiDEOUCfTx2e07K/Jc+nbrOdn/yslj/AEOB3wFbAUOBeYNuGOvsD/wsI2A24q9m2AyTOzYCdyvZ6wG/6Ks6exlrbfyLwE+C6gRoncDFwTNkeCmww0OIEXg08Agwvj68AJvXzOX0VsAvwdeCk7rQdIHEOxOdTu7HW9vf58+nl/GTmI1Zn44Hf2n7Y9nLgp8B7G+q8F/iRKzOBDSRt1mTbfo/T9qO25wLYfhq4n+pFqa/05Jwi6TXAAcAFfRhjj+KUtD6wN/A/ALaX2/7bQIuz7FsTGC5pTWBt4M99FGdTsdp+zPYs4J/dbTsQ4hyIz6dOzmkrn0/dluQjVmevBv5Qe/xHXvofSUd1mmnbW3oS579IGgnsCNzV6xF2I44u6pwBfA54vq8CbCKGrupsBTwO/LBMZ18gaZ2BFqftPwHfAf5f4FFgie0b+yjOZmPti7bd1StjDaDnU2da9XzqtiQfsTpTO2WNnz3vqE4zbXtLT+KsdkrrAlcDJ9j+ey/G1uhlxyrp3cBjtuf0flgv0ZNzuiawE/B92zsCzwJ9tUahJ+dzQ6p3yVsCmwPrSDq8l+PrMo4WtO2uHo81wJ5P7Tds7fOp25J8xOrsj8AWtcev4aXT0h3VaaZtb+lJnEhai+o/ykttX9NHMXYZRxN19gTeI2kx1fTyWyT9eADG+Ufgj7bb3vFeRZWMDLQ49wMesf247X8C1wB79FGczcbaF227q0djDcDnU0da+XzqtiQfsTqbBYyStKWkocCHgCkNdaYAHymfKNiNaur60Sbb9nuckkS1NuF+2//dR/H1Sqy2v2D7NbZHlna/tt1X79R7Euf/B/xB0tal3luB+wZanFSXW3aTtHb5d/BWqjUKfaUnz4mB9nxq1wB9PrWrxc+n7uvvFa/5yU9//lB9UuA3VCvKTy5lHwU+WrYFfK/sXwCM66ztQIsT2ItqmnY+MK/87D8QY23oYwJ9vDq/h3/7scDscl5/Bmw4QOM8BXgAWAhcAryin8/p/0P1bv7vwN/K9vodtR1ocQ7Q51OH57TWR58/n7r7k69Xj4iIiJbKZZeIiIhoqSQfERER0VJJPiIiIqKlknxERERESyX5iIiIiJZK8hER0YskzWjxeCMlfbiVY0b0VJKPiIheZLsvv0X0RcoN40YCST5iUMn3fERE9CJJz9heV9IEqi/5+gvVl5JdQ/UlYJ8GhgMH2f6dpIuA54DRwKbAibavkzQM+D4wDlhRyqdJmkR1p9JhwDpUd6t9E/AIcDFwLdUXirXd7O6TtmeUeCYDTwDbAXOAw21b0i7Ad0ubZVTfhvoP4JtUX1D1CuB7tn/Qy6crVlNr9ncAERGrsB2oEoMngYeBC2yPl/Rp4FPACaXeSGAf4PXANElvAD4BYHt7SdsAN0p6Y6m/OzDG9pMlqTjJ9rsBJK0NvM32c5JGAZdRJTBQ3YV1NNX9Qe4A9pR0N3A5MNH2LEnrA0uBo6m+qn0XSa8A7pB0o+1H+uA8xWomyUdERN+Z5eo+K0j6HdB2S/sFwL61elfYfh54SNLDwDZUX+V9FoDtByT9HmhLPm6y/WQHY64FnC1pLLCy1gbgbtt/LPHMo0p6lgCP2p5Vxvp72f92YIykQ0rbEcAoqhmWiB5J8hER0XeW1bafrz1+nhf//9t4/du0fzv1Ns92su8zVJd6dqBa1/dcB/GsLDGonfEp5Z+yfUMnY0W8LFlwGhHR/z4gaQ1Jrwe2Ah4EbgUOAyiXW15byhs9DaxXezyCaibjeeAIYEgXYz8AbF7WfSBpvbKQ9QbgY+UW8kh6o6R1OuknommZ+YiI6H8PArdQLTj9aFmvcQ5wrqQFVAtOJ9leVt3V/UXmAysk3QtcBJwDXC3pA8A0Op8lwfZySROBsyQNp1rvsR9wAdVlmbnlVvKPAwf1xsFG5NMuERH9qHza5TrbV/V3LBGtkssuERER0VKZ+YiIiIiWysxHREREtFSSj4iIiGipJB8RERHRUkk+IiIioqWSfERERERL/f8OsnHRBYD41wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_var_imp = pd.DataFrame({\"feature\": X_train_encoded.columns, \n",
    "                           \"importance\": clf_gb.feature_importances_})\n",
    "df_var_imp.sort_values(by = \"importance\", ascending = False, inplace = True)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.barplot(x = \"importance\", y = \"feature\", data = df_var_imp.head(10), color = \"lightblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now score the training and test sets with the trained model from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = clf_gb.predict(X_train_encoded)\n",
    "Y_hat_test = clf_gb.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the accuracy scores in either case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "acc_test = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we store the results in the same `results` table as bofere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = str(clf_gb.__class__).split('.')[-1].strip(\"\\\"\\'>\")\n",
    "results.loc[len(results), 0:3] = [model_name, acc_train, acc_test]\n",
    "\n",
    "for hp in hypers.keys():\n",
    "    results.loc[len(results) - 1, hp] = hypers[hp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.865852</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.865698</td>\n",
       "      <td>0.861679</td>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.838856</td>\n",
       "      <td>0.838093</td>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.955929</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         algo acc_train  acc_test  n_estimators max_features  \\\n",
       "0      RandomForestClassifier  0.865852  0.861126         100.0         sqrt   \n",
       "1      RandomForestClassifier  0.865698  0.861679         200.0         sqrt   \n",
       "2      RandomForestClassifier  0.838856  0.838093         200.0         sqrt   \n",
       "3  GradientBoostingClassifier  0.955929  0.823537         100.0         sqrt   \n",
       "\n",
       "   max_depth  min_samples_leaf  learning_rate  \n",
       "0       20.0              10.0            NaN  \n",
       "1       20.0              10.0            NaN  \n",
       "2        5.0              10.0            NaN  \n",
       "3       20.0              10.0            0.5  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\"n_estimators\": 100, \"max_features\": \"sqrt\", \"max_depth\": 3, \"min_samples_leaf\": 10, \"learning_rate\": 0.8}\n",
    "model = GradientBoostingClassifier(loss = 'deviance', **hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the `train_evaluate.py` script using the new hyper-parameters values. We can run an external Python script from inside the notebook using the `%run` magic. It is important to use the `-i` switch (stands for interactive), which runs the script using the **same** Python session that the notebook is hosting. Without the `-i` switch, the script would run in a new Python session and would not be aware of the variables we are providing above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i train_evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.865852</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.865698</td>\n",
       "      <td>0.861679</td>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.838856</td>\n",
       "      <td>0.838093</td>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.955929</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.98231</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.88434</td>\n",
       "      <td>0.867207</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.922822</td>\n",
       "      <td>0.864566</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.93956</td>\n",
       "      <td>0.854616</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.936642</td>\n",
       "      <td>0.854677</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.898068</td>\n",
       "      <td>0.863092</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.901846</td>\n",
       "      <td>0.858363</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.873775</td>\n",
       "      <td>0.864443</td>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          algo acc_train  acc_test  n_estimators max_features  \\\n",
       "0       RandomForestClassifier  0.865852  0.861126         100.0         sqrt   \n",
       "1       RandomForestClassifier  0.865698  0.861679         200.0         sqrt   \n",
       "2       RandomForestClassifier  0.838856  0.838093         200.0         sqrt   \n",
       "3   GradientBoostingClassifier  0.955929  0.823537         100.0         sqrt   \n",
       "4   GradientBoostingClassifier   0.98231  0.851852         100.0         sqrt   \n",
       "5   GradientBoostingClassifier   0.88434  0.867207         100.0         sqrt   \n",
       "6   GradientBoostingClassifier  0.922822  0.864566         100.0         sqrt   \n",
       "7   GradientBoostingClassifier   0.93956  0.854616         100.0         sqrt   \n",
       "8   GradientBoostingClassifier  0.936642  0.854677         100.0         sqrt   \n",
       "9   GradientBoostingClassifier  0.898068  0.863092         100.0         sqrt   \n",
       "10  GradientBoostingClassifier  0.901846  0.858363         100.0         sqrt   \n",
       "11  GradientBoostingClassifier  0.873775  0.864443         100.0         sqrt   \n",
       "\n",
       "    max_depth  min_samples_leaf  learning_rate  \n",
       "0        20.0              10.0            NaN  \n",
       "1        20.0              10.0            NaN  \n",
       "2         5.0              10.0            NaN  \n",
       "3        20.0              10.0            0.5  \n",
       "4        20.0              10.0            0.4  \n",
       "5         5.0              10.0            0.4  \n",
       "6        10.0              10.0            0.4  \n",
       "7        10.0              10.0            0.7  \n",
       "8        10.0              10.0            0.6  \n",
       "9         6.0              10.0            0.6  \n",
       "10        6.0              10.0            0.8  \n",
       "11        3.0              10.0            0.8  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to the two classifiers we trained above and change the hyper-parametrs and train at least 10 different random forest and 10 different gradient boosted classfiers. Make sure to store all the training runs in the `results` table. Once you have all the runs, find the best model you have and report its accuracy and state your choice of hyper-parametrs. We will compare this with everyone else in class to see who got the best model.\n",
    "\n",
    "Before you begin, recall that bagged learners like random forests reduce variance, so we want their **base-learner** to be more likely overfit (**high variance**). On the other hand, boosted learners like gradient boosted trees reduce bias, so we want their **base-learners** to be more likely to underfit (**high bias**). So your choice of hyper-parameters for the base-learners (decision trees) in each case should reflect this tendency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easy, we're already pasted the cells for you here. Run the next two cells 10 times (after changing `hypers` every time) and you will train 10 different **random forests**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dtree_grid_search(X,y,nfolds, criteria):\n",
    "    param_grid = { 'max_depth': np.arange(3, 15), 'min_samples_leaf':np.arange(2, 6)}\n",
    "    # decision tree model\n",
    "    \n",
    "    dtree_model=DecisionTreeClassifier(criterion=criteria)\n",
    "    #use gridsearch to test all values\n",
    "    dtree_gscv = GridSearchCV(dtree_model, param_grid, cv=nfolds)\n",
    "    #fit model to data\n",
    "    dtree_gscv.fit(X, y)\n",
    "    \n",
    "    return dtree_gscv.best_params_\n",
    "\n",
    "def report_best(X, y, X_tst, y_tst, nfolds, criteria, lbls):    \n",
    "    best_params = dtree_grid_search(X, y, nfolds, criteria)\n",
    "    print(f'Best Params: {best_params}')\n",
    "    classifier = DecisionTreeClassifier(criterion=criteria, \n",
    "                                               max_depth=best_params['max_depth'], \n",
    "                                               min_samples_leaf=best_params['min_samples_leaf'])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_ent_pred = classifier.predict(X_tst)\n",
    "    print(\"Entropy accuracy is : {}%\".format(accuracy_score(y_tst, y_ent_pred)*100))\n",
    "    print(classification_report(y_tst, y_ent_pred, target_names=lbls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "hypers = {\"n_estimators\": [100], \"max_features\": [\"sqrt\", \"log2\"], \"max_depth\": np.arange(3,10), \"min_samples_leaf\": np.arange(4,10)}\n",
    "model = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
    "dtree_gscv = GridSearchCV(model, hypers, cv=5)\n",
    "dtree_gscv.fit(X_train_encoded, Y_train)\n",
    "\n",
    "print(dtree_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hypers = {\"n_estimators\": 200, \"max_features\": \"sqrt\", \"max_depth\": 20, \"min_samples_leaf\": 10}\n",
    "model = RandomForestClassifier(random_state = 0, **hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i train_evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next two cells 10 times (after changing `hypers` every time) and you will train 10 different **gradient boosted trees**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\"n_estimators\": 100, \"max_features\": \"sqrt\", \"max_depth\": 20, \"min_samples_leaf\": 10, \"learning_rate\": 0.5}\n",
    "model = GradientBoostingClassifier(loss = 'deviance', **hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i train_evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're done with your runs, you can check all the results by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you check the classifier's documentation and understand what `n_estimators`, `max_features`, `max_depth`, and `min_leaf_size` represent. Then, answer the following question:\n",
    "\n",
    "- What seems to be the effect of changing each of these hyper-parameters on the accuracy of the training and test data?\n",
    "- Does this match your intuition about how these hyper-parameters work?\n",
    "- Are there any hyper-parameters that seem promising and worth trying to tune?\n",
    "\n",
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning can be a very time-consuming and difficult task. In a future lecture, we will see how we can use a Python library to automatically specify different hyper-parameter values ahead of time and train different models. This will save us from having to manually re-run external scripts or collect results, but for now this will suffice and it's also a chance to show-case some more advanced Python and Jupyter functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a non-tree-based ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finish this notebook by providing an example of a non-tree-based classifier. Tree-based classifiers are so common that they have their own functions in `sklearn`, but if we want we can choose any base-learners and pass it to the `BaggingClassifier` or any of the other ensemble learners in `sklearn.ensemble`. In the following example, we use `KNeighborsClassifier` as the base learner and train a bagged classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "bag_cls = BaggingClassifier(KNeighborsClassifier(), max_samples = 0.5, max_features = 0.5)\n",
    "bag_cls.fit(X_train_encoded, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can let the classifier predict on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = bag_cls.predict(X_train_encoded)\n",
    "Y_hat_test = bag_cls.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And obtain just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = accuracy_score(Y_train, Y_hat_train)\n",
    "acc_test = accuracy_score(Y_test.str.replace(\"\\\\.$\", \"\"), Y_hat_test)\n",
    "\n",
    "print(\"Accuracy on training data = {:.02} and on test data = {:.02}\".format(acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ensemble classifiers are a great method to improve accuracy if we're willing to pay the computational cost. Another downside as we saw in this notebook is that we add new hyper-parameters on top of the ones we inherit from the base learner and hyper-parameter tuning becomes a daunting task. In fact, one of the short-comings in this notebook is that we did our hyper-parameter tuning on the **test data** when we should have used a **validation data** instead. If we try a few different runs we can get away with this, but if we get serious about hyper-parameter tuning then as we learned the right way to do it is to evaluate the hyper-parameters on the **validation data** (or to use cross-validation) and leave the **test data** to evaluate the accuracy of the **final model** at the end."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
