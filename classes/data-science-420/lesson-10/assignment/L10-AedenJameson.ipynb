{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 10 (or Milestone NUMBER)\n",
    "# Aeden Jameson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Assignments & Milestones\n",
    "\n",
    "- <b>Break the assignment into sections - one section per numbered requirement.</b> Each assignment has numbered requirements/instructions e.g. \"1. Read the CIFAR-10 dataset\". Each requirement should have at least one markdown cell and at least one code cell. Feel free to combine sections or make other sensible changes if that makes sense for your code and is still clear. The intent is to give you a useful structure and to make sure you get full credit for your work.\n",
    "\n",
    "- <b>Break the milestone into sections - one section for each item in the rubric.</b> Each milestone has rubric items e.g. \"5. Handle class imbalance problem\". Each rubric item should have at least one markdown cell and at least one code cell. Feel free to combine sections or make other sensible changes if that makes sense for your code and is still clear. The intent is to give you a useful structure and to make sure you get full credit for your work.\n",
    "\n",
    "- <b>Include comments, with block comments preferred over in-line comments.</b> A good habit is to start each code cell with comments.\n",
    "\n",
    "The above put into a useful pattern:\n",
    "\n",
    "<b>Markdown cell:</b> Requirement #1: Read the CIFAR-10 dataset<br>\n",
    "<b>Code cell:</b>: Comments followed by code<br>\n",
    "<b>Markdown cell:</b> Requirement #2: Explore the data<br>\n",
    "<b>Code cell:</b>: Comments followed by code<br>\n",
    "<b>Markdown cell:</b> Requirement #3: Preprocess the data and prepare for classification<br>\n",
    "<b>Code cell:</b>: Comments followed by code<br>\n",
    "\n",
    "For more information:\n",
    "- A good notebook example: [DataFrame Basics](https://github.com/Tanu-N-Prabhu/Python/blob/master/Pandas/Pandas_DataFrame.ipynb) \n",
    "- More example notebooks: [A gallery of interesting Jupyter Notebooks](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks#pandas-for-data-analysis)\n",
    "- [PEP 8 on commenting](https://www.python.org/dev/peps/pep-0008/)\n",
    "- [PEP 257 - docstrings](https://www.python.org/dev/peps/pep-0257/)\n",
    "\n",
    "Occasionally an assignment or milestone will ask you to do something other than write Python code e.g. ask you turn in a .docx file. In which case, please use logical structuring, but the specific notes above may not apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 516.2 MB 8.9 kB/s eta 0:00:014    |█                               | 16.0 MB 12.7 MB/s eta 0:00:40     |█                               | 16.8 MB 12.7 MB/s eta 0:00:40     |█                               | 17.5 MB 12.7 MB/s eta 0:00:40     |█▏                              | 18.9 MB 12.7 MB/s eta 0:00:40     |█▏                              | 19.5 MB 12.7 MB/s eta 0:00:39     |███                             | 47.7 MB 13.2 MB/s eta 0:00:36     |███▏                            | 51.3 MB 13.2 MB/s eta 0:00:36     |███▏                            | 51.8 MB 13.2 MB/s eta 0:00:36     |████▊                           | 75.9 MB 5.9 MB/s eta 0:01:15     |█████▏                          | 83.2 MB 6.4 MB/s eta 0:01:08     |███████▋                        | 122.1 MB 10.9 MB/s eta 0:00:37     |████████▎                       | 133.0 MB 12.3 MB/s eta 0:00:32     |████████▋                       | 138.7 MB 11.9 MB/s eta 0:00:32\n",
      "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.2.1-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.29.0-cp37-cp37m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.11.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.0.0.post20200311)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)\n",
      "\u001b[K     |████████████████████████████████| 777 kB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.17.2-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 5.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.25.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.5.0)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.0-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3\"\n",
      "  Downloading rsa-4.6-py2.py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: absl-py, termcolor, wrapt\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=a98ad80e291abfdcda5303fc18fba02f9c5b7c009cbd906a33a701281ca4b2a2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=edd8dc0222496da7778921804cda78f06b747484dd38f656b45760c34c5a1eb4\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70927 sha256=fd231370f3053796aeae3e91840459e9f808c090a29ebbcd156edb0f67d33074\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "Successfully built absl-py termcolor wrapt\n",
      "Installing collected packages: astunparse, absl-py, keras-preprocessing, grpcio, requests-oauthlib, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, werkzeug, tensorboard-plugin-wit, markdown, tensorboard, opt-einsum, tensorflow-estimator, termcolor, gast, google-pasta, wrapt, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 gast-0.3.3 google-auth-1.17.2 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.29.0 keras-preprocessing-1.1.2 markdown-3.2.2 opt-einsum-3.2.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.2.2 tensorboard-plugin-wit-1.6.0.post3 tensorflow-2.2.0 tensorflow-estimator-2.2.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "plt.rc('font', size=14) \n",
    "\n",
    "def decode_wire(wire, lookup):\n",
    "    return ' '.join([lookup[i] for i in wire])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read & Explore Reuters dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded...\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.reuters.load_data(num_words=max_features)\n",
    "print('Loaded...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded...\n"
     ]
    }
   ],
   "source": [
    "words = tf.keras.datasets.reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "word_lookup = {value: key for key, value in words.items()}\n",
    "print('Loaded...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data dimensions: (8982,)\n",
      "Test data dimensions: (2246,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data dimensions: {}\".format(X_train.shape))\n",
    "print(\"Test data dimensions: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the wattie nondiscriminatory mln loss for plc said at only ended said commonwealth could 1 traders now april 0 a after said from 1985 and from foreign 000 april 0 prices its account year a but in this mln home an states earlier and rise and revs vs 000 its 16 vs 000 a but 3 psbr oils several and shareholders and dividend vs 000 its all 4 vs 000 1 mln agreed largely april 0 are 2 states will billion total and against 000 pct dlrs'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_wire(X_train[0], word_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For index 1 the word is \"the\".\n",
      "For index 2 the word is \"of\".\n",
      "For index 3 the word is \"to\".\n",
      "For index 4 the word is \"in\".\n",
      "For index 5 the word is \"said\".\n",
      "For index 6 the word is \"and\".\n",
      "For index 7 the word is \"a\".\n",
      "For index 8 the word is \"mln\".\n",
      "For index 9 the word is \"3\".\n",
      "For index 10 the word is \"for\".\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"For index {i+1} the word is \\\"{word_lookup[i+1]}\\\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad Wires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pad the wires, but where do we cut it off. Let's explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Length of Wires')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wire_lens = np.array([len(i) for i in X_train])\n",
    "_ = plt.hist(wire_lens, bins='auto')\n",
    "plt.title(\"Length of Wires\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(wire_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2376"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(wire_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Padding...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_wire_length = 300\n",
    "X_train_padded = pad_sequences(X_train, maxlen = max_wire_length)\n",
    "X_test_padded = pad_sequences(X_test, maxlen = max_wire_length)\n",
    "\n",
    "print('Done Padding...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    1    2    2    8   43   10  447    5   25  207  270\n",
      "    5 3095  111   16  369  186   90   67    7   89    5   19  102    6\n",
      "   19  124   15   90   67   84   22  482   26    7   48    4   49    8\n",
      "  864   39  209  154    6  151    6   83   11   15   22  155   11   15\n",
      "    7   48    9 4579 1005  504    6  258    6  272   11   15   22  134\n",
      "   44   11   15   16    8  197 1245   90   67   52   29  209   30   32\n",
      "  132    6  109   15   17   12]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Encoding...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(y_train)\n",
    "one_hot_test_labels = to_categorical(y_test)\n",
    "\n",
    "print('Done Encoding...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 300, 64)           640000    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 46)                1518      \n",
      "=================================================================\n",
      "Total params: 653,934\n",
      "Trainable params: 653,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_one = keras.models.Sequential()\n",
    "model_one.add(keras.layers.Embedding(max_features, 64, input_length = max_wire_length))\n",
    "model_one.add(keras.layers.LSTM(32))\n",
    "model_one.add(keras.layers.Dense(46, activation = 'softmax'))\n",
    "model_one.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model_one.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "71/71 [==============================] - 11s 154ms/step - loss: 3.0010 - accuracy: 0.3354 - val_loss: 2.4540 - val_accuracy: 0.3620\n",
      "Epoch 2/2\n",
      "71/71 [==============================] - 10s 147ms/step - loss: 2.3766 - accuracy: 0.3517 - val_loss: 2.2855 - val_accuracy: 0.3620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f169e2f6790>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_one.fit(X_train_padded, one_hot_train_labels, validation_data = (X_test_padded, one_hot_test_labels), epochs = 2, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 2s 23ms/step - loss: 2.2855 - accuracy: 0.3620\n",
      "Accuracy: 36.20%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "scores = model_one.evaluate(X_test_padded, one_hot_test_labels)\n",
    "print(\"Accuracy: {:.2f}%\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - Increase Epochs from 2 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 300, 64)           640000    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 46)                1518      \n",
      "=================================================================\n",
      "Total params: 653,934\n",
      "Trainable params: 653,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_two = keras.models.Sequential()\n",
    "model_two.add(keras.layers.Embedding(max_features, 64, input_length = max_wire_length))\n",
    "model_two.add(keras.layers.LSTM(32))\n",
    "model_two.add(keras.layers.Dense(46, activation = 'softmax'))\n",
    "model_two.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model_two.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "71/71 [==============================] - 11s 155ms/step - loss: 2.9924 - accuracy: 0.3369 - val_loss: 2.4099 - val_accuracy: 0.3620\n",
      "Epoch 2/5\n",
      "71/71 [==============================] - 11s 154ms/step - loss: 2.1928 - accuracy: 0.4316 - val_loss: 2.0730 - val_accuracy: 0.4711\n",
      "Epoch 3/5\n",
      "71/71 [==============================] - 12s 165ms/step - loss: 1.9129 - accuracy: 0.5045 - val_loss: 1.8044 - val_accuracy: 0.5307\n",
      "Epoch 4/5\n",
      "71/71 [==============================] - 12s 166ms/step - loss: 1.7287 - accuracy: 0.5587 - val_loss: 1.7393 - val_accuracy: 0.5646\n",
      "Epoch 5/5\n",
      "71/71 [==============================] - 11s 155ms/step - loss: 1.6053 - accuracy: 0.5871 - val_loss: 1.7106 - val_accuracy: 0.5614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f163e321710>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_two.fit(X_train_padded, one_hot_train_labels, validation_data = (X_test_padded, one_hot_test_labels), epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 2s 22ms/step - loss: 1.7106 - accuracy: 0.5614\n",
      "Accuracy: 56.14%\n"
     ]
    }
   ],
   "source": [
    "scores = model_two.evaluate(X_test_padded, one_hot_test_labels)\n",
    "print(\"Accuracy: {:.2f}%\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 512)               5120512   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 46)                23598     \n",
      "=================================================================\n",
      "Total params: 5,144,110\n",
      "Trainable params: 5,144,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_three = keras.models.Sequential()\n",
    "model_three.add(keras.layers.Embedding(max_features, 64, input_length = max_wire_length))\n",
    "model_three.add(keras.layers.SimpleRNN(64, return_sequences=True))\n",
    "model_three.add(keras.layers.SimpleRNN(64, return_sequences=True))\n",
    "model_three.add(keras.layers.SimpleRNN(64, return_sequences=True))\n",
    "model_three.add(keras.layers.LSTM(64))\n",
    "model_three.add(keras.layers.Dense(46, activation = 'softmax'))\n",
    "model_three.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model_three.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_23 is incompatible with the layer: expected axis -1 of input shape to have value 10000 but received input with shape [None, 300]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-6d6315c1ed21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_three\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_test_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_23 is incompatible with the layer: expected axis -1 of input shape to have value 10000 but received input with shape [None, 300]\n"
     ]
    }
   ],
   "source": [
    "model_three.fit(X_train_padded, one_hot_train_labels, validation_data = (X_test_padded, one_hot_test_labels), epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 6s 82ms/step - loss: 2.0383 - accuracy: 0.4622\n",
      "Accuracy: 46.22%\n"
     ]
    }
   ],
   "source": [
    "scores = model_three.evaluate(X_test_padded, one_hot_test_labels)\n",
    "print(\"Accuracy: {:.2f}%\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Describe & Explain Your Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Model 2 had the highest accuracy of 56%. I would have liked try more networks, but I kept getting \"layer incompatibility errors\" that I wasn't sure how to address. Hopefully I'll learn more about this stuff in future courses and books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
