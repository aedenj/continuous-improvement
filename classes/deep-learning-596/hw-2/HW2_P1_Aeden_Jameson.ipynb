{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1i05kmE7NXz"
   },
   "source": [
    "## **Homework 2** Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bP-Ag-y17Epj"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMljKOak7Epo"
   },
   "source": [
    "### (a) Multilayer Perceptron (MLP)\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a ``torch.Tensor``.\n",
    "\n",
    "For vision, PyTorch has a package called ``torchvision``, \n",
    "that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz., ``torchvision.datasets`` \n",
    "and ``torch.utils.data.DataLoader``.\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLYLJR0eCoEb"
   },
   "source": [
    "Load MNIST dataset using `torchvision.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DM7f0ejmCsGa"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_185/4026725785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "mnist_trainset = ...  # TODO: use built-in functions to load MNIST dataset\n",
    "mnist_testset = ...   # TODO: use built-in functions to load MNIST dataset\n",
    "print(\"Print the training dataset:\\n \", mnist_trainset)\n",
    "print(\"Print the testing dataset:\\n \", mnist_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JW-d8ox1GmfO"
   },
   "source": [
    "Visualize dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzqWf9rlEkr_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize = (12, 12))\n",
    "plt.gray()\n",
    "\n",
    "# loop through subplots and add mnist images\n",
    "for i, ax in enumerate(axs.flat):\n",
    "  ax.imshow(mnist_trainset[i][0][0], cmap=cm.gray_r)\n",
    "  ax.axis('off')\n",
    "  ax.set_title('Number {}'.format(mnist_trainset[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q73_y-qMJhbm"
   },
   "source": [
    "Create dataloader for neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xni7h1blGye3"
   },
   "outputs": [],
   "source": [
    "train_loader = ...  # TODO: create dataloader from dataset\n",
    "test_loader = ...   # TODO: create dataloader from dataset\n",
    "print(train_loader)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSbKnVwZKhtd"
   },
   "source": [
    "Iterate through the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ge_rVirSKlFR"
   },
   "outputs": [],
   "source": [
    "for batch_id, (data, label) in enumerate(train_loader):\n",
    "  print('batch_id:', batch_id)\n",
    "  print(data.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fj3L0DrOM88X"
   },
   "source": [
    "Follow the above instructions on MNIST dataset, write code to load and visualize the CIFAR-10 dataset in the similar manner.\n",
    "\n",
    "CIFAR-10 dataset has the classes (listed below): ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size $3 \\times 32 \\times 32$, i.e. 3-channel color images of $32 \\times 32$ pixels in size. \n",
    "\n",
    "<h4>Note:</h4>\n",
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqnizXadNh8b"
   },
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', \n",
    "           'ship', 'truck')\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# TODO: load the CIFAR-10 dataset and build dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igESHithODja"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "def cifar_imshow(img):\n",
    "  img = img / 2 + 0.5     # unnormalize\n",
    "  npimg = img.numpy()\n",
    "  return np.transpose(npimg, (1, 2, 0))\n",
    "\n",
    "# TODO: visualize some samples in the CIFAR-10 dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQOoObWBSiKg"
   },
   "source": [
    "Define an MLP neural network to do classification on CIFAR-10 dataset. \n",
    "To feed the data into the MLP, each image with dim of $3 \\times 32 \\times 32$ needs to be flatten into a vector with dim of $3072$.\n",
    "\n",
    "Just like how you transfer a Tensor onto the GPU, you transfer the neural net onto the GPU. Let's first define our device as the first visible cuda device if we have CUDA available.\n",
    "\n",
    "**Note**: remember to keep the logs of training the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvbWQt2Qv28G"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHGFYOm8emtA"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MLP, self).__init__()\n",
    "    # TODO: define your MLP\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO: define your forward function\n",
    "    return x\n",
    "\n",
    "mlp = MLP().to(device)  # operate on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkkNxVUz7Ep1"
   },
   "source": [
    "Define a loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6_ABQ1DfJgg"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# TODO: you can change loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_axZ2tOWfe-Z"
   },
   "source": [
    "Train the network. \n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8MgioYvfhXb"
   },
   "outputs": [],
   "source": [
    "n_epoch = 5\n",
    "\n",
    "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
    "  for i, data in enumerate(train_loader, 0):\n",
    "    # TODO: write training code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0CP36AOgCQR"
   },
   "source": [
    "Save the trained model. \n",
    "See [here](https://pytorch.org/docs/stable/notes/serialization.html)\n",
    "for more details on saving PyTorch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spe6mioOgFPq"
   },
   "outputs": [],
   "source": [
    "PATH = './mlp_cifar10.pth'\n",
    "torch.save(mlp.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohEOKpQh7EqA"
   },
   "source": [
    "Load back in our saved model. (Note: saving and re-loading the model\n",
    "wasn't necessary here, we only did it to illustrate how to do so)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdW5-7Rf7EqA"
   },
   "outputs": [],
   "source": [
    "mlp = MLP().to(device)\n",
    "mlp.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Afw7lYRFg71p"
   },
   "source": [
    "Evaluate the classfication performance on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqMt1tBihA0E"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    # TODO: write testing code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeOA4vRbV3Pq"
   },
   "source": [
    "### (c) Convolution Neural Network (CNN)\n",
    "\n",
    "Define a CNN to do classification on CIFAR-10 dataset. You can build a CNN from the previous PyTorch tutorial code and modify it to take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "**Note**: remember to keep the logs of training the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzXPX4rm7Epz"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    # TODO: define your CNN\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO: define your forward function  \n",
    "    return x\n",
    "\n",
    "cnn = CNN().to(device)  # operate on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfi4oC0bhHxg"
   },
   "source": [
    "Define a loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIikPKNI7Ep2"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# TODO: you can change loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzvExFSVhL3x"
   },
   "source": [
    "Train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWjbkl5o7Ep5"
   },
   "outputs": [],
   "source": [
    "n_epoch = 5\n",
    "\n",
    "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
    "  for i, data in enumerate(train_loader, 0):\n",
    "    # TODO: write training code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXp2X4wVhfiP"
   },
   "source": [
    "Save the trained model. (Do not upload your trained model to Canvas.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG1JzHWp7Ep8"
   },
   "outputs": [],
   "source": [
    "PATH = './weights/cnn_cifar10.pth'\n",
    "torch.save(cnn.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RGeRQxR7EqG"
   },
   "source": [
    "Evaluate the classfication performance on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IERp19p7EqH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAW5JJHL1ufz"
   },
   "source": [
    "### (d) Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frupe8HZ1ylk"
   },
   "source": [
    "Write your answers here."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_P1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
