{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYSR4-wK6bp3"
   },
   "source": [
    "# HW3 Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjCV8OFc6awr"
   },
   "source": [
    "The goal of domain adaptation is to transfer the knowledge of a model to a different but related data distribution. The model is trained on a source dataset and applied to a target dataset (usually unlabeled). For Problem 3, the model will be trained on regular MNIST images, but we want to get good performance on MNIST with random color (without any labels).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfinfRb16fT_"
   },
   "source": [
    "**Problem Statement** Given a labelled source domain (MNIST) and an unlabelled target domain (MNIST-M). We would like to train a classifier or a predictor which would give accurate predictions on the target domain. \n",
    "\n",
    "**Assumptions** Probability distribution of source domain is not equal to the probability distribution of target domain. The conditional probability distribution of the labels given an instance from the source domain is equal to the conditional probability distribution of the labels given an instance from the target domain. Source dataset is labelled. Target dataset is unlabelled.\n",
    "\n",
    "**Approach** Here, we adopt the DABP method mentioned in the paper “Unsupervised Domain Adaptation by Backpropagation”.\n",
    "\n",
    "* Feature Extractor (green): This is a neural network that will learn to perform the transformation on the source and target distribution. \n",
    "* Label Classifier (blue): This is a neural network that will learn to perform the classification on the transformed source distribution. Since, the source domain is labelled. \n",
    "* Domain Classifier (red): This is a neural network that will predict whether the output of the Feature Extractor is from the source distribution or the target distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YpTheb-6u87"
   },
   "source": [
    "By using the above three components, the Feature Extractor will learn to produce discriminative and domain-invariant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBRRrvrf66BP"
   },
   "source": [
    "Follow the instructions in `HW3_P3.ipynb` to download the pre-processed MNIST and MNIST-M dataset and visualize some examples. \n",
    "\n",
    "\n",
    "The details of the implementation are also introduced in `HW3_P3.ipynb`. Please read it carefully before working on this problem. The implementation of the DABP includes the following components (please follow the provided sample codes): \n",
    "* MNIST and MNITS-M DataLoader\n",
    "* Feature Extractor \n",
    "* Label and Domain Classifier\n",
    "* Gradient Reversal Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1491,
     "status": "ok",
     "timestamp": 1604001274218,
     "user": {
      "displayName": "Haotian Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNL08CVQSt0awNVIEmOH4s-XUIgq0jFGlfWIIG=s64",
      "userId": "11729683938836141639"
     },
     "user_tz": 360
    },
    "id": "Ki1QDNkZ7AKN",
    "outputId": "e0239e74-1a85-4fe6-aedf-dabd2ac321ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Pytorch_DABP'...\n",
      "remote: Enumerating objects: 16, done.\u001b[K\n",
      "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 16 (delta 0), reused 12 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (16/16), done.\n"
     ]
    }
   ],
   "source": [
    "# download the codes from Git\n",
    "!git clone https://github.com/Haotian-Zhang/Pytorch_DABP.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUHlfPzg7W36"
   },
   "source": [
    "Train the DABP model by running `main.py` and answer the following questions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4ypSoWm7Z2b"
   },
   "source": [
    "* Q1: Perform **3** experiments on training and report your source and target accuracy in the tables below. (Your result is the average of the Target Accs. based on 3 experiments)\n",
    "\n",
    "|                | Test1 | Test2 | Test3 |\n",
    "|----------------|:-----:|:-----:|:-----:|\n",
    "| Source Acc (%) |  ...  |       |       |\n",
    "| Target Acc (%) |  ...  |       |       |\n",
    "\n",
    "|          | Paper | Your Result |\n",
    "|----------|:-----:|:-----------:|\n",
    "| DABP (%) | 52.25 |     ...     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113006,
     "status": "ok",
     "timestamp": 1604001617866,
     "user": {
      "displayName": "Haotian Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNL08CVQSt0awNVIEmOH4s-XUIgq0jFGlfWIIG=s64",
      "userId": "11729683938836141639"
     },
     "user_tz": 360
    },
    "id": "m2q1c6o2UvJv",
    "outputId": "33f6c2b2-ad6c-4b2e-8692-c3b9cfa06f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/pytorch/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "9920512it [00:01, 7527306.97it/s]                 \n",
      "Extracting data/pytorch/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to data/pytorch/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/pytorch/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "32768it [00:00, 132581.31it/s]\n",
      "Extracting data/pytorch/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to data/pytorch/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/pytorch/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "1654784it [00:00, 2546779.61it/s]               \n",
      "Extracting data/pytorch/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to data/pytorch/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/pytorch/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "8192it [00:00, 43429.68it/s]\n",
      "Extracting data/pytorch/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/pytorch/MNIST/MNIST/raw\n",
      "Processing...\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "Done!\n",
      "Downloading https://github.com/VanushVaswani/keras_mnistm/releases/download/1.0/keras_mnistm.pkl.gz\n",
      "Processing...\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "9920512it [00:00, 10085161.85it/s]                \n",
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "32768it [00:00, 115117.35it/s]\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "1654784it [00:00, 2445450.26it/s]               \n",
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "8192it [00:00, 48248.71it/s]\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n",
      "MNISTM Done!\n",
      "Running GPU : 0\n",
      "Source-only training\n",
      "Epoch : 0\n",
      "/content/Pytorch_DABP/model.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n",
      "[1568/60000 (3%)]\tClass Loss: 2.298589\n",
      "[3168/60000 (6%)]\tClass Loss: 2.297021\n",
      "[4768/60000 (9%)]\tClass Loss: 2.258317\n",
      "[6368/60000 (12%)]\tClass Loss: 2.122027\n",
      "[7968/60000 (14%)]\tClass Loss: 2.099762\n",
      "[9568/60000 (17%)]\tClass Loss: 1.990219\n",
      "[11168/60000 (20%)]\tClass Loss: 1.784783\n",
      "[12768/60000 (23%)]\tClass Loss: 1.713689\n",
      "[14368/60000 (26%)]\tClass Loss: 1.813060\n",
      "[15968/60000 (29%)]\tClass Loss: 1.673084\n",
      "[17568/60000 (32%)]\tClass Loss: 1.719666\n",
      "[19168/60000 (35%)]\tClass Loss: 1.655721\n",
      "[20768/60000 (38%)]\tClass Loss: 1.731506\n",
      "[22368/60000 (41%)]\tClass Loss: 1.744247\n",
      "[23968/60000 (44%)]\tClass Loss: 1.663994\n",
      "[25568/60000 (46%)]\tClass Loss: 1.657419\n",
      "[27168/60000 (49%)]\tClass Loss: 1.567958\n",
      "[28768/60000 (52%)]\tClass Loss: 1.728017\n",
      "[30368/60000 (55%)]\tClass Loss: 1.650851\n",
      "[31968/60000 (58%)]\tClass Loss: 1.607567\n",
      "[33568/60000 (61%)]\tClass Loss: 1.555709\n",
      "[35168/60000 (64%)]\tClass Loss: 1.710140\n",
      "[36768/60000 (67%)]\tClass Loss: 1.647452\n",
      "[38368/60000 (70%)]\tClass Loss: 1.755668\n",
      "[39968/60000 (73%)]\tClass Loss: 1.577430\n",
      "[41568/60000 (76%)]\tClass Loss: 1.640570\n",
      "[43168/60000 (78%)]\tClass Loss: 1.758929\n",
      "[44768/60000 (81%)]\tClass Loss: 1.785868\n",
      "[46368/60000 (84%)]\tClass Loss: 1.667105\n",
      "[47968/60000 (87%)]\tClass Loss: 1.739028\n",
      "[49568/60000 (90%)]\tClass Loss: 1.720179\n",
      "[51168/60000 (93%)]\tClass Loss: 1.657764\n",
      "[52768/60000 (96%)]\tClass Loss: 1.679976\n",
      "[54368/60000 (99%)]\tClass Loss: 1.644307\n",
      "Epoch : 1\n",
      "[1568/60000 (3%)]\tClass Loss: 1.682398\n",
      "[3168/60000 (6%)]\tClass Loss: 1.743530\n",
      "[4768/60000 (9%)]\tClass Loss: 1.661338\n",
      "[6368/60000 (12%)]\tClass Loss: 1.617723\n",
      "[7968/60000 (14%)]\tClass Loss: 1.619110\n",
      "[9568/60000 (17%)]\tClass Loss: 1.715601\n",
      "[11168/60000 (20%)]\tClass Loss: 1.536389\n",
      "[12768/60000 (23%)]\tClass Loss: 1.618487\n",
      "[14368/60000 (26%)]\tClass Loss: 1.742220\n",
      "[15968/60000 (29%)]\tClass Loss: 1.707594\n",
      "[17568/60000 (32%)]\tClass Loss: 1.667358\n",
      "[19168/60000 (35%)]\tClass Loss: 1.878894\n",
      "[20768/60000 (38%)]\tClass Loss: 1.647106\n",
      "[22368/60000 (41%)]\tClass Loss: 1.706608\n",
      "[23968/60000 (44%)]\tClass Loss: 1.741006\n",
      "[25568/60000 (46%)]\tClass Loss: 1.678303\n",
      "[27168/60000 (49%)]\tClass Loss: 1.668398\n",
      "[28768/60000 (52%)]\tClass Loss: 1.642731\n",
      "[30368/60000 (55%)]\tClass Loss: 1.676881\n",
      "[31968/60000 (58%)]\tClass Loss: 1.666258\n",
      "[33568/60000 (61%)]\tClass Loss: 1.769761\n",
      "[35168/60000 (64%)]\tClass Loss: 1.587945\n",
      "[36768/60000 (67%)]\tClass Loss: 1.645602\n",
      "[38368/60000 (70%)]\tClass Loss: 1.616285\n",
      "[39968/60000 (73%)]\tClass Loss: 1.748835\n",
      "[41568/60000 (76%)]\tClass Loss: 1.688988\n",
      "[43168/60000 (78%)]\tClass Loss: 1.584281\n",
      "[44768/60000 (81%)]\tClass Loss: 1.831547\n",
      "[46368/60000 (84%)]\tClass Loss: 1.644149\n",
      "[47968/60000 (87%)]\tClass Loss: 1.645704\n",
      "[49568/60000 (90%)]\tClass Loss: 1.494524\n",
      "[51168/60000 (93%)]\tClass Loss: 1.667357\n",
      "[52768/60000 (96%)]\tClass Loss: 1.556703\n",
      "[54368/60000 (99%)]\tClass Loss: 1.552365\n",
      "Epoch : 2\n",
      "[1568/60000 (3%)]\tClass Loss: 1.820405\n",
      "[3168/60000 (6%)]\tClass Loss: 1.566142\n",
      "[4768/60000 (9%)]\tClass Loss: 1.748267\n",
      "[6368/60000 (12%)]\tClass Loss: 1.707193\n",
      "[7968/60000 (14%)]\tClass Loss: 1.693348\n",
      "[9568/60000 (17%)]\tClass Loss: 1.587516\n",
      "[11168/60000 (20%)]\tClass Loss: 1.554296\n",
      "[12768/60000 (23%)]\tClass Loss: 1.611282\n",
      "[14368/60000 (26%)]\tClass Loss: 1.585847\n",
      "[15968/60000 (29%)]\tClass Loss: 1.645376\n",
      "[17568/60000 (32%)]\tClass Loss: 1.563897\n",
      "[19168/60000 (35%)]\tClass Loss: 1.591685\n",
      "[20768/60000 (38%)]\tClass Loss: 1.615298\n",
      "[22368/60000 (41%)]\tClass Loss: 1.645398\n",
      "[23968/60000 (44%)]\tClass Loss: 1.679196\n",
      "[25568/60000 (46%)]\tClass Loss: 1.589822\n",
      "[27168/60000 (49%)]\tClass Loss: 1.690840\n",
      "[28768/60000 (52%)]\tClass Loss: 1.554806\n",
      "[30368/60000 (55%)]\tClass Loss: 1.645280\n",
      "[31968/60000 (58%)]\tClass Loss: 1.625548\n",
      "[33568/60000 (61%)]\tClass Loss: 1.800824\n",
      "[35168/60000 (64%)]\tClass Loss: 1.789137\n",
      "[36768/60000 (67%)]\tClass Loss: 1.680521\n",
      "[38368/60000 (70%)]\tClass Loss: 1.590001\n",
      "[39968/60000 (73%)]\tClass Loss: 1.694291\n",
      "[41568/60000 (76%)]\tClass Loss: 1.557318\n",
      "[43168/60000 (78%)]\tClass Loss: 1.590017\n",
      "[44768/60000 (81%)]\tClass Loss: 1.498506\n",
      "[46368/60000 (84%)]\tClass Loss: 1.574520\n",
      "[47968/60000 (87%)]\tClass Loss: 1.573715\n",
      "[49568/60000 (90%)]\tClass Loss: 1.562742\n",
      "[51168/60000 (93%)]\tClass Loss: 1.557074\n",
      "[52768/60000 (96%)]\tClass Loss: 1.584502\n",
      "[54368/60000 (99%)]\tClass Loss: 1.593885\n",
      "Save models ...\n",
      "Model is saved !!!\n",
      "Model test ...\n",
      "Test results on source_only :\n",
      "\n",
      "Source Accuracy: 48770/60000 (81.28%)\n",
      "Target Accuracy: 25234/60000 (42.06%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python Pytorch_DABP/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLFcP0xO876a"
   },
   "source": [
    "* Q2: Write your own codes to visualize the feature space by using the TSNE(perplexity=30, n_components=2, init=’pca’, n_iter=3000). Plot the feature distributions for both (1) original MNIST and MNIST-M inputs and (2) after DABP using source only. (**You will find useful functions inside the `utils`function.** )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTt-JFPK81ig"
   },
   "outputs": [],
   "source": [
    "# Your code here (You may use multiple code and text segments to display your solutions.)\n",
    "# Q1\n",
    "# ...\n",
    "# Q2\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOrPA+urLkr5EzseLu+V9Jm",
   "collapsed_sections": [],
   "name": "HW3P3_Domain_Adaptation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
