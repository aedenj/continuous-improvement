{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW4_P1_HPE.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9VHCAJrYrscT"},"source":["# **Homework 4** Problem 1"]},{"cell_type":"markdown","metadata":{"id":"4r61jPcerznI"},"source":["## (a) Prepare code and dataset"]},{"cell_type":"markdown","metadata":{"id":"hG7D__mMu1BQ"},"source":["### Download source code"]},{"cell_type":"code","metadata":{"id":"8vMsx2x-SuF6"},"source":["!git clone https://github.com/princeton-vl/pytorch_stacked_hourglass.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HxXSGFpu4d8"},"source":["### Download MPII dataset"]},{"cell_type":"code","metadata":{"id":"k_8xrPxaS8ky"},"source":["!wget https://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2A_56MkTifM"},"source":["!tar -xvzf mpii_human_pose_v1.tar.gz -C pytorch_stacked_hourglass/data/MPII/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q3H2jwILr7oo"},"source":["### Visualize some images in MPII dataset"]},{"cell_type":"code","metadata":{"id":"5bxUc6NWsAFv"},"source":["# TODO"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zi9dmeC7sSuA"},"source":["## (c) Train the network"]},{"cell_type":"markdown","metadata":{"id":"nfXw4vmLscC5"},"source":["Train with one stack (1HG). Please keep your terminal output in order to get full credit."]},{"cell_type":"code","metadata":{"id":"bJPJ7DqnYGwe"},"source":["%cd pytorch_stacked_hourglass/\n","!python train.py -e test_run_001 --max_iters 4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7F8yoJUPuIhp"},"source":["Draw your 1HG loss plot from log file."]},{"cell_type":"code","metadata":{"id":"WTj5-KUUaQbc"},"source":["# TODO"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u4vQ_cMMufi0"},"source":["## (d) Inference and Visualization"]},{"cell_type":"markdown","metadata":{"id":"6wEBQ0Z3vOGa"},"source":["### Infer HPE using the pretrain model"]},{"cell_type":"markdown","metadata":{"id":"C43fMYREveeg"},"source":["Infer and evaluate the pretrained 2HG model. Please keep your terminal output in order to get full credit."]},{"cell_type":"code","metadata":{"id":"VOlgnHR5vEaF"},"source":["!python test.py -c test_run_001"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lx2awjtqvlBJ"},"source":["Infer and evaluate the pretrained 8HG model. Please keep your terminal output in order to get full credit."]},{"cell_type":"code","metadata":{"id":"k44xxnm1vmDD"},"source":["# TODO"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n0xAES_zvo5M"},"source":["Visualize some human pose estimation results."]},{"cell_type":"code","metadata":{"id":"587wRfsqv2UQ"},"source":["# TODO"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GpQNvQNhv21r"},"source":["### Try customized images"]},{"cell_type":"markdown","metadata":{"id":"24sw-SFhv_FB"},"source":["Download some images from the internet and infer and visualize the human pose."]},{"cell_type":"code","metadata":{"id":"HBWqMxGZv8Vb"},"source":["# TODO"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IhXNsfPxOv8R"},"source":["## (e) Install VideoPose3D\n","### Pytorch & Caffe2"]},{"cell_type":"code","metadata":{"id":"-qVnLIwLwVdJ"},"source":["!wget https://anaconda.org/pytorch/pytorch/1.2.0/download/linux-64/pytorch-1.2.0-py3.6_cuda10.0.130_cudnn7.6.2_0.tar.bz2\n","!tar xvjf pytorch-1.2.0-py3.6_cuda10.0.130_cudnn7.6.2_0.tar.bz2\n","!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n","\n","# It might take some time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pMGXdUiePJ_j"},"source":["### Check if Caffe2 was built\n"]},{"cell_type":"code","metadata":{"id":"g1aTr5HoPSWH"},"source":["# To check if Caffe2 build was successful\n","!python -c 'from caffe2.python import core' 2>/dev/null && echo \"Success\" || echo \"Failure\"\n","\n","# To check if Caffe2 GPU build was successful\n","!python -c 'from caffe2.python import workspace; print(workspace.NumCudaDevices())'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AFcrnx_XPVbk"},"source":["# Install COCO Dataset \n","\n","!apt-get install python-dev\n","!pip install cython\n","!pip install pycocotools\n","!git clone https://github.com/cocodataset/cocoapi.git\n","!cd cocoapi/PythonAPI && make install\n","\n","import os\n","os.environ['COCOAPI'] = \":/content/cocoapi\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whXJfVrXPYDS"},"source":["# Install Detectron\n","\n","!git clone https://github.com/facebookresearch/detectron\n","!pip install -r detectron/requirements.txt\n","!cd detectron && make\n","!python detectron/detectron/tests/test_spatial_narrow_as_op.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBzAyhFVPUE4"},"source":["### Install VideoPose3D & Copy Video Script to Detectron Tools Folder"]},{"cell_type":"code","metadata":{"id":"XdEoU7r0PnSV"},"source":["# copy file from VideoPose3d\n","!git clone https://github.com/facebookresearch/VideoPose3D\n","!cp VideoPose3D/inference/infer_video.py detectron/tools/infer_video.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z9MA_AqyPpJ2"},"source":["### Download Pretrained Human3.6m Coco Model"]},{"cell_type":"code","metadata":{"id":"xr9hz6V7Pswe"},"source":["!mkdir VideoPose3D/checkpoint\n","os.chdir('VideoPose3D/checkpoint')\n","!wget https://dl.fbaipublicfiles.com/video-pose-3d/pretrained_h36m_detectron_coco.bin\n","os.chdir('../..')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8no36JuPq8l"},"source":["### Download Youtube Video for 3D Pose Estimation (specify YOUTUBE_ID)"]},{"cell_type":"code","metadata":{"id":"cWSAvIWAP1FM"},"source":["YOUTUBE_ID ='UpH7rm0cYbM'\n","\n","\n","!pip install -q youtube-dl\n","#download video\n","!youtube-dl -f 'bestvideo[ext=mp4]' --output \"youtube.%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID\n","\n","!mkdir videos   \n","  \n","# cut the first 5 seconds\n","!ffmpeg -y -loglevel info -i youtube.mp4 -ss 00:00:42 -t 00:00:05 videos/video.mp4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GeBRRlukP34S"},"source":["### Example: Compute 2D Coordinates with Detectron"]},{"cell_type":"code","metadata":{"id":"MPqGjD7MP13G"},"source":["!mkdir output\n","!python detectron/tools/infer_video.py \\\n","    --cfg detectron/configs/12_2017_baselines/e2e_keypoint_rcnn_R-101-FPN_s1x.yaml \\\n","    --output-dir output \\\n","    --image-ext mp4 \\\n","    --wts https://dl.fbaipublicfiles.com/detectron/37698009/12_2017_baselines/e2e_keypoint_rcnn_R-101-FPN_s1x.yaml.08_45_57.YkrJgP6O/output/train/keypoints_coco_2014_train:keypoints_coco_2014_valminusminival/generalized_rcnn/model_final.pkl \\\n","   videos"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zwhe7CPWP_pg"},"source":["### Example: Prepare Detectron Output to fit VideoPose3D Input"]},{"cell_type":"code","metadata":{"id":"Pwet7kKkQCDy"},"source":["!mkdir ./VideoPose3D/data/detectronoutput\n","!cp output/video.mp4.npz VideoPose3D/data/detectronoutput/video.mp4.npz\n","os.chdir('VideoPose3D/data') # This script must be launched from the \"data\" directory\n","!python prepare_data_2d_custom.py -i detectronoutput -o myvideos\n","os.chdir('../../')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nzoT_EgWQHT2"},"source":["### Example: Compute 3D Joints with VideoPose3D"]},{"cell_type":"code","metadata":{"id":"Tjw6A0dJQEIH"},"source":["!cp ./videos/video.mp4 VideoPose3D/video.mp4\n","os.chdir('VideoPose3D')\n","\n","!python run.py -d custom -k myvideos -arc 3,3,3,3,3 -c checkpoint --evaluate pretrained_h36m_detectron_coco.bin --render --viz-subject video.mp4 --viz-action custom --viz-camera 0 --viz-video video.mp4 --viz-output output.mp4 --viz-export outputfile --viz-size 6"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"clkU7x1TQNkC"},"source":["## (f) Questions"]},{"cell_type":"markdown","metadata":{"id":"vMhf2P1NQQve"},"source":["(1) Use the provided video and the pre-trained model of BOTH Stacked Hourglass and Detectron to do the inference and visualize the 2D human pose estimation results.\n"]},{"cell_type":"code","metadata":{"id":"TVAqm5yTQv7z"},"source":["# TODO"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2sZzDpIzQara"},"source":["\n","(2) Infer the 3D keypoints based on the 2D keypoints results from the two methods in (1). (needs to be displayed in Colab with mp4 format, sample codes and images are given below.)\n"]},{"cell_type":"code","metadata":{"id":"S_ZGyRdVQMq-"},"source":["# display video\n","def show_local_mp4_video(file_name, width=640, height=480):\n","  import io\n","  import base64\n","  from IPython.display import HTML\n","  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n","  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n","                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n","                      </video>'''.format(width, height, video_encoded.decode('ascii')))\n","\n","show_local_mp4_video('output.mp4', width=960, height=720)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8f0zNX1SQlv_"},"source":["(3) Besides the quality of the 2D keypoint detector, what other parameters or model architecture do you think that may affect the 3D performance? Explain why. (e.g., receptive fields, numbers of residual blocks, etc. )\n"]}]}