{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b955ba56-d4fd-4899-8bea-b305d7249695",
   "metadata": {},
   "source": [
    "# EE P 596 - TinyML - Assignment 3\n",
    "### Due: 11:59 pm (PST) on June 5 (Wed), 2024 via Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2d1e9-59ef-43ab-a2ac-4315cd90ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89d743-a539-4d7f-9bdd-47ac1203cab9",
   "metadata": {},
   "source": [
    "## Q1: Load the Dataset and Train Test Split (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4970441-e0b2-44ea-b987-1e21d8056cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load the dataset \"IMDB_Dataset.csv\" to a dataframe named \"df\"\n",
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "df. head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c479b3-c1b1-481a-b7cf-7d4759ea019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Get features X from column \"review\" and get labels y from column \"sentiment\"\n",
    "# convert the labels from text to integers such that positive = 1 and negative = 0\n",
    "\n",
    "X = df['review']\n",
    "y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5afce7-4010-4041-82ee-eb0ec8fcef18",
   "metadata": {},
   "source": [
    "## Q2: Data Pre-Processing (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fed7ee-8c65-44c0-8afd-6c0a90e5b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1:\n",
    "# (a) Use TfidfVectorizer from sklearn.feature_extraction.text and initialize it ONLY using \n",
    "#     max_features = 100 and n_gram_range = (1,1) <---- 1-gram features\n",
    "# (b) Use the initialized TfidfVectorizer in tfidf to obtain TF-IDF features of X_train and \n",
    "#     X_test\n",
    "# Hint: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=100, ngram_range=(1, 1))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a11ff-7800-473e-b714-4c255d3ef319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2:\n",
    "# (a) Use TfidfVectorizer from sklearn.feature_extraction.text and initialize it ONLY using \n",
    "#     max_features = 100 and n_gram_range = (2,2) <----- 2-gram features\n",
    "# (b) Use the initialized TfidfVectorizer in tfidf to obtain TF-IDF features of X_train and \n",
    "#     X_test\n",
    "\n",
    "tfidf_bigrams = TfidfVectorizer(max_features=100, ngram_range=(2, 2))\n",
    "X_train_tfidf_bigrams = tfidf_bigrams.fit_transform(X_train)\n",
    "X_test_tfidf_bigrams = tfidf_bigrams.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f5654-4442-4090-87ce-f0d4571d5829",
   "metadata": {},
   "source": [
    "## Q3: Create a Keras model equivalent for Logistic Regression (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2e92c-848e-494c-80c2-5ef446d951ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Define the Keras model equivalent for Logistic Regression\n",
    "# i.e, add ONE dense layer with 1 output neuron, sigmoid activation, and use input_dim to \n",
    "#      set input dimentions \n",
    "def create_keras_model(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(1, activation='sigmoid', input_dim=input_dim),\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483428d-2fca-4e9b-991a-3086cded245f",
   "metadata": {},
   "source": [
    "## Q4: Train Two models (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8828ac-f529-43b2-b8c5-bea089ad4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Train the Keras model 1 on 1-gram TF-IDF data\n",
    "#         Use 10 epochs, 32 batch size, 0.2 validation split\n",
    "model1 = create_keras_model(X_train_tfidf.shape[1])\n",
    "model1.fit(X_train_tfidf.toarray(), y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd3847-a6fd-451b-9762-3803204b4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Train the Keras model 2 on 2-gram TF-IDF data\n",
    "#         Use 10 epochs, 32 batch size, 0.2 validation split\n",
    "model2 = create_keras_model(X_train_tfidf_bigrams.shape[1])\n",
    "model2.fit(X_train_tfidf_bigrams.toarray(), y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819832ba-7222-4e7e-8811-7af186d7e021",
   "metadata": {},
   "source": [
    "## Q5: Quantize the model 1 and model 2 using Post Training Integer Quantization  (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac5f91-3628-4333-a707-d7df3a8ec83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Task 1: Quantize model 1 using Post Training Integer Quantization\n",
    "\n",
    "# Convert the Keras model1 to TensorFlow Lite format with integer quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model1)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in X_train_tfidf.toarray().astype(np.float32):\n",
    "        yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "tflite_model1 = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('model1_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bcf87a-75b9-44e1-ae00-2d01715e960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Quantize model 1 using Post Training Integer Quantization\n",
    "\n",
    "# Convert the Keras model to TensorFlow Lite format with integer quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in X_train_tfidf_bigrams.toarray().astype(np.float32):\n",
    "        yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "tflite_model2 = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('model2_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c60432-5d42-4f73-a4c2-7d17cf3f14b0",
   "metadata": {},
   "source": [
    "## Q6: Define a thrid model to aggregate the outputs from first two models and train it usinf Quantization-Aware Integer Quantization  (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbcd822-4995-4a35-a859-8436e7d9e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Define the Keras model equivalent for Logistic Regression for QAT\n",
    "def create_keras_model_QAT(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        tfmot.quantization.keras.quantize_annotate_layer(keras.layers.Dense(1, activation='sigmoid', input_dim=input_dim),\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model 3: Combined Sentiment Analysis using another DNN\n",
    "model1_pred = model1.predict(X_train_tfidf.toarray())\n",
    "model2_pred = model2.predict(X_train_tfidf_bigrams.toarray())\n",
    "\n",
    "X_train_combined = np.column_stack((model1_pred, model2_pred))\n",
    "\n",
    "model3 = create_keras_model_QAT(X_train_combined.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126554ae-84e7-4ec6-b555-ab17d65620b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_combined_scaled = scaler.fit_transform(X_train_combined)\n",
    "\n",
    "# Apply quantization-aware training\n",
    "quantize_model = tfmot.quantization.keras.quantize_apply(model3)\n",
    "\n",
    "quantize_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the quantization-aware model\n",
    "quantize_model.fit(X_train_combined_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Convert the trained model to TensorFlow Lite format with QAT\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(quantize_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in X_train_combined_scaled.astype(np.float32):\n",
    "        yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "tflite_model3_qat = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('model3_qat_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model3_qat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d1289-f617-4c67-b384-742b48af6aee",
   "metadata": {},
   "source": [
    "## Q7: Evaluate the three Quntized Models (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2570ac9b-978d-4198-9d68-6c05af13db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quantized model1\n",
    "interpreter_model1 = tf.lite.Interpreter(model_path='model1_quantized.tflite')\n",
    "interpreter_model1.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details_model1 = interpreter_model1.get_input_details()\n",
    "output_details_model1 = interpreter_model1.get_output_details()\n",
    "\n",
    "# Scale inputs to int8 range\n",
    "def scale_to_int8(input_data, input_scale, input_zero_point):\n",
    "    return (input_data / input_scale + input_zero_point).astype(np.int8)\n",
    "\n",
    "# Evaluate Model 1\n",
    "def evaluate_model1():\n",
    "    y_pred1 = []\n",
    "    input_scale, input_zero_point = input_details_model1[0]['quantization']\n",
    "    for i in range(len(X_test_tfidf.toarray())):\n",
    "        input_data = np.expand_dims(X_test_tfidf.toarray()[i].astype(np.float32), axis=0)\n",
    "        input_data_int8 = scale_to_int8(input_data, input_scale, input_zero_point)\n",
    "        interpreter_model1.set_tensor(input_details_model1[0]['index'], input_data_int8)\n",
    "        interpreter_model1.invoke()\n",
    "        output = interpreter_model1.get_tensor(output_details_model1[0]['index'])\n",
    "        y_pred1.append((output[0] > 0.5).astype(int))\n",
    "    return y_pred1\n",
    "\n",
    "y_pred1_quantized = evaluate_model1()\n",
    "print(\"Model 1 - Quantized Sentiment Analysis\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred1_quantized))\n",
    "print(classification_report(y_test, y_pred1_quantized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65703d-e321-4e8d-9763-31d08dac17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quantized model2\n",
    "interpreter_model2 = tf.lite.Interpreter(model_path='model2_quantized.tflite')\n",
    "interpreter_model2.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details_model2 = interpreter_model2.get_input_details()\n",
    "output_details_model2 = interpreter_model2.get_output_details()\n",
    "\n",
    "# Evaluate Model 2\n",
    "def evaluate_model2():\n",
    "    y_pred2 = []\n",
    "    input_scale, input_zero_point = input_details_model2[0]['quantization']\n",
    "    for i in range(len(X_test_tfidf_bigrams.toarray())):\n",
    "        input_data = np.expand_dims(X_test_tfidf_bigrams.toarray()[i].astype(np.float32), axis=0)\n",
    "        input_data_int8 = scale_to_int8(input_data, input_scale, input_zero_point)\n",
    "        interpreter_model2.set_tensor(input_details_model2[0]['index'], input_data_int8)\n",
    "        interpreter_model2.invoke()\n",
    "        output = interpreter_model2.get_tensor(output_details_model2[0]['index'])\n",
    "        y_pred2.append((output[0] > 0.5).astype(int))\n",
    "    return y_pred2\n",
    "\n",
    "y_pred2_quantized = evaluate_model2()\n",
    "print(\"\\nModel 2 - Quantized Sentiment Analysis\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2_quantized))\n",
    "print(classification_report(y_test, y_pred2_quantized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517d5be-3446-4d96-b310-112d696e4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quantized model3 (QAT)\n",
    "interpreter_model3 = tf.lite.Interpreter(model_path='model3_qat_quantized.tflite')\n",
    "interpreter_model3.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details_model3 = interpreter_model3.get_input_details()\n",
    "output_details_model3 = interpreter_model3.get_output_details()\n",
    "\n",
    "# Prepare test data\n",
    "X_test_tfidf_dense = X_test_tfidf.toarray()\n",
    "X_test_tfidf_bigrams_dense = X_test_tfidf_bigrams.toarray()\n",
    "\n",
    "model1_probs_test = model1.predict(X_test_tfidf_dense)\n",
    "model2_probs_test = model2.predict(X_test_tfidf_bigrams_dense)\n",
    "\n",
    "X_test_combined = np.column_stack((model1_probs_test, model2_probs_test))\n",
    "X_test_combined_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "# Evaluate Model 3\n",
    "def evaluate_model3():\n",
    "    y_pred3 = []\n",
    "    input_scale, input_zero_point = input_details_model3[0]['quantization']\n",
    "    for i in range(len(X_test_combined_scaled)):\n",
    "        input_data = np.expand_dims(X_test_combined_scaled[i].astype(np.float32), axis=0)\n",
    "        input_data_int8 = scale_to_int8(input_data, input_scale, input_zero_point)\n",
    "        interpreter_model3.set_tensor(input_details_model3[0]['index'], input_data_int8)\n",
    "        interpreter_model3.invoke()\n",
    "        output = interpreter_model3.get_tensor(output_details_model3[0]['index'])\n",
    "        y_pred3.append((output[0] > 0.5).astype(int))\n",
    "    return y_pred3\n",
    "\n",
    "y_pred3_quantized = evaluate_model3()\n",
    "print(\"\\nModel 3 (QAT) - Quantized Sentiment Analysis\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred3_quantized))\n",
    "print(classification_report(y_test, y_pred3_quantized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18156bc5-d844-4830-b982-dbed98ec0a42",
   "metadata": {},
   "source": [
    "## Q7: Breifly discuss the observed Results and how would you implement this on Arduino Nano BLE (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d60b24-1254-4ccd-9d02-b7e32c91a15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6083460b-c5f6-4244-9ca2-a7d47f115a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba805d2c-fb39-49c1-a4c3-acc1f9127996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ICCPS23]",
   "language": "python",
   "name": "conda-env-ICCPS23-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
