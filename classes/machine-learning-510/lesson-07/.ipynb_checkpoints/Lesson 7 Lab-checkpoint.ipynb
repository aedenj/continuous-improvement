{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Subset Selection in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we apply the best subset selection approach to the Hitters data. We wish to predict a baseball player’s\n",
    "Salary on the basis of various statistics associated with performance in the previous year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ngough/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>...</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Andy Allanson</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>446</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Alan Ashby</td>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>...</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Alvin Davis</td>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>...</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-Andre Dawson</td>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>...</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Andres Galarraga</td>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player  AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  \\\n",
       "0     -Andy Allanson    293    66      1    30   29     14      1     293   \n",
       "1        -Alan Ashby    315    81      7    24   38     39     14    3449   \n",
       "2       -Alvin Davis    479   130     18    66   72     76      3    1624   \n",
       "3      -Andre Dawson    496   141     20    65   78     37     11    5628   \n",
       "4  -Andres Galarraga    321    87     10    39   42     30      2     396   \n",
       "\n",
       "   CHits    ...      CRuns  CRBI  CWalks  League Division PutOuts  Assists  \\\n",
       "0     66    ...         30    29      14       A        E     446       33   \n",
       "1    835    ...        321   414     375       N        W     632       43   \n",
       "2    457    ...        224   266     263       A        W     880       82   \n",
       "3   1575    ...        828   838     354       N        E     200       11   \n",
       "4    101    ...         48    46      33       N        E     805       40   \n",
       "\n",
       "   Errors  Salary  NewLeague  \n",
       "0      20     NaN          A  \n",
       "1      10   475.0          N  \n",
       "2      14   480.0          A  \n",
       "3       3   500.0          N  \n",
       "4       4    91.5          N  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Hitters.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Salary\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dimensions of the original Hitters data \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop any rows the contain missing values, along with the player's name\n",
    "df = df.dropna().drop('Player', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dimensions of the modified data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we have no more null values\n",
    "df[\"Salary\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Convert categorical variable into dummy/indicator variables\n",
    "dummies = pd.get_dummies(df[['League', 'Division', 'NewLeague']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Get the label\n",
    "y = df.Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>League_A</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_E</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_A</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     League_A  League_N  Division_E  Division_W  NewLeague_A  NewLeague_N\n",
       "1           0         1           0           1            0            1\n",
       "2           1         0           0           1            1            0\n",
       "3           0         1           1           0            0            1\n",
       "4           0         1           1           0            0            1\n",
       "5           1         0           0           1            1            0\n",
       "6           0         1           1           0            1            0\n",
       "7           1         0           0           1            1            0\n",
       "8           0         1           0           1            0            1\n",
       "9           1         0           1           0            1            0\n",
       "10          1         0           1           0            1            0\n",
       "11          0         1           0           1            0            1\n",
       "12          0         1           1           0            0            1\n",
       "13          1         0           1           0            1            0\n",
       "14          0         1           1           0            0            1\n",
       "16          0         1           0           1            0            1\n",
       "17          1         0           0           1            1            0\n",
       "19          0         1           0           1            0            1\n",
       "20          0         1           1           0            0            1\n",
       "21          1         0           0           1            0            1\n",
       "23          0         1           0           1            0            1\n",
       "24          1         0           1           0            1            0\n",
       "25          1         0           1           0            1            0\n",
       "26          0         1           1           0            0            1\n",
       "27          0         1           0           1            0            1\n",
       "28          0         1           0           1            0            1\n",
       "29          1         0           0           1            1            0\n",
       "31          0         1           0           1            0            1\n",
       "33          1         0           1           0            1            0\n",
       "34          1         0           0           1            1            0\n",
       "35          0         1           0           1            0            1\n",
       "..        ...       ...         ...         ...          ...          ...\n",
       "287         1         0           1           0            1            0\n",
       "288         0         1           0           1            0            1\n",
       "289         0         1           1           0            0            1\n",
       "290         0         1           0           1            0            1\n",
       "291         0         1           0           1            1            0\n",
       "293         0         1           1           0            0            1\n",
       "294         1         0           0           1            1            0\n",
       "295         0         1           0           1            1            0\n",
       "296         0         1           1           0            0            1\n",
       "297         1         0           0           1            1            0\n",
       "299         1         0           0           1            1            0\n",
       "300         0         1           1           0            0            1\n",
       "301         0         1           1           0            0            1\n",
       "303         1         0           0           1            1            0\n",
       "304         0         1           0           1            0            1\n",
       "306         0         1           0           1            0            1\n",
       "307         0         1           1           0            0            1\n",
       "308         0         1           1           0            0            1\n",
       "309         0         1           1           0            0            1\n",
       "310         0         1           1           0            0            1\n",
       "311         0         1           1           0            0            1\n",
       "312         0         1           1           0            0            1\n",
       "313         1         0           1           0            1            0\n",
       "314         0         1           0           1            0            1\n",
       "315         1         0           0           1            1            0\n",
       "317         0         1           1           0            0            1\n",
       "318         1         0           1           0            1            0\n",
       "319         1         0           0           1            1            0\n",
       "320         1         0           1           0            1            0\n",
       "321         1         0           0           1            1            0\n",
       "\n",
       "[263 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop the column with the independent variable (Salary), and columns for which we created dummy variables\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "# Define the feature set X\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will perform best subset selection by identifying the best model that contains a given number of predictors, where best is quantified using RSS. We’ll define a helper function to outputs the best set of variables for each model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate RSS\n",
    "    model = sm.OLS(y,X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    RSS = ((regr.predict(X[list(feature_set)]) - y) ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This returns a DataFrame containing the best model that we generated, along with some extra information\n",
    "about the model. Now we want to call that function for each number of predictors k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getBest(k): #Number of predictors\n",
    "    start = time.time()\n",
    "    results = []\n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(processSubset(combo))\n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    end = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", k, \"predictors in\", (end-start), \"seconds.\")\n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  19 models on 1 predictors in 0.0659341812133789 seconds.\n",
      "Processed  171 models on 2 predictors in 0.3546171188354492 seconds.\n",
      "Processed  969 models on 3 predictors in 1.9167070388793945 seconds.\n",
      "Processed  3876 models on 4 predictors in 8.654996156692505 seconds.\n"
     ]
    }
   ],
   "source": [
    "models = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "for i in range(1,5):\n",
    "    models.loc[i] = getBest(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As you can see it's running p (predictors) choose k(desired predictors) number of models. For computation purpose we're not going to run subset selection on all 19 range of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we have one big DataFrame that contains the best models we’ve generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSS</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.321393e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.073305e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.941071e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.797678e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RSS                                              model\n",
       "1  4.321393e+07  <statsmodels.regression.linear_model.Regressio...\n",
       "2  3.073305e+07  <statsmodels.regression.linear_model.Regressio...\n",
       "3  2.941071e+07  <statsmodels.regression.linear_model.Regressio...\n",
       "4  2.797678e+07  <statsmodels.regression.linear_model.Regressio..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can get a full rundown of a single model using the summary() function if we want to access the details of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Salary</td>      <th>  R-squared:         </th> <td>   0.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   293.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 16 Aug 2018</td> <th>  Prob (F-statistic):</th> <td>4.43e-83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:12:39</td>     <th>  Log-Likelihood:    </th> <td> -1901.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   263</td>      <th>  AIC:               </th> <td>   3810.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   260</td>      <th>  BIC:               </th> <td>   3820.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hits</th>       <td>    3.4057</td> <td>    0.288</td> <td>   11.842</td> <td> 0.000</td> <td>    2.839</td> <td>    3.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRBI</th>       <td>    0.6964</td> <td>    0.065</td> <td>   10.742</td> <td> 0.000</td> <td>    0.569</td> <td>    0.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Division_W</th> <td> -129.1604</td> <td>   37.777</td> <td>   -3.419</td> <td> 0.001</td> <td> -203.548</td> <td>  -54.773</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>110.025</td> <th>  Durbin-Watson:     </th> <td>   1.893</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 621.594</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.589</td>  <th>  Prob(JB):          </th> <td>1.05e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.828</td>  <th>  Cond. No.          </th> <td>    856.</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Salary   R-squared:                       0.772\n",
       "Model:                            OLS   Adj. R-squared:                  0.769\n",
       "Method:                 Least Squares   F-statistic:                     293.0\n",
       "Date:                Thu, 16 Aug 2018   Prob (F-statistic):           4.43e-83\n",
       "Time:                        17:12:39   Log-Likelihood:                -1901.8\n",
       "No. Observations:                 263   AIC:                             3810.\n",
       "Df Residuals:                     260   BIC:                             3820.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Hits           3.4057      0.288     11.842      0.000       2.839       3.972\n",
       "CRBI           0.6964      0.065     10.742      0.000       0.569       0.824\n",
       "Division_W  -129.1604     37.777     -3.419      0.001    -203.548     -54.773\n",
       "==============================================================================\n",
       "Omnibus:                      110.025   Durbin-Watson:                   1.893\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              621.594\n",
       "Skew:                           1.589   Prob(JB):                    1.05e-135\n",
       "Kurtosis:                       9.828   Cond. No.                         856.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model summary for three variables\n",
    "models.loc[3, \"model\"].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This output indicates that the best three-variable model contains Hits, CRBI and Division_W. To save time, we\n",
    "only generated results up to the best four-variable model. You can use the functions we defined above to\n",
    "explore as many variables as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In addition to the output we get when we print the summary to the screen, fitting the OLS also produced many other useful statistics such as adjusted R square, AIC, and BIC. We can examine these to try to select the best overall model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x118e280f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAE3CAYAAAB2LD/OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHVWZ//HPN2unuxOSkAayQDbCphAgQdlGQEBFEFDU\nUdaoyKiIgOP8FJVFZkYURBhFHVmURVxAJC4oUVZRZCRAACNLyAKBROg2ISSdPXl+f5y6SeXm9pbc\nzr3d/X2/XvdV6VOn6p6qFPSTc06dRxGBmZmZmZVPr0o3wMzMzKy7cYBlZmZmVmYOsMzMzMzKzAGW\nmZmZWZk5wDIzMzMrMwdYZmZmZmXmAMvMzMyszBxgmZmZmZWZAywzMzOzMutT6QZ0F8OGDYsxY8ZU\nuhlmZmbWSR577LGmiGhoT10HWGUyZswYpk+fXulmmJmZWSeR9GJ763qI0MzMzKzMHGCZmZmZlZkD\nLDMzM7Myc4BlZmZmVmYOsMzMzMzKzAGWmZmZWZk5wDIzMzMrMwdYXcDadesr3QQzMzPrAAdYVe62\nR+dz4nf/zLJVayvdFDMzM2snB1hVbqftanhm4VI+85MnWLc+Kt0cMzMzawcHWFXubbs1cMnxb+K+\nZ1/jv+76e6WbY2ZmZu3gXIRdwGkHjmZO4zJ++Od5jGuo57QDR1e6SWZmZtYKB1hdxJeP3Yt5Tc1c\n8quZjB5ay9t2a1cybzMzM6sADxF2Eb17iW+fvD8Tdqjn7FsfZ9arSyvdJDMzM2uBA6wupL5/H64/\nYzL9+/bmozc9yj+Xrap0k8zMzKwEB1hdzKghtVx3+iRee2MV/3bLY6xau67STTIzM7MiDrC6oP12\nGcKVH5zI9BcX84U7nibCyzeYmZlVE09y76KO22cEcxqb+eYfnmfcsDrOOXJCpZtkZmZmmYr2YEna\nXdKtkp6RtETSckmzJH1X0rgS9T8g6WFJzZKWSnpI0rtbOHcvSedLelbSSknzJV0pqa6VtkyVtDg7\n/0OS3l7uay6nc96+K+/dbyRX/uF5fvPUgko3x8zMzDKVHiIcBQwH7gQuAM4D7gZOBx7PB1mSPg/c\nBtQAFwIXA3XAbySdUuLcVwHfBP4OnAPcDnwG+LWkTa5b0njgYeAg4HLgP4B6YJqko8p1seUmia+d\ntDeTRw/h3297kideWlzpJpmZmRmgapy/I+kDpGDq0oi4WNKOwEvA88D+EbEmq9cXeBwYCYyJiDey\n8jcBTwN3RsRJufOeA3wLOCUifpwrvw04CZgUETOysnpgJrAS2CPauFGTJ0+O6dOnl+X6O+qfy1Zx\n4nf/zIrV65l69sGMGlJbkXaYmZl1Z5Iei4jJ7alb6R6slryYbddk24OBfsCtheAKIPvzj4EhwAm5\n4z8MCLi66LzXAcuBUwsF2ZDh8cADheAqO/cy4HpgN+CArb+kzrN9fX9+cMYBrFqzjjNvmu7E0GZm\nZhVWFQGWpBpJwySNkvQO4PvAfOCGrEr/bLu8xOGFsgNzZQcA64G/5itGxEpgBpsGTPtk5/9LiXM/\nkjtfVZuw40C+c8r+zHptmRNDm5mZVVhVBFjAmUAjKaiaBqwFDo2Ihdn+mdm21KTzI7LtzrmyEUBT\nRJRaifMVYJikfrm6hfJSdSENQW5G0lmSpkua3tjYWKrKNpVPDP3fdz1T6eaYmZn1WNWyTMNU4FnS\nxPL9SJPSH5R0VETMjoinJf0BOEHS5cAPs+OmAMdkf85PPKoFWlrmfGWuzurccaXq5+tuJiKuBa6F\nNAerxavbhk47cDSzX1vGD/48l3ENdZzqxNBmZmbbXFX0YEXEyxFxT0RMjYiLgcNJPUtX5ar9K/AL\n4HOkNwP/DnwQODvb/0au7nI2DisWq8nVyW9L1S+u2yVceNxeHLF7Axf/aiZ/fL7yPWtmZmY9TVUE\nWMUi4ingCeCwXNni7I3A4cDbgP2B8UBhAahnc6dYQBoGLBU0jSQNH67O1S2Ul6oLpYcPq5YTQ5uZ\nmVVWVQZYmQGkieqbiIhXI+KhiHgiItYDhYVGf5ur9ijp2t6SP1ZSDbAvkF9P4WnS8OBBJdpQmDhf\nmfUXtoITQ5uZmVVOpVdy36mF8iOANwP3tnH8ZNIE+Qcj4k+5XT8DgrRwad7HSfOpbi0UZMsx/Bo4\nXNLE3Lnrs3PPouhtxK6ikBj6VSeGNjMz26YqutCopDtJQ373kda+qgEmAR8CFgGHRMTsrO5/AhNI\nwc4S0hDhR4CFwOERMb/o3N8GPk1aJf63wJ6kldz/DLw96/0q1N01O+8a0ryvN0jB2N7AsRExra1r\nqeRCo2359ZMLOOcnT/De/UbyzQ9ORFKlm2RmZtbldGSh0Uq/RfgTUlqc04AGUq/TXODbwOUR8Wqu\n7uPAkcA7SL1QL2X1LouI10uc+zxgHnAWcCzQlNW/KB9cAUTEC5IOAb4GfIG0qOnjwLsi4p6yXGkF\nvWfiCOY2pcTQ4xvq+PTbnRjazMysM1VlqpyuqJp7sAAigvN/NoOpMxZwzcn7cdw+I9o+yMzMzDbo\nDqlyrMxSYuh9mOTE0GZmZp3OAVYPUtO3N9eeNokdBvXn4zc/xiuvr6h0k8zMzLolB1g9TD4x9Mdu\nfNSJoc3MzDqBA6weyImhzczMOpcDrB7KiaHNzMw6T6WXabAKcmJoMzOzzuEAq4e78Li9ePGfzVz8\nq5mM3r6Wf5nQUOkmmZmZdXkeIuzhevcS3/rwfuzaUM+nbn2cF15zYmgzM7Ot5QDLGFjTlxumTKZ/\nn9585EYnhjYzM9taDrAM2DQx9Cd+5MTQZmZmW8MBlm2w3y5DuPIDE3l03mK+cMfTOI2SmZnZlvEk\nd9uEE0ObmZltPQdYtplz3r4rcxqX8Y3fP8+YYXVODG1mZtZBHiK0zRQnhp4x//VKN8nMzKxLcYBl\nJdX07c33T5tEw8D+nHnTdCeGNjMz6wAHWNaiYfX9+eEUJ4Y2MzPrKAdY1qoJOw7kGieGNjMz6xAH\nWNamw3Zr4JL37OXE0GZmZu3ktwitXU47aAyzG5udGNrMzKwdHGBZu3352D2Z58TQZmZmbfIQobVb\nn969+LYTQ5uZmbXJAZZ1yMbE0L346I3TWdS8utJNMjMzqzoOsKzDRg2p5drTJ/OPN1byb7dMd2Jo\nMzOzIg6wbIvsn0sMfYETQ5uZmW3Ck9xti71n4gjmNDZz1T3PM86Joc3MzDZwgGVb5TNH7srcppQY\neuyweo7dZ3ilm2RmZlZxHiK0rZJPDP3Z22Y4MbSZmRkOsKwMnBjazMxsUxUNsCTtLulWSc9IWiJp\nuaRZkr4raVyJ+u+SNE3SAkkrJM2WdF0LdYdJ+mp27mZJTZIeljRFklpoy1RJi7P6D0l6e2dde3cz\nrL4/P3BiaDMzM6DyPVijgOHAncAFwHnA3cDpwOP5wEnS6cDvgLHAt4BzgF8BJwPTJY3M1e0P/BH4\nPPAX4Hzgv4DewA+Br+UbIWk88DBwEHA58B9APTBN0lHlvujuajcnhjYzMwNA1fh6vaQPALcBl0bE\nxVnZn4C3ACMioilX90zgOuD8iLg6KzsK+ANwdUScn6vbD3gWGBoRg3PltwEnAZMiYkZWVg/MBFYC\ne0QbN2ry5Mkxffr0rb727uCWv8zjwl/O5GOHjuXC4/aqdHPMzMzKQtJjETG5PXUr3YPVkhez7Zpc\n2XJSsLO4qO6CbNtcVDe/D4CIWA005etKqgOOBx4oBFdZ3WXA9cBuwAFbdBU91GkHjWHKwWO44U9z\nufX/Xmz7ADMzs26mKpZpkFRDGpKrAfYCvg7MB27IVbsMuAu4SdIVpEDpzcCVwDPAT3N1/0IaTvx/\nkuYB/wfUAmcAk4BP5OruA/TPjin2SLY9APjrFl9gD1RIDH3RL2eyy1AnhjYzs56lWnqwzgQaSUHV\nNGAtcGhELCxUiIj7gSOBw4EZwMuk+VpzgAMjYmmubpB6pe4gDTW+SArCzgZOiojrct89Itu+UqJd\nhbKRJfYh6SxJ0yVNb2xs7Mj1dntODG1mZj1ZtQRYU4GjgfcClwLjgQezyecAZG/0TQNeIwVk7yP1\nXh0F/FRS31zdvsDtwEeyOu/LjnkB+LGko3PfXZttV5Vo18qiOpuIiGsjYnJETG5ocA9NMSeGNjOz\nnqoqAqyIeDki7omIqdmk9sNJPUtXwYbJ6TeThgUPiYgbIuLOiPgccC5wDGn4r+As4ETg3Ij4XFb3\nBuBQ4B/AdZJ6Z3UL87X6l2haTVEd6yAnhjYzs56oKgKsYhHxFPAEcFhWtCdpmO6uiChexfL2bHtY\nruyoon2F8y4nzeMaDYzJigsT4UsNAxbKSg0fWjvtv8sQvuHE0GZm1oNUxST3FgwA1md/Lgz/9S5R\nr0/RtqP1nyYNDx5Uou6B2dbrL2yl4yeOYK4TQ5uZWQ9R6ZXcd2qh/AjSG4L3ZkUzScN0J0oaXFR9\nSrZ9NFf2aNG+wnkHAyeQlnp4ATYsx/Br4HBJE3N160nztmbhNwjL4jNH7soJ+47gG79/nrueWtj2\nAWZmZl1UpXuwvidpOHAf6U2/GtIyCh8ivVX4eYCIWCHpUtIK7E9Iug5YBBwCnALMJq1ZVfAd4GPA\n1yTtDfwZGAp8nLRy/NkRkZ8MdAHpDcXfS7oKeCOrOxI4tq1FRq19JPH1k/bh5cUr+OxtMxg5ZAD7\n7lwcL5uZmXV9FV3JXdIHSWlxJgINQABzSWtYXR4RrxbV/zBpqYWJpGDsFdKcqksiorGo7gjgYtIE\n+OHACtLyDldHxC9KtGVPUgB3GNAPeDw77z3tuRav5N5+TctWceJ3/szKNev55acPYeTgAZVukpmZ\nWZs6spJ7VabK6YocYHXM868u5aTvPszIIQP4+ScPpr5/pTtTzczMWtcdUuVYN5dPDH2uE0ObmVk3\n4wDLKuaw3Rq45D17ce+zr/HV3z5T6eaYmZmVjcdlrKJOO2gMsxubueFPcxnXUMcpbx1d6SaZmZlt\nNQdYVnH5xNCjh9Zx6IRhlW6SmZnZVvEQoVVcPjH0J299zImhzcysy3OAZVXBiaHNzKw7cYBlVcOJ\noc3MrLtwgGVVxYmhzcysO/Akd6s6+cTQ43eo5+wjdq10k8zMzDrEAZZVpc8cuStzmpZxxbTnGLN9\nHcfuM7zSTTIzM2s3DxFaVSokht5/l8F89rYZPDn/9Uo3yczMrN0cYFnVqunbm2tPn0zDwP6cefN0\nXnl9RaWbZGZm1i4OsKyqDavvzw+mHMDK1ev42I2PsmzV2ko3yczMrE0OsKzqFRJDP//qUieGNjOz\nLsEBlnUJh+3WwCXHv8mJoc3MrEvwW4TWZZx+0BjmODG0mZl1AQ6wrEtxYmgzM+sKPERoXYoTQ5uZ\nWVfgAMu6nIE1fbn+DCeGNjOz6uUAy7qknYfW8v3TnBjazMyqkwMs67Imjc4lhv6FE0ObmVn18CR3\n69KOnziCOY3LuPqeWYxvcGJoMzOrDg6wrMs798gJzG1q5oppzzF2WB3v3tuJoc3MrLI8RGhdXj4x\n9Pk/c2JoMzOrPAdY1i04MbSZmVUTB1jWbRQSQ69wYmgzM6swB1jWrey240CuOXk/J4Y2M7OKqmiA\nJWl3SbdKekbSEknLJc2S9F1J40rUf5ekaZIWSFohabak60rVzeoPlfQNSS9IWimpUdL9kv6lhbZM\nlbRYUrOkhyS9vTOu2zrX4bvvsCEx9GVODG1mZhVQ6bcIRwHDgTuBl4G1wN7AR4CTJe0fEXMAJJ0O\n3ATMAr4FNAFvAs4CTpK0d0S8UjixpNHAA0A9cAPwPLAdsA8wMt8ISeOBh7PvvxxYAnwcmCbpmIi4\npzMu3jrP6QeNYfZry7j+T3MZ11DPyW/dpdJNMjOzHqSiAVZE3AvcW1wu6Y/AbcAZwMVZ8VnAGuDg\niGjK1Z0JXAd8ALg6d5ofka5vn4hY2EZTLgMGA5MiYkZ23puBmcB3JO0RXsWyy7nwuL14cdFyLvzl\n39hlaK0TQ5uZ2TZTrXOwXsy2a3Jly4GVwOKiuguybXOhQNLbgEOByyNioaS+kmpLfZGkOuB44IFC\ncAUQEcuA64HdgAO24lqsQgqJocc31GWJoZdVuklmZtZDVEWAJalG0jBJoyS9A/g+MJ80tFdwGalH\n6iZJEyWNlPRO4ErgGeCnubrvzrYvSfo1sAJolvS8pFOLvn4foD/wlxJNeyTbOsDqogbW9OWGMw7I\nEkM/6sTQZma2TVRFgAWcCTSSgqpppLlQh+aH9iLifuBI4HBgBmnO1t3AHODAiFiaO9/u2fY6YChp\nqPGjwGrgFkkfydUdkW1fYXOFspEl9iHpLEnTJU1vbGxs35XaNpdPDP2JWx5zYmgzM+t01RJgTQWO\nBt4LXAqMBx7MJp8DkL3RNw14jRSQvY/Ue3UU8FNJfXPnG5htlwJHRMStEfFD4F+A14GvSipce2Ho\ncFWJdq0sqrOJiLg2IiZHxOSGhoaOXK9tY5NGD+GK9+/DX+ctcmJoMzPrdJV+ixCAiHiZ1CMFMFXS\nHcCjwFXA8ZL6ATeT3hw8JCIKy3TfKekF4HukXqrrs/LC/p9ExIYxoYhYLOlXwOmkXq5nSHO7IA0T\nFqvJtstL7LMu5oR9RzK3qdmJoc3MrNO12YMlaQ9Je2xtnY6IiKeAJ4DDsqI9ScN0d+WCq4Lbs+1h\nubJCsPaPEqcvDDsOybaFSfKlhgELZaWGD60LOvfICRw/cQRXTHuO3z7d1sulZmZmW6bVAEvSZNJS\nBe9s4zzvBP4mad9yNQwYAKzP/lwY/utdol6foi3AX7PtqBL1C2WvZdunScODB5Woe2C2nd5WY61r\nkMTl73diaDMz61xt9WB9HJgLfLuNet8mTTb/ZEe+XNJOLZQfAbyZjWtkzSQN050oaXBR9SnZ9tFc\n2VTS/KtTJdXnzjscOBF4PiJegA3LMfwaOFzSxFzdetJcr1lsDNisGyhODL3AiaHNzKzM2gqwDgfu\niIj1rVXK9t+R1e+I70l6RNJXJf2bpHOzBT6nkd4q/Hx2/hWkye/DgSckfVHSJyTdQlq+YTYb518R\nEYuBz5GG+B6R9FlJXyAtu9APOKeoHReQVm//vaQvSPoU8FB2/DleZLT7GVbfnxvOyBJD3zSdZieG\nNjOzMmorwNqZlGKmPV7I6nfET0gT108D/gf4GjCZ1CM2MSJmFypGxNeBk0nzoS7I6vwLaYL7QRHx\nRv7EEXEtcBKwDPhP4EvAc6S3Cn9fVPcF4BBSAPYF4BukhUvfFRHTOnhN1kXsvlNKDP3cP97gM04M\nbWZmZdTWW4Tr21Enf65We7qKRcRtpJQ47a3/E1JQ1t76vwB+0c66zwAntPfc1j0UEkNf9MuZXPbb\nZ/jycXtVuklmZtYNtBU8zQfaO3F9Xza+vWfWZTgxtJmZlVtbQ4T3Ax+WtGNrlbL9H6ZE4mazruDC\n4/bisN0auPCXf+NPs5raPsDMzKwVbQVYV5GWS5gmafdSFSTtBvyOtCjn1eVtntm20ad3L759shND\nm5lZebQaYEXELOBTpCUTZkp6QNLVki6VdJWkB0hLKOwDfDKrb9YlDcolhv7YTU4MbWZmW67Nldwj\n4gbgXcCTwNuAzwBfBs7Nfn6K9LbdDzuxnWbbRCEx9MIlTgxtZmZbrl3JniPinoiYBIwDjgdOzbbj\nImJSRNzTiW0026acGNrMzLZWh5I9R8Q8YF6ntMSsijgxtJmZbY0OBVhmPcm5R05gTmMzV0x7jrHD\n6nj33sMr3SQzM+siWg2wJD3VwfNFRExsu5pZ9Sskhn558XI+e9sMRg4ewMSdi1NhmpmZba6tOViD\ngIEd+AzqtJaaVUBN3958/7TJbF/nxNBmZtZ+bS3TMCYixrb3A+yxjdptts00DOzPD6Y4MbSZmbVf\nu94ibIukSZK+Cywox/nMqk0+MfS5P3ViaDMza90WB1iShkr6jKQZwF+BTwCNZWuZWZU5fPcduPg9\nb+KeZ17jst8+U+nmmJlZFevwW4SS3gl8lLQOVj/geeArwB0RMbO8zTOrLmccPIY5jU4MbWZmrWtX\ngCVpDCmoOgMYBSwC7iAleP5SRPyik9pnVnUuPG4v5v1zORf98m+M3r6WQ3YdVukmmZlZlWl1iFDS\nKZLuBV4AvkTqrToZGAlcDKjTW2hWZQqJocc11PGJHzkxtJmZba6tOVi3AAcAXwXGR8TREfGziHAW\nXOvRComh+/V2YmgzM9tcWwHWKqAeOAF4j6Qhnd8ks65h56G1XHu6E0Obmdnm2gqwhgOfAdYB/wMs\nkPRjSUe241izbi+fGPqLv/ibE0ObmRnQ9kKjr0fENRGxPzAZ+AHwLuD3wJ+AALbr9FaaVbET9h3J\nuUdO4I7HX+a7D8yudHPMzKwKtLsXKiIej4izSb1apwF/y3ZdL2mGpC9LelNnNNKs2p131ASOnziC\nK6Y9x2+fXljp5piZWYV1eJgvIlZFxI8j4khgPPDfwBDgUuDJMrfPrEsoJIbef5fBfPa2GTw5//VK\nN8nMzCpoq+ZRRcS8iLgIGAO8G/B6WNZjOTG0mZkVlGWieiR3R8QHy3E+s67KiaHNzAz8JqBZ2Tkx\ntJmZOcAy6wT5xNBf+50TQ5uZ9TQdTvZsZu1zxsFjmN24jOseSomhP/wWJ4Y2M+spHGCZdaKLjtuL\nF/+5nAun/o1dhjoxtJlZT1HRIUJJu0u6VdIzkpZIWi5plqTvShpXov67JE2TtEDSCkmzJV1Xqm7R\ncbWS5kgKSde00papkhZLapb0kKS3l+tarWdyYmgzs56p0nOwRpEWLr0TuAA4D7gbOB14PB84STod\n+B0wFvgWcA7wK+BkYLqkka18z6VAQ0s7JY0HHgYOAi4H/oOUg3GapKO29OLMwImhzcx6oooOEUbE\nvcC9xeWS/gjcBpwBXJwVnwWsAQ6OiKZc3ZnAdcAHgKtLnGt/UuD2/4ArW2jKZcBgYFJEzMiOuxmY\nCXxH0h7hJHO2FVJi6El8+Lr/4xO3PMYtZ76F/n16V7pZZmbWSSrdg9WSF7PtmlzZcmAlsLio7oJs\n21x8Ekm9ScHX3bSwCKqkOuB44IFCcAUQEcuA64HdgAM6fglmm5o0eqgTQ5uZ9RBVEWBJqpE0TNIo\nSe8Avg/MB27IVbuM1ON2k6SJkkZKeiepV+oZ4KclTn0+sAfw6Va+fh+gP/CXEvseybYOsKwsnBja\nzKxnqIoACzgTaCQFVdOAtcChEbEha25E3A8cCRwOzABeJvVMzQEOjIil+RNKGgt8Bbg0Iua18t0j\nsu0rJfYVykrO75J0lqTpkqY3Nja2dn1mG+QTQ//OiaHNzLqlagmwpgJHA+8lTUgfDzyYTT4HIHuj\nbxrwGikgex+p9+oo4KeS+had839Jwdc32/ju2my7qsS+lUV1NhER10bE5IiY3NDQ4hx6s00UEkPv\nt8tgzr9tBk+97MTQZmbdTVUEWBHxckTcExFTI+JiUi/VCOAqAEn9gJuBJuCQiLghIu6MiM8B5wLH\nkCbEk9U/lRSwfTIi1tC65dm2f4l9NUV1zMqipm9vrs0SQ3/sJieGNjPrbqoiwCoWEU8BTwCHZUV7\nkobp7oqI4t9Et2fbwwAk9Sf1Wv0W+IekXSXtCozO6m2XlQ3Ofi5Mki81DFgoKzV8aLZV8omhz3Ri\naDOzbqUqA6zMAGB99ufC8F+p99r7FG0HkNa8OhaYlfs8kO0/Nfv5zOznp0nDgweVOPeB2XZ6h1tv\n1g6FxNDPOjG0mVm3UumV3HdqofwI4M1sXCNrJmmY7sRcz1PBlGz7aLZtJq2JVfz5VLb/7uznX8GG\n5Rh+DRwuaWKuDfWkIGwW8NctukCzdnBiaDOz7qfSuQi/J2k4cB9p7asaYBLwIdJbhZ8HiIgVki4F\nvgY8Iek6YBFwCHAKMJu0ZhXZnKufF3+RpDHZH2dHRPH+C0hvKP5e0lXAG8DHSUOEx3qRUetsTgxt\nZta9VDrA+gkpLc5ppGG9AOYC3wYuj4hXCxUj4uuSXgLOJgVENaS5Ud8DLomIN7a0ERHxgqRDSAHc\nF4B+wOPAuyLini09r1lHXHTcXsxzYmgzs25B7pwpj8mTJ8f06Z6qZVvnjZVrOOm7D/PqGyv5xacO\nYdcd6ivdJDMzy0h6LCImt6duNU9yN+txBtX05QdTDqCvE0ObmXVpDrDMqkwhMfTCJSv5xC2PsWrt\nuko3yczMOsgBllkVcmJoM7OurdKT3M2sBSfsO5I5jc38z72zGL9DHZ86fNdKN8nMzNrJAZZZFTvv\nqAnMaWrm8rufY+z2dRyz9/BKN8nMzNrBQ4RmVUwSVzgxtJlZl+MAy6zK5RNDn3nTdBYucWJoM7Nq\n5wDLrAsoJIZevnodH7vRiaHNzKqdAyyzLmL3nQby7Q2JoWc4MbSZWRVzgGXWhRyx+w5cdNxe3PPM\nq04MbWZWxfwWoVkXM+WQscxpanZiaDOzKuYAy6wLcmJoM7Pq5iFCsy6oT+9eXHPyfowdVscnf/QY\nL7y2rNJNMjOzHAdYZl1UcWLoxU4MbWZWNRxgmXVh+cTQ//YjJ4Y2M6sWDrDMurgNiaHnOjG0mVm1\n8CR3s27ghH1HMruxmW85MbSZWVVwgGXWTZx/1ATmOjG0mVlV8BChWTfhxNBmZtXDAZZZN+LE0GZm\n1cEBllk348TQZmaV5wDLrBtyYmgzs8pygGXWTTkxtJlZ5fgtQrNu7IyDxzC70Ymhzcy2NQdYZt2Y\nJC5+z168uMiJoc3MtiUPEZp1c8WJoWc3OjG0mVlnc4Bl1gPkE0N/9EYnhjYz62wVDbAk7S7pVknP\nSFoiabmkWZK+K2lcifrvkjRN0gJJKyTNlnRdcV1Ju0m6VNIjkholLZU0Q9KXJNW10papkhZLapb0\nkKS3d9a1m21rGxJDv54SQ69eu77STTIz67Yq3YM1ChgO3AlcAJwH3A2cDjyeD5wknQ78DhgLfAs4\nB/gVcDIwXdLI3Hk/CpwPzAYuBf4DeA74L+BhSQPyjZA0HngYOAi4PKtfD0yTdFR5L9msciaNHsrl\nhcTQdz7txNBmZp2kopPcI+Je4N7ickl/BG4DzgAuzorPAtYAB0dEU67uTOA64APA1Vnxz4HLImJJ\n7rT/K2lpK/FmAAAetElEQVQW8CXgY8A1uX2XAYOBSRExIzvvzcBM4DuS9gj/JrJu4sT9RjKnKSWG\nHtfgxNBmZp2h0j1YLXkx267JlS0HVgKLi+ouyLbNhYKImF4UXBX8LNu+uVCQDRkeDzxQCK6ycywD\nrgd2Aw7Ygmswq1rnHzWB90wcweV3P8fdf1tY6eaYmXU7VRFgSaqRNEzSKEnvAL4PzAduyFW7jNTj\ndpOkiZJGSnoncCXwDPDTdnzVqGz7aq5sH6A/8JcS9R/Jtg6wrFvJJ4Y+72dODG1mVm5VEWABZwKN\npKBqGrAWODQiNvzTOiLuB44EDgdmAC+T5mvNAQ6MiKWtfYGk3sCF2bl/nNs1Itu+UuKwQtnIEvuQ\ndJak6ZKmNzY2tvb1ZlWnODH0S/9cXukmmZl1G9Wy0OhU4FnSxPL9SBPYH5R0VETMBsje6JsKvECa\nl7UIOCSr+1NJJ0TEmlInz1xNmsT+xYh4Lldem21XlThmZVGdTUTEtcC1AJMnT/YcLetyGgb254Yp\nk3n/9/7C2664n0E1fdh5aC07D6ll56EDNvnzqCG11PTtXekmm5l1CVURYEXEy6QeKYCpku4AHgWu\nAo6X1A+4GWgCDomIFVndOyW9AHyPNCH++lLnl/SfwKeBayPisqLdhX+29y9xaE1RHbNuZ4+dBvGL\nTx3Mg881Mn/xcuYvWs6s15Zy/3OvsapoKYeGgf3ZecimgVfa1jJ8uxr69K6WTnEzs8qqigCrWEQ8\nJekJ4LCsaE/SMN01ueCq4HZSgHUYJQIsSZcAXwZ+CHyixNcVJsmXGgYslJUaPjTrNnbbcSC77Thw\nk7KIoHHpqizoWsH8Rcs3/PmxFxfzm6cWsm79xo7b3r3E8O1qNgu8Cn9uGNgfSdv60szMKqIqA6zM\nAKDwz+e+2bbU+ESfou0GWXB1MXATcGYLSy08TRoePKjEvgOz7fT2Ndms+5DEDoNq2GFQDZNGb75/\n7br1LFyycpPAq9ADdv9zjTQu3XTUvX+fXoxqofdr56G1bDeg7+ZfYmbWRVU0wJK0U0T8o0T5EaSl\nFO7MimaShulOlPTFiMi/8jQl2z5adI6LSMHVLcBHI6LkstURsUzSr4H3SZoYEU9mx9eTJt/PAv66\nhZdo1m316d1rQ3BUyso163i5KPAq/PnxFxfzxsq1m9T3/C8z605UyfUzJd1JWsn9PtLaVzXAJOBD\nZJPYc5PcPw98DZhHWli0MMn9FNKbhPtHxBtZ3bNJC4m+RHpzsDi4ejUi/pBrx66kIGoNad7XG8DH\ngb2BYyNiWlvXMnny5Jg+3R1dZu21ZMUa5i9avnkQtjgNR3r+l5lVG0mPRcTkdtWtcID1QVJanIlA\nAxDAXFJKnMsj4tWi+h8Gzs7q15DmRt0FXBIRjbl6N5ImvbfkwYg4vOjce5ICuMOAfsDj2Xnvac+1\nOMAyK5/W5n/NX7ychUtWev6XmW1zXSbA6k4cYJltO63N/5q/eEXH5n8NqWW7Ws//MrO2dSTAquZJ\n7mZmJZV7/tfAmj7sPKSWXYZ6/peZlYcDLDPrdmr69mbXHQay6w4DS+5vaf7XC43LvP6XmZWFAywz\n63G2G9CX7UZux5tHbrfZvoigcdkq5i9akQVgy3lpkdf/MrOOcYBlZpYjiR0G1rDDwBomjR6y2f6y\nrv/l+V9m3ZYDLDOzDvD8LzNrDwdYZmZl5PlfZgYOsMzMtinP/zLrGRxgmZlVCc//Mus+HGCZmXUR\nnTX/q7j3a5ehtZ7/ZbaVHGCZmXUTWzr/a3ZjMw881+j5X2Zl5ADLzKyH6Oj8rw29Xy95/pdZRznA\nMjOzbTb/a8ywOsYOq/Pwo3V7DrDMzKxN5Z7/NXLwAMY1pGBr3LA6xjbUM25YHSMGD6B3L/d8Wdfn\nAMvMzLZae+d/zW1qZm5TM3MalzG3qZk7H3+Fpas2Bl/9+vRi7PYp8BrbkIKvcQ11jBtWz5C6ftvq\ncsy2mgMsMzPrdC3N/4oImpat3hBwzWlqZk5jM8+/tpR7nnmVtbl5X4Nr+6bermH1WdBVx7iGekZv\n7zcerfo4wDIzs4qRRMPA/jQM7M9bx22/yb6169Yzf/EK5jYtY05jIfhaxp9eaOSOx1/OnSMNOY4d\nVsf4hvo07JgNP47YbgC9PORoFeAAy8zMqlKf3r3SUOGwOt6+x6b7lq1ay7ymjUHX3Kzn6/bp82le\nvW5Dvf59em0ScI0bVs/YhjrGD6v3QqvWqRxgmZlZl1Pfvw9vbmHIsXHpqg1DjYXer2cXLuX3Mzcd\nchxa1y8bckxDjYVAbPT2tfTv4yFH2zoOsMzMrNuQxA6DathhUA0HFg05rlm3nvmLlmeBVzNzsuDr\ngecbuf2xjUOOvQQjhwxIvV3D6hjfsHHe106DajzkaO3iAMvMzHqEvr17Ma6hnnEN9ZvtW7pyzYY3\nHGc3bnzT8dF5i1ieG3Ic0Lc3Y4ZtfLsx3/u13QAPOdpGDrDMzKzHG1jTl31GDWafUYM3KY8IXlu6\nitm5eV5zm5qZuWAJd8/8xyar2w+r77fJPK9CELbL0Dr69XFaoZ7GAZaZmVkLJLHjoBp2HFTDweOH\nbbJv9dr1vJSt7ZWfaH/vs6/RNH3jyva9BDsPrd2wxESaZJ/W+dppUI1TCnVTDrDMzMy2QL8+vdh1\nh3p23aEe2HGTfUtWrMneclzG3MZmZjc1M7exmUfmLGLFmo1DjrX9ejNm+7pN1vUqLLI6qMZDjl2Z\nAywzM7My225AXybuPJiJO2865Lh+ffDq0pWbrOs1t6mZp15ewm+fXkhuxJFh9f1zgdfGifY7D6n1\nkGMX4ADLzMxsG+nVSwzfbgDDtxvAIbtuOuS4au06XvrncuYUpRP6w99f5Z/NqzfU691L7DK0NpfH\nMc37GtdQxw4D+3vIsUo4wDIzM6sC/fv0ZsKOA5mw4+b5HJcsX5OGG3MT7Wc3LuPh2U2sXLN+Q726\nfr0ZW+jtyuVxHNtQR31//8rflny3zczMqtx2tX3Zb5ch7LfLkE3K168PFr6xkrmNG9f1mtPUzIz5\ni/nNUwuI3JDjDgP7b1hWIr/MxM5Da+nb20OO5VbRAEvS7sBFwP7ACKAv8ArwB+AbETGnqP67gPOB\nvYEhwALgPuCyEnV7AecC/waMARqB24CLIqK5hbZ8HTgM6Ac8DlwcEfeV6XLNzMzKqlcvMXLwAEYO\nHsChEzYdcly5Zh0vLVrOnMZluZXtm7n7bwtZvHzNhnp9siHH4nW9xjXU0VDvIcctVekerFHAcOBO\n4GVgLSl4+ghwsqT9C4GTpNOBm4BZwLeAJuBNwFnASZL2johXcue+CvhMdu4rgT2zn/eTdFREbOhT\nlTQeeDj7/suBJcDHgWmSjomIezrp+s3MzDpFTd/e7LbjQHYrMeS4uHn1ZnO95jY189CsJlat3Tjk\nOLB/n2zIcdP1vcYOq6POQ46tUuT7D6uEpA+QepsujYiLs7I/AW8BRkREU67umcB1wPkRcXVW9ibg\naeDOiDgpV/ccUnB2SkT8OFd+G3ASMCkiZmRl9cBMYCWwR7RxoyZPnhzTp0/f6ms3MzOrlPXrgwVL\nVqShxsLaXlnv14IlKzYZctxpUM2GJSXy871GDRlAn2465CjpsYiY3J661Rp+vpht1+TKlpOCncVF\ndRdk2/yw34cBAVcX1b0O+BpwKvBjAEl1wPHAA4XgCiAilkm6HrgUOAD465ZejJmZWVfQq5cYNaSW\nUUNqedtuDZvsW7lmHfP+2ZzN92rO5nst466nFrJkxcZf1317F95yrM/yOG4cdhxW36/HDDlWRYAl\nqQaoB2qAvUhzoeYDN+SqXQbcBdwk6QrSEOGbScN/zwA/zdU9AFhPUVAUESslzcj2F+wD9Af+UqJp\nj+TO5wDLzMx6rJq+vdljp0HssdOgzfYtal7N3KZlm+RxnNvUzB+fb2T1utyQY02fTRZULcz7Gjus\njtp+WxGSzJ4NV14JP/oRLFsG9fVw6qnw7/8O48dv+Xm3QlUEWMCZwLdzP08HDo2IhYWCiLhf0pHA\n7cApubq/BT4cEUtzZSOApohYxeZeAQ6W1C8iVmd1C+Wl6gKMLNVoSWeR5oCxyy67tHRtZmZm3drQ\nun4MrRvKpNFDNylftz5Y8PqKzXI5/t+cf3LnE5v+2h2+XU0u4KrfsMjqqCG19O7VSq/X734H738/\nrFmTPgBLl8L118NNN8HPfw7HHFPuS25TtQRYU4FnSb1Y+wHnAA9mk9FnA0h6e1bvBeBiYBFwSFb3\np5JOiIhCH2UtUCq4gjTMWKizOtvSQv183c1ExLXAtZDmYLV9mWZmZj1H715i56G17Dy0lsN333Tf\nitXrNkyuL/R4zW5q5pczFrB05doN9fr17sUu29duWFR1fG6y/dB/zEfvfz8sX775lxcCrve/H556\napv3ZFVFgBURL5PeIgSYKukO4FHSm4DHS+oH3EwaFjwkIlZkde+U9ALwPeAM4PqsfDmwQwtfV5Or\nk9/2b0ddMzMzK4MB/Xqz14hB7DVi0yHHiOCfzas3BF5zmjbO+7r/uddYs25jf8bX7v1fTlq5mlaz\nNq5ZA1ddBddc0zkX0oKqCLCKRcRTkp4grUkFaYmFkcA1ueCq4HZSgHUYGwOsBcBekvqXGCYcSRo+\nXJ2rWygvVigrNXxoZmZmZSaJYfX9GVbfnwPGbDrkuHbdel55fcWGSfYnfut++q5f28KZMmvWwC23\nOMDKGUCaqA5sCE57l6jXp2gLqffrHaRlHR4qFGaT6fcF/pir+zRpePCgEuc+MNt6/QUzM7MK69O7\nF6O3r2P09nUcsTuwsp0DTMuWdWq7SqnoQhWSdmqh/AjSG4L3ZkUzScN0J0oaXFR9SrZ9NFf2MyCA\n84rqfpw0n+rWQkFELAN+DRwuaWKuDfWkyfez8BuEZmZm1ae+vrz1yqjSPVjfkzSclO7mRdKcp0nA\nh0ipbT4PEBErJF1KWsPqCUnXsXGS+ynAbDYODxIRT0v6DvBpSb8gvWlYWMn9QbI1sHIuAI4Efi/p\nKuANUjA2Eji2rUVGzczMrAJOPTW9LbhmTct1+vaF007bdm3KVHQld0kfBE4HJgINpF6nucDvgMsj\n4tWi+h8Gzs7q15DmRt0FXBIRjUV1e5N6sM4i5SJsIvVsXZT1WhW3ZU9SAJfPRXhJe9PkeCV3MzOz\nbWz2bNhnn9JvERbU1pbtLcKOrORelalyuiIHWGZmZhVQah0sSD1XffuWdR2sjgRY3TNZkJmZmfUM\nxxyTeqjOOgsGDYJevdL2rLNSeQUWGQX3YJWNe7DMzMy6N/dgmZmZmVWQAywzMzOzMnOAZWZmZlZm\nDrDMzMzMysyT3MtEUiNpsdTOMIy0jpe1n+9Zx/medZzvWcf5nnWc71nHdOb9Gh0RDe2p6ACrC5A0\nvb1vLVjie9Zxvmcd53vWcb5nHed71jHVcr88RGhmZmZWZg6wzMzMzMrMAVbXcG2lG9AF+Z51nO9Z\nx/medZzvWcf5nnVMVdwvz8EyMzMzKzP3YJmZmZmVmQMsMzMzszJzgGVmZmZWZg6wKkDSBZJulzRH\nUkiat4XnebekhyU1S1qUnXNsmZtbFcpxzyQ9kB1b6lPxNVPKSdJuki6V9IikRklLJc2Q9CVJdR04\nT096xrb6nvWkZwxA0u6SbpX0jKQlkpZLmiXpu5LGdeA8PeI5K8f96mnPWCmSanO/C67pwHHb9Dnr\n01kntlZ9FVgEPA4M3pITSHof8HPgSeA/gO2A84A/S5ocEQvK1NZqsdX3LNMEnF+ifM5WnLMafRQ4\nG/gVcCuwBjgC+C/gg5IOjIgVrZ2gBz5jW33PMj3lGQMYBQwH7gReBtYCewMfAU6WtH9EtHrdPew5\n2+r7lelJz1gplwLtWk29oCLPWUT4s40/wLjcn/8GzOvg8X2BV0ipeepz5fsC64BrK32N1XbPsuMe\n2JLjuuIHmAxsV6L8v4AAPt3G8T3xGduqe5bV7THPWBv34QPZPftKG/V63HO2Nfcrq9ujnzFgf1Jg\n+tnsnl3TjmMq8px5iLACon3/QmnNYcAI4PqIWJY77wzSf3z/KqnvVn5HVSnDPdtAUi9JgySpXOes\nNhExPSKWlNj1s2z75jZO0ROfsa29Zxv0hGesDYW8rGvaqNfjnrMWtPd+bdATnzFJvYHrgLuBX3Tg\n0Io8Zw6wuqYDsu1fSux7BBgE7LbtmtOljASWAUuAZZJ+IWmPCrdpWxqVbV9to56fsY3ae88Ketwz\nJqlG0jBJoyS9A/g+MB+4oY1De+RzthX3q6DHPWOZ84E9gE938LiKPGeeg9U1jci2r5TYVygbCczc\nNs3pMuYCfwaeInULv5X0H+qRkg6NiKcr2bjOlv3r70JS9/qP26juZ4wO3zPouc/YmcC3cz9PBw6N\niIVtHNdTn7MtvV/QQ5+xbDL6V4BLI2KepDEdOLwiz5kDrK6pNtuuKrFvZVEdy0TER4qKfi7pV6Qu\n4m8CR2/zRm1bVwMHAV+MiOfaqOtnLOnIPevJz9hU4FmgHtgPOAd4UNJRETG7leN66nO2pferJz9j\n/0uaxP/NLTi2Is+ZA6yuaXm27V9iX01RHWtFRDwk6Y/AEZIGRPveEutyJP0n6V+510bEZe04pMc/\nY1twz0rqCc9YRLxMeisOYKqkO4BHgauA41s5tEc+Z1txv1o6X7d+xiSdSgoc3xYR7Z6nllOR58xz\nsLqmwuukI0vsK5SV6gq10uYBvYEhFW5Hp5B0CfBl4IfAJ9p5WI9+xrbwnrVmHt34GSsWEU8BT5Am\nF7emRz9nBR24X62ZRzd8xiT1J/Va/Rb4h6RdJe0KjM6qbJeVtbZ8T0WeMwdYXdOj2fagEvsOBN4A\nnt92zenyJpDm2CyqdEPKLQsULgZuAs6M7N3kduixz9hW3LPWdNtnrBUDgPVt1Omxz1kJ7blfremu\nz9gA0ppXxwKzcp8Hsv2nZj+f2co5KvKcOcCqcpKGS9pDUn58+EFgIXCmpPpc3YnA4cDtW9iN2i2U\numeStssmLBfXPRY4BPhDRKws3t+VSbqIFCjcAnw0Ikr+z9vP2EZbc8966DO2UwvlR5CWtbg3V9bj\nn7OtvV898RkDmknrhBV/PpXtvzv7+VdQXc+ZyvOPM+sISaexsXvzHKAfcGX284sRcUuu7o3AGcAR\nEfFArvwDpPV5niStCzKI9AprAJMiolt1q2/tPZN0Iqmb+dekiZJrgbeQ/vWzCDgkIrrNv5QlnQ1c\nA7xEeguuOFB4NSL+kNW9ET9jW33PetozBiDpTtLK5PeR1nKqASYBH2LjNc/O6t5ID3/OtvZ+9cRn\nrCXZW4Rzge9ExKdz5TdSLc9ZZ6226k+rq8o+kP2llvo8UFT3xqz88BLnOY60hsdyYDEpDcD4Sl9f\nNd4zYE/gNmA2af2YVdmfvwOMrPT1dcL9urGV+7XJPfMzVp571tOeseyaPwj8hrSG00pgBfB30j9+\ndmzh/vbY52xr71dPfMZauZdjKLGSezU9Z+7BMjMzMyszz8EyMzMzKzMHWGZmZmZl5gDLzMzMrMwc\nYJmZmZmVmQMsMzMzszJzgGVmZmZWZg6wzMzMzMrMAZaZbTOSIltpucuRVCvpW5JekrRO0rxKt6m9\nJI3J7v0lrZWZWfk4wDLr4iQdnv2iDEkfb6FOSPrNtm5bN/N5UpqmnwFTgPNaq5z7Oyl8VkqaJemb\nkoZug/Z2miw4u0TSvpVui1m16lPpBphZWV0i6UcRsaLSDemGjgaejoj/6MAxM9iYM3Mo8G5S/rOj\nJU2KiNVlbmNHvAgMIOWz66gxpKTY80jXaGZF3INl1n1MB0bQRs9KTyGpt6TaMp5yJ1JC3Y54JSJ+\nlH2+FRHvIuWiezNwQksHKanfira2KZKVEbElAVan2RbXbrYtOMAy6z5uAx4DPi9p+7YqtzQfStKU\nbN/hubJLsrK9siGuBZKaJd0vaa+szkmSHpe0QtI8SWe18t1HSXpE0nJJ/5D0P6V+qUraTtLXJb0g\naZWkRkk/kTSuhTYfJelCSbNJyXQ/2MY96CPp85L+ng3h/VPSnZL2Lj43MBY4LDfkd0lr527FtGy7\na3b+whDvFElnS/p71vbP5dowQdItkhZKWp3d3ysk1ZW4pkMl/Tn7e3hV0jVAqXvb4hys7O/yAUmv\nZ39Hz2Xzz/pJmgLcn1X9Ye5+PJA7vk7SZZJmZ39v/5B0s6TRRd/T6rVLepOk2yW9kjvP/ZKO7cD9\nNqsIDxGadR8BfAH4A/Al4LOd8B03AcuAy4AG4N+B30u6CPhv4HvAD4CPAd+X9PeI+FPROfYH3g9c\nB9wMHAF8BnizpKMjYj2k4Ap4GNglO+dMYDjwKeD/JE2OiBeLzv0NoG927jeA59q4nltJQdgfsrbv\nBJwN/EXSv0TEE8AfgdOAq4Cm7DoBnmrj3C2ZkG2bisrPA7bP2v4PYD6ApEnAfcDrwPeBV4CJpHt2\niKTDImJNVvetwD3AUuDr2TEfIt3ndpH038AXgb+TrnkhMB44CbiIdD++mtW5FngoO/TV7Pi+pCDy\nEODnpCHSCcAngXdkf28vt3Xt2T8S7sv2/y9pSHMYMBl4K3BXe6/JrCIiwh9//OnCH+BwUnD1uezn\n35N6AUbn6gTwm6LjArixxPmmZPsOz5VdkpX9GlCu/DNZ+VJg51x5Q9aGn5T4zgBOLCr/n6z8Q0Vl\nK4CJRXVHk4KnG0u0+Tmgtp337ejsmJ8VXdNE0rykh4rqzwMe6MDfS5ACjWHZZwJp/tVqUuCzQ9Hf\n36JCWdF5ngSeBQYWlb83O25Kruzh7Py75cr6AX/N6l6SKx9TouwtWdl9QE3R96lwn3JtnlKivR/P\n9l1eVH5sVn5LiWd3s2sHjs/2fbDS/43548+WfDxEaNb9fJ70S/U/O+Hc34qIyP1c6L34ZUTMLxRG\nRCMp2JnA5p6LiKlFZV/Ltu+FNA8HOIXUW/KKpGGFD9AMPAK8o8S5vxcRy9t5Le/Ntv+dv6aIeJIU\nSB4qqaGd52rJO4DG7PM88E1Sz9A7IuK1oro3F5dlQ5X7AD8G+hfdhz+R7sU7sro7AAeR/i6ez13P\nalJPVHuckm0viIiV+R2Racc53gusJ/Vy5o+/izQh/gRJxb97Nrt2YEm2PUbSoHa13qyKOMAy62Yi\nDWv9BDhF0j5lPv2cop8XZ9u5JeouJg37FHumuCAiFpJ6dQpzqxqyY/MBSv5zNLBjiXM/X6KsJWNJ\ngcBm7SENRxbqbI3/I7X1aOBtpF7FfSPiryXqlmr7ntn2K2x+D14D6th4Hwr37tkS5/l7O9s7gdRr\n9GQ765cyFlgQEYtL7JsJDCT16OVtdu0R8SBpaHMK0JTNK/tKYc6fWbXzHCyz7unLpHlOXweO6eCx\nrf1/YV0Hy9XB7y4+7h7SNbRXe3uvtpWmiLinnXVLtb1wH64E7m7huFKBzNYoDONuSyX/3iLiDElX\nkJ7hfyHN+fuSpPMi4ppt2UCzjnKAZdYNRcRcSd8Dzs2/DVhkEWltpmLjSpSV057FBZKGA4PZ2EPW\nSOrRGtSBAKWj5pB68fdk8wnrhV6SUj1z29KsbLuuHfeh0NY9Suxrb6/P86RgZiJp3lZLWgvA5gDv\nkjQ4Il4v0Y432HyCf8tfFPE34G/AFZIGk3oFvybpO+0csjSrCA8RmnVf/0X6ZXZ5C/ufBw5Sbq0o\nSUOAj3Ryu3aXdGJR2eez7VSASG8S3gq8RdL7S50km3O0NQrzwC7I5nwVzvtm0gTrP2VzySrpCVJw\n8YnipSlgwzITQwEi4lXS3LQTJO2Wq9OPNLm+PX6cbb+aHVf8fYX7tCzblgrQp5J+t3yh6NhjgP2A\nX2V/v62SNLR4rlYWsM0FaoGats5hVknuwTLrpiKiKRteaWmy+zXAj4D7JN1C6kH6OOl1+J06sWlP\nAz+SdB2ph+YI0nDmg6Q3+gq+RHrV/zZJt5GCh9WktwjfTVrza8qWNiIi/pCd90PAEKVUQoVlGlaS\n3pCsqIgISaeR3up7SlJhuYpa0jpa7wMuAG7MDvks8ADwZ0nfYeMyDe36f31E/FXS10kB7+OSfkZa\nNmEs6e/oLdk5/056c/RTkpZnZa9FxH1ZW84grcc2hvSiwq6k5TVeJS3v0B6nA+dLuhN4AVgDHAa8\nE7gtnK3AqpwDLLPu7ZukX2zDi3dExK2SRgCfzurNAS4lTfx+aye26XFSIPDfwCdIvWzXAF/M92xE\nxBJJh5Dm3XyQtPL5WuBl0ht015ehLadk7ZlCmufUTAr0LoyIp8tw/q0WETMk7UcKpI4n3bOlpGUj\nbgTuzdX9i6SjSW9lfoH0Jt7PSWt8tet6IuILkp4kPRf/j9QbNR/4LdlcqYhYIelDpF7Sq4H+pPt2\nX0SskfRO0jzAfyUFga8DtwNfzr9t2oYHSD1ex5Ge33Wk3qvPkZ4Xs6omD2GbmZmZlZfnYJmZmZmV\nmQMsMzMzszJzgGVmZmZWZg6wzMzMzMrMAZaZmZlZmTnAMjMzMyszB1hmZmZmZeYAy8zMzKzMHGCZ\nmZmZldn/B25QMfQN2GGJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e568d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 18, 'lines.markersize': 10})\n",
    "\n",
    "#We're looking for the model with the smallest AIC, we can do the same for BIC \n",
    "aic = models.apply(lambda row: row[1].aic, axis=1)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(aic)\n",
    "plt.plot(aic.argmin(), aic.min(), \"or\")\n",
    "plt.xlabel('Number of Predictors')\n",
    "plt.ylabel('AIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression with regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A regression model that uses L1 regularization technique is called Lasso Regression and model which uses L2 is called Ridge Regression. The key difference between these two is the penalty term.\n",
    "\n",
    "As mentioned in the lectures Ridge regression adds “squared magnitude” of coefficient as penalty term to the loss function while Lasso Regression adds “absolute value of magnitude” of coefficient as penalty term to the loss function.\n",
    "\n",
    "Let's use the the breast cancer wisconsin dataset to showcase an example of these concepts in practise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the Data\n",
    "\n",
    "# Load the diabetes dataset\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "\n",
    "# Create X from the features\n",
    "X = breast_cancer.data\n",
    "\n",
    "# Create y from output\n",
    "y = breast_cancer.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Because the regularization penalty is comprised of the sum of the absolute value of the coefficients, we need to scale the data so the coefficients are all based on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_scaled = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split the data into test and training sets, with 30% of samples being put into the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The usefulness of L1 is that it can push feature coefficients to 0, creating a method for feature selection. In the code below we run a logistic regression with a L1 penalty four times, each time decreasing the value of C. We should expect that as C decreases, more coefficients become 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10\n",
      "Coefficient of each feature: [[ 0.         -0.02129455  0.          0.         -0.25069553  5.97120463\n",
      "  -3.96052598 -1.67526673 -1.26841671 -1.38008329 -5.85135299  1.40262757\n",
      "   0.         -6.22134392  0.67836847  1.55874925 -0.0511146  -3.25346183\n",
      "   0.          6.99649252 -1.96370685 -3.56084753 -2.59363438 -1.54233321\n",
      "  -0.30370845  2.13490801 -2.75139085 -2.13019139 -0.07662989 -5.99238397]]\n",
      "\n",
      "Training accuracy: 0.9899497487437185\n",
      "Test accuracy: 0.9298245614035088\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[ 0.         -0.36687407  0.          0.          0.          0.\n",
      "  -0.01840872 -0.241033   -0.29812589  0.         -2.97785722  0.\n",
      "   0.          0.          0.          0.80013529  0.          0.\n",
      "   0.          0.56691958 -0.80534134 -0.98665585 -0.18633767 -2.35583323\n",
      "  -0.35425338  0.         -1.20984782 -2.27916274 -0.23946806  0.        ]]\n",
      "\n",
      "Training accuracy: 0.9874371859296482\n",
      "Test accuracy: 0.9649122807017544\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[ 0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.41673352  0.          0.         -0.58846178  0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.         -1.40969585 -0.51666455 -0.29181069  0.\n",
      "  -0.09032182  0.          0.         -1.17645626 -0.13192404  0.        ]]\n",
      "\n",
      "Training accuracy: 0.9773869346733668\n",
      "Test accuracy: 0.9707602339181286\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Training accuracy: 0.3743718592964824\n",
      "Test accuracy: 0.3684210526315789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C=c)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('')\n",
    "    print('Training accuracy:', clf.score(X_train, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Notice that as C decreases the model coefficients become smaller until at C=0.001 most of the coefficients are zero. This is the effect of the regularization penalty becoming more prominent.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10\n",
      "Coefficient of each feature: [[ 0.32465289 -0.75854885  0.0654676   0.08284629  0.08617085  2.17528557\n",
      "  -1.53859524 -1.37110113 -0.81045275 -0.66573156 -3.37286883  0.6807736\n",
      "  -1.73375065 -2.64152224  0.45977877  2.18775866 -0.67715627 -1.46180092\n",
      "   0.32119399  3.33222802 -1.84675827 -1.77031262 -1.52123043 -1.87660109\n",
      "  -0.67455671  1.14386206 -1.93999378 -1.77546792 -0.38899862 -2.61745498]]\n",
      "\n",
      "Training accuracy: 0.9899497487437185\n",
      "Test accuracy: 0.9473684210526315\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[-0.25840359 -0.5880958  -0.27416781 -0.3520136  -0.13354014  0.41468589\n",
      "  -0.67227465 -0.74147194 -0.3800354   0.02991019 -1.35226951  0.1408772\n",
      "  -0.91142999 -0.98366515  0.25770894  0.92407813 -0.13327435 -0.34673898\n",
      "   0.16811638  0.91286138 -0.84755236 -0.91017679 -0.73591256 -0.8511223\n",
      "  -0.56846902  0.17687916 -0.8257333  -1.08177893 -0.48462679 -0.60818805]]\n",
      "\n",
      "Training accuracy: 0.9899497487437185\n",
      "Test accuracy: 0.9824561403508771\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[-0.32184796 -0.36544135 -0.31927795 -0.33408121 -0.15677647 -0.0491755\n",
      "  -0.34777988 -0.41078928 -0.16023734  0.13299093 -0.5206605  -0.00333697\n",
      "  -0.42390816 -0.40698435  0.07928678  0.22002661  0.03324865 -0.08133137\n",
      "   0.08412805  0.27318087 -0.46236629 -0.47450623 -0.43659675 -0.44267085\n",
      "  -0.33457249 -0.15147941 -0.3897604  -0.50111401 -0.3257941  -0.18964742]]\n",
      "\n",
      "Training accuracy: 0.9874371859296482\n",
      "Test accuracy: 0.9707602339181286\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[-0.07010557 -0.04181399 -0.07080026 -0.06751553 -0.03300431 -0.05155596\n",
      "  -0.06317764 -0.07375959 -0.03112675  0.00872889 -0.05371068  0.00320459\n",
      "  -0.05111051 -0.05029802  0.01009262 -0.0154888  -0.01173773 -0.02901612\n",
      "   0.00358283  0.0054557  -0.07643255 -0.04972934 -0.07629201 -0.07134713\n",
      "  -0.04446384 -0.05534292 -0.06209155 -0.07808761 -0.04669891 -0.02976804]]\n",
      "\n",
      "Training accuracy: 0.9597989949748744\n",
      "Test accuracy: 0.9005847953216374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l2', C=c)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('')\n",
    "    print('Training accuracy:', clf.score(X_train, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of each feature: [[-0.25840359 -0.5880958  -0.27416781 -0.3520136  -0.13354014  0.41468589\n",
      "  -0.67227465 -0.74147194 -0.3800354   0.02991019 -1.35226951  0.1408772\n",
      "  -0.91142999 -0.98366515  0.25770894  0.92407813 -0.13327435 -0.34673898\n",
      "   0.16811638  0.91286138 -0.84755236 -0.91017679 -0.73591256 -0.8511223\n",
      "  -0.56846902  0.17687916 -0.8257333  -1.08177893 -0.48462679 -0.60818805]]\n",
      "\n",
      "Training accuracy: 0.9899497487437185\n",
      "Test accuracy: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "#Let's apply a regular logistic regression without regularization to the data\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print('Coefficient of each feature:', clf.coef_)\n",
    "print('')\n",
    "print('Training accuracy:', clf.score(X_train, y_train))\n",
    "print('Test accuracy:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's say we want to break down the data from 30 dimensions to 3 dimensions – so that we can visualize it. We'll use PCA for that purpose. \n",
    "\n",
    "As mentioned in the lecture, PCA is great for finding patterns while trying to retain the variation in the data set. The artifacts of such an analysis is called principal components, which we use to try to explain as much of the variance (in the data set) as possible. This means that some of the variance may be lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Use PCA to fit then transform the data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_scaled)\n",
    "decomposed_data = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "W will most likely not retain all of the variance. We can view it using the *explained_variance_ratio_* field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44272026 0.18971182 0.09393163] 0.7263637090890609\n"
     ]
    }
   ],
   "source": [
    "# Get explained variance.\n",
    "print(pca.explained_variance_ratio_, sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Each element in the array shows you how much variance each principal component can explain. Notice that the last principal component/dimension only retains 9.39% of the variance. In some cases, adding additional dimensions will not have a significant impact.\n",
    "\n",
    "In this case, we are able to retain 72.63% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Visualize principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we want to understand how each feature correlates with each principal component, we can visualize it using a heat map. The first thing we need to do is to configure the Plotly library. This is easily done as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will then create the heat map data using the Heatmap function (within go). The heat map data is created by supplying the principal components as the z-axis. The x-axis is the feature and the y-axis is the principal component. Finally, we can plot the heat map using the iplot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "heatmap",
         "x": [
          "mean radius",
          "mean texture",
          "mean perimeter",
          "mean area",
          "mean smoothness",
          "mean compactness",
          "mean concavity",
          "mean concave points",
          "mean symmetry",
          "mean fractal dimension",
          "radius error",
          "texture error",
          "perimeter error",
          "area error",
          "smoothness error",
          "compactness error",
          "concavity error",
          "concave points error",
          "symmetry error",
          "fractal dimension error",
          "worst radius",
          "worst texture",
          "worst perimeter",
          "worst area",
          "worst smoothness",
          "worst compactness",
          "worst concavity",
          "worst concave points",
          "worst symmetry",
          "worst fractal dimension"
         ],
         "y": [
          "PC 1",
          "PC 2",
          "PC 3"
         ],
         "z": [
          [
           0.21890244355496963,
           0.10372457789787097,
           0.22753729284152127,
           0.2209949852047848,
           0.1425896938834528,
           0.23928535372003956,
           0.2584004809509858,
           0.2608537584419166,
           0.13816695886942126,
           0.06436334645521166,
           0.2059787759884657,
           0.01742802845404862,
           0.2113259165848421,
           0.20286963534760877,
           0.014531452118619084,
           0.1703934508429427,
           0.15358978935510037,
           0.18341739780455912,
           0.04249842172980999,
           0.10256832202427289,
           0.2279966343110976,
           0.10446932548679344,
           0.23663968081108772,
           0.22487053277468974,
           0.1279525613304458,
           0.210095880184679,
           0.22876753271796224,
           0.2508859718648407,
           0.12290455667130488,
           0.1317839432536157
          ],
          [
           -0.2338571196348376,
           -0.05970606179266748,
           -0.2151813477277457,
           -0.2310766962830577,
           0.18611306207633646,
           0.15189162893516545,
           0.06016538768448053,
           -0.03476750462236948,
           0.1903488065449801,
           0.3665754638370617,
           -0.10555216271075207,
           0.0899796565308006,
           -0.08945725159865821,
           -0.15229262039114416,
           0.2044304555696475,
           0.23271592580538444,
           0.19720731398488187,
           0.13032149040798838,
           0.1838479920300987,
           0.2800920332710266,
           -0.2198663860246636,
           -0.04546730089381176,
           -0.19987843395016167,
           -0.2193518617343856,
           0.17230434009269066,
           0.14359317093947419,
           0.09796412258036383,
           -0.008257288162707894,
           0.14188332414623492,
           0.2753394380492664
          ],
          [
           -0.008531315900602111,
           0.06454974233704061,
           -0.009314302693784082,
           0.02869943311477034,
           -0.104292136737703,
           -0.07409169443320265,
           0.00273368889611735,
           -0.025563508871105037,
           -0.04024015924276874,
           -0.022574066089617185,
           0.2684814582697001,
           0.3746338197324288,
           0.2666454739992319,
           0.21600648665278238,
           0.30883895994202554,
           0.15477953706995556,
           0.176463544187135,
           0.22465798925072716,
           0.28858434413070416,
           0.21150373659068414,
           -0.04750695590779317,
           -0.04229780807652342,
           -0.0485464791758647,
           -0.011902306725387923,
           -0.2597975420164049,
           -0.236075607314525,
           -0.17305738022724548,
           -0.1703437454968051,
           -0.2713124933586568,
           -0.23279112013055503
          ]
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"69ea868f-2c41-4cb0-8787-78b9fd39e562\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"69ea868f-2c41-4cb0-8787-78b9fd39e562\", [{\"x\": [\"mean radius\", \"mean texture\", \"mean perimeter\", \"mean area\", \"mean smoothness\", \"mean compactness\", \"mean concavity\", \"mean concave points\", \"mean symmetry\", \"mean fractal dimension\", \"radius error\", \"texture error\", \"perimeter error\", \"area error\", \"smoothness error\", \"compactness error\", \"concavity error\", \"concave points error\", \"symmetry error\", \"fractal dimension error\", \"worst radius\", \"worst texture\", \"worst perimeter\", \"worst area\", \"worst smoothness\", \"worst compactness\", \"worst concavity\", \"worst concave points\", \"worst symmetry\", \"worst fractal dimension\"], \"y\": [\"PC 1\", \"PC 2\", \"PC 3\"], \"z\": [[0.21890244355496963, 0.10372457789787097, 0.22753729284152127, 0.2209949852047848, 0.1425896938834528, 0.23928535372003956, 0.2584004809509858, 0.2608537584419166, 0.13816695886942126, 0.06436334645521166, 0.2059787759884657, 0.01742802845404862, 0.2113259165848421, 0.20286963534760877, 0.014531452118619084, 0.1703934508429427, 0.15358978935510037, 0.18341739780455912, 0.04249842172980999, 0.10256832202427289, 0.2279966343110976, 0.10446932548679344, 0.23663968081108772, 0.22487053277468974, 0.1279525613304458, 0.210095880184679, 0.22876753271796224, 0.2508859718648407, 0.12290455667130488, 0.1317839432536157], [-0.2338571196348376, -0.05970606179266748, -0.2151813477277457, -0.2310766962830577, 0.18611306207633646, 0.15189162893516545, 0.06016538768448053, -0.03476750462236948, 0.1903488065449801, 0.3665754638370617, -0.10555216271075207, 0.0899796565308006, -0.08945725159865821, -0.15229262039114416, 0.2044304555696475, 0.23271592580538444, 0.19720731398488187, 0.13032149040798838, 0.1838479920300987, 0.2800920332710266, -0.2198663860246636, -0.04546730089381176, -0.19987843395016167, -0.2193518617343856, 0.17230434009269066, 0.14359317093947419, 0.09796412258036383, -0.008257288162707894, 0.14188332414623492, 0.2753394380492664], [-0.008531315900602111, 0.06454974233704061, -0.009314302693784082, 0.02869943311477034, -0.104292136737703, -0.07409169443320265, 0.00273368889611735, -0.025563508871105037, -0.04024015924276874, -0.022574066089617185, 0.2684814582697001, 0.3746338197324288, 0.2666454739992319, 0.21600648665278238, 0.30883895994202554, 0.15477953706995556, 0.176463544187135, 0.22465798925072716, 0.28858434413070416, 0.21150373659068414, -0.04750695590779317, -0.04229780807652342, -0.0485464791758647, -0.011902306725387923, -0.2597975420164049, -0.236075607314525, -0.17305738022724548, -0.1703437454968051, -0.2713124933586568, -0.23279112013055503]], \"type\": \"heatmap\"}], {}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"69ea868f-2c41-4cb0-8787-78b9fd39e562\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"69ea868f-2c41-4cb0-8787-78b9fd39e562\", [{\"x\": [\"mean radius\", \"mean texture\", \"mean perimeter\", \"mean area\", \"mean smoothness\", \"mean compactness\", \"mean concavity\", \"mean concave points\", \"mean symmetry\", \"mean fractal dimension\", \"radius error\", \"texture error\", \"perimeter error\", \"area error\", \"smoothness error\", \"compactness error\", \"concavity error\", \"concave points error\", \"symmetry error\", \"fractal dimension error\", \"worst radius\", \"worst texture\", \"worst perimeter\", \"worst area\", \"worst smoothness\", \"worst compactness\", \"worst concavity\", \"worst concave points\", \"worst symmetry\", \"worst fractal dimension\"], \"y\": [\"PC 1\", \"PC 2\", \"PC 3\"], \"z\": [[0.21890244355496963, 0.10372457789787097, 0.22753729284152127, 0.2209949852047848, 0.1425896938834528, 0.23928535372003956, 0.2584004809509858, 0.2608537584419166, 0.13816695886942126, 0.06436334645521166, 0.2059787759884657, 0.01742802845404862, 0.2113259165848421, 0.20286963534760877, 0.014531452118619084, 0.1703934508429427, 0.15358978935510037, 0.18341739780455912, 0.04249842172980999, 0.10256832202427289, 0.2279966343110976, 0.10446932548679344, 0.23663968081108772, 0.22487053277468974, 0.1279525613304458, 0.210095880184679, 0.22876753271796224, 0.2508859718648407, 0.12290455667130488, 0.1317839432536157], [-0.2338571196348376, -0.05970606179266748, -0.2151813477277457, -0.2310766962830577, 0.18611306207633646, 0.15189162893516545, 0.06016538768448053, -0.03476750462236948, 0.1903488065449801, 0.3665754638370617, -0.10555216271075207, 0.0899796565308006, -0.08945725159865821, -0.15229262039114416, 0.2044304555696475, 0.23271592580538444, 0.19720731398488187, 0.13032149040798838, 0.1838479920300987, 0.2800920332710266, -0.2198663860246636, -0.04546730089381176, -0.19987843395016167, -0.2193518617343856, 0.17230434009269066, 0.14359317093947419, 0.09796412258036383, -0.008257288162707894, 0.14188332414623492, 0.2753394380492664], [-0.008531315900602111, 0.06454974233704061, -0.009314302693784082, 0.02869943311477034, -0.104292136737703, -0.07409169443320265, 0.00273368889611735, -0.025563508871105037, -0.04024015924276874, -0.022574066089617185, 0.2684814582697001, 0.3746338197324288, 0.2666454739992319, 0.21600648665278238, 0.30883895994202554, 0.15477953706995556, 0.176463544187135, 0.22465798925072716, 0.28858434413070416, 0.21150373659068414, -0.04750695590779317, -0.04229780807652342, -0.0485464791758647, -0.011902306725387923, -0.2597975420164049, -0.236075607314525, -0.17305738022724548, -0.1703437454968051, -0.2713124933586568, -0.23279112013055503]], \"type\": \"heatmap\"}], {}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create heat map data.\n",
    "data = go.Heatmap(z=pca.components_, \n",
    "                  x=breast_cancer.feature_names, \n",
    "                  y=['PC 1', 'PC 2', 'PC 3'])\n",
    " \n",
    "# Plot heatmap.\n",
    "plotly.offline.iplot([data], filename='heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since we created the heat map using Plotly, it is also interactive. Notice how we can hover over individual parts to discover more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
