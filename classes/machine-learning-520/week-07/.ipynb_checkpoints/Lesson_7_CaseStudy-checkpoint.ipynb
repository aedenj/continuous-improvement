{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example dealing with text data. Raw text data is an unstructured and ubiquitous type of data. Most of the world’s data is unstructured. Volumes of unstructured data, including text, are growing much faster than structured data. There are many industry estimates for the fraction of all data which is unstructured. How much text data are we talking about here? In a few years time, Twitter will have [more text data recorded](http://www.internetlivestats.com/twitter-statistics/) than all that has been written in print in the history of mankind.\n",
    "\n",
    "Given the ubiquity and volume of text data, it is not surprising that numerous powerful applications which exploit text analytics are appearing. A few of these applications are listed below.\n",
    "\n",
    "- Intelligent applications\n",
    "  - Assistants\n",
    "  - Chat bots\n",
    "- Classification\n",
    "  - Sentiment analysis\n",
    "  - SPAM detection\n",
    "- Speech recognition\n",
    "- Search\n",
    "- Information retrieval\n",
    "- Legal discovery\n",
    "\n",
    "In this tutorial we investigate two areas of text analytics:\n",
    "\n",
    "- Pre-processing text data for analysis\n",
    "- Classification of text and sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cProfile\n",
    "import argparse\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# If you get an SSL-certificate error, and you are on a MAC then you may have to navigate to: application/python3/ and\n",
    "# run/double-click on the command 'install certificates'.  Then try this again.\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first step to prepare text is to clean it.  We clean and normalize the text by performing various operations on the text. Some examples are as follows:\n",
    "\n",
    "- Make the text lowercase.\n",
    "- Remove symbols or punctuation.\n",
    "- Remove numbers. May also replace all numbers with a numeric tag, for example `<NUM>` or similar. We may also consider replacing all dates with `<DATE>` or similarly use tags `<URL>`, `<PHONE>`, `<EMAIL>`, etc...\n",
    "- Strip extra white space. White space has many forms: space, newline, or tab. There are also other rarely used unicode specifications for other white space characters.\n",
    "- Remove all non-printable unicode characters.\n",
    "- Replace accent characters.\n",
    "- Remove 'stop words'. Stop words are generally non-informative words like \"the\", \"as\", \"a\", etc.\n",
    "- Stem words to similar endings, such as \"eats\" and \"eat\".\n",
    "\n",
    "There are a few reasons to clean your text.  The primary reason is to reduce the potential vocabulary and increase the observations of specific words (or tokens). Depending on the application, the above steps should be considered carefully and only applied when it makes sense. Ask yourself if words like \"China\" and \"china\" to be different.\n",
    "\n",
    "**NOTE**: Be careful dealing with unicode characters. There are many editors and text viewers that only display printable characters but will not remove non-printable characters. Strange unicode characters can end up in data from users blindly copy/pasting text (with invisible unicode) into other text boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (8 minutes)\n",
    "\n",
    "By its very nature, text data comes unstructured and poorly organized for analysis. Typically multiple steps are required to process text into a form suitable for analysis, starting with cleaning it.\n",
    "\n",
    "Here's a horrible tweet. We're going to clean it and learn about ways to clean text data in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfiltered text: \n",
      "I <3 cleaning data $\\ \\ $, it’s my ၲ  $\\ \\ $    fAvoRitE!! 11!!! I enjoy looking for bats in the closet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horrible_tweet_text = 'I <3 cleaning data $\\ \\ $, it’s my \\u1072  $\\ \\ $    fAvoRitE!! 11!!! I enjoy looking for bats in the closet'\n",
    "print('Unfiltered text: \\n{}\\n'.format(horrible_tweet_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step by step, refine the above text. To avoid overwriting the existing string, you can create a new string from the string so far each time.\n",
    "\n",
    "- Remove any non-ASCI character. A string `x` is ASCI if `ord(x) < 128`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfiltered text: \n",
      "I <3 cleaning data $\\ \\ $, its my   $\\ \\ $    fAvoRitE!! 11!!! I enjoy looking for bats in the closet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ''.join([x for x in horrible_tweet_text if ord(x) < 128])\n",
    "print('Unfiltered text: \\n{}\\n'.format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make all the letters lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower Case text: \n",
      "i <3 cleaning data $\\ \\ $, its my   $\\ \\ $    favorite!! 11!!! i enjoy looking for bats in the closet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "print('Lower Case text: \\n{}\\n'.format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all punctuation from the text. You can use `string.punctuation` to get a string of all punctuation characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed punctuation text: \n",
      "i  3 cleaning data         its my             favorite   11    i enjoy looking for bats in the closet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "punc = string.punctuation\n",
    "text = ''.join([' ' if ele in punc else ele for ele in text])\n",
    "print('Removed punctuation text: \\n{}\\n'.format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the numbers from the text. HINT: If you are familiar with **regular expressions** you can use `re.sub` to do this easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed numbers text: \n",
      "i   cleaning data         its my             favorite       i enjoy looking for bats in the closet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = re.sub(r'\\d+', '', text)\n",
    "print('Removed numbers text: \\n{}\\n'.format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Strip the text of any extra whitespace. HINT: The `split` method might help here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed white spaces text: \n",
      "i cleaning data its my favorite i enjoy looking for bats in the closet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(text.split())\n",
    "print('Removed white spaces text: \\n{}\\n'.format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all stop words from the text. We can use `stopwords.words('english')` to get a list of stop words for the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated text: \n",
      " cleaning data   favorite  enjoy looking  bats   closet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(['' if ele in stopwords.words('english') else ele for ele in text.split()])\n",
    "print('Updated text: \\n{}\\n'.format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's now use `WordNetLemmatizer()` to reduce the words to their **stems**. HINT: Use the object's `lemmatize` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated text: \n",
      " cleaning data   favorite  enjoy looking  bat   closet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "word_list = text.split(' ')\n",
    "stemmed_words = [lmtzr.lemmatize(word) for word in word_list]\n",
    "text = ' '.join(stemmed_words)\n",
    "print('Updated text: \\n{}\\n'.format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now combine the steps outlined in the above exercise and create a function to clean text for use. We will later use this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: \"I <3 cleaning data $\\ \\ $, it’s my ၲ  $\\ \\ $    fAvoRitE!! 11!!! I enjoy looking for bats in the closet\"\n",
      "after : \"cleaning data favorite enjoy looking bat closet\"\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text, list_of_steps):\n",
    "    \n",
    "    for step in list_of_steps:\n",
    "        if step == 'remove_non_ascii':\n",
    "            text = ''.join([x for x in text if ord(x) < 128])\n",
    "        elif step == 'lowercase':\n",
    "            text = text.lower()\n",
    "        elif step == 'remove_punctuation':\n",
    "            punct_exclude = set(string.punctuation)\n",
    "            text = ''.join(char for char in text if char not in punct_exclude)\n",
    "        elif step == 'remove_numbers':\n",
    "            text = re.sub(\"\\d+\", \"\", text)\n",
    "        elif step == 'strip_whitespace':\n",
    "            text = ' '.join(text.split())\n",
    "        elif step == 'remove_stopwords':\n",
    "            stops = stopwords.words('english')\n",
    "            word_list = text.split(' ')\n",
    "            text_words = [word for word in word_list if word not in stops]\n",
    "            text = ' '.join(text_words)\n",
    "        elif step == 'stem_words':\n",
    "            lmtzr = WordNetLemmatizer()\n",
    "            word_list = text.split(' ')\n",
    "            stemmed_words = [lmtzr.lemmatize(word) for word in word_list]\n",
    "            text = ' '.join(stemmed_words)\n",
    "    return text\n",
    "\n",
    "step_list = ['remove_non_ascii', 'lowercase', 'remove_punctuation', 'remove_numbers',\n",
    "            'strip_whitespace', 'remove_stopwords', 'stem_words']\n",
    "\n",
    "print(\"before: \\\"{}\\\"\".format(horrible_tweet_text))\n",
    "print(\"after : \\\"{}\\\"\".format(preprocess(horrible_tweet_text, step_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurizing text data\n",
    "\n",
    "We the clean data we can begin to ask what is the best way to extract features from the data. There are many more approaches for text analytics and natural language processing (NLP). We only mention a few below. Note that the collection of unique words in the data is called a **corpus**. To avoid having a corpus that's too large, we can trim the corpus by keeping the most frequent $N$ words, making $N$ the size of the corpus. A **document** usually refers to a single data point with raw text, such as a tweet, a review, an invoice, etc. So our documents are made up of \"words\" that come from the corpus (ignoring any words that are not in the corpus). The question now is how do we represent such a data numerically? Here are two approaches:\n",
    "\n",
    "- The **bag of words model** is a simple and surprisingly effective model for analysis of text data. The BOW model creates a **sparse vector representation** of each word in the corpus based on the frequency of the words in the document. The order of the words is not considered, nor is the similarity between different words. Despite serious shortcomings, the model can work well in many cases.\n",
    "- We can usually do much better by using **word embeddings**, which are **dense vector respresentations** for each word in the corpus. Word embeddings are learned by examining the word's **context** (other words around it). Word embeddings are very common in **deep learning** applications of NLP, although the embeddings themselves are learned using a shallow network. If we learn word embeddings from a very large data set once, we can save and re-use these word embeddings to create features for other data sets. In fact, **pre-trained word embeddings** are trained by large companies like Google and made available for use by others. So we can load these embeddings and numerically represent a document using the average of the embeddings of the words in it. Because word embeddings are vectors, such an average would also be a vector that is a dense representation of the document.\n",
    "\n",
    "As you can see, BOW models seem too simplistic and word embeddings seem too sophisticated for now. So here's another approach that is sort of between the two in terms of difficulty. It is called TF-IDF and it is a clever way to featurize words in documents. Just like a BOW model, we begin by \"tokenizing\" the data. In BOW we then create a one-hot encoded feature for each token (or word). But in TF-IDF we first extract the relative word frequencies per document (called **term frequencies** or TF), we then multiply the term frequencies by a multiplier we call IDF. This has the effect of dampening the values for terms that appear frequently across documents, giving them less influence when we move on to the machine learning phase. Note that we used the words token, word and term almost interchangeably. Sorry for confusing you! Data scientists don't always agree on terminology. Let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text\n",
    "\n",
    "As a first step in preparing text for analysis of a document is to **tokenize** the text. In general terms, tokenization is the process dividing raw text into words, symbols and other elements, known as **tokens**. A set of tokens from all documents in the data is known as a **corpus**.\n",
    "\n",
    "As a first step in creating a corpus is reading the data set. This particular data set is comprised of 160,000 tweets. The sentiment of these tweets has been human labeled as positive or negative (4 is for positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>@elephantbird Hey dear, Happy Friday to You  A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Ughhh layin downnnn    Waiting for zeina to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@greeniebach I reckon he'll play, even if he's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@vaLewee I know!  Saw it on the news!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>very sad that http://www.fabchannel.com/ has c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment_label                                         tweet_text\n",
       "0                4  @elephantbird Hey dear, Happy Friday to You  A...\n",
       "1                4  Ughhh layin downnnn    Waiting for zeina to co...\n",
       "2                0  @greeniebach I reckon he'll play, even if he's...\n",
       "3                0              @vaLewee I know!  Saw it on the news!\n",
       "4                0  very sad that http://www.fabchannel.com/ has c..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = '../data/twitter_data.csv'\n",
    "tweet_df = pd.read_csv(data_file)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    80000\n",
       "0    80000\n",
       "Name: sentiment_label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df['sentiment_label'] = tweet_df['sentiment_label'].replace(4, 1)\n",
    "tweet_df['sentiment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = tweet_df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data set read, we need to clean then tokenize the tweets. Note that stemming can be slow on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = ['lowercase', 'remove_punctuation', 'remove_numbers', 'strip_whitespace', 'stem_words']\n",
    "tweet_df['clean_tweet'] = tweet_df['tweet_text'].map(lambda s: preprocess(s, steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@elephantbird Hey dear, Happy Friday to You  A...</td>\n",
       "      <td>elephantbird hey dear happy friday to you alre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ughhh layin downnnn    Waiting for zeina to co...</td>\n",
       "      <td>ughhh layin downnnn waiting for zeina to cook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@greeniebach I reckon he'll play, even if he's...</td>\n",
       "      <td>greeniebach i reckon hell play even if he not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@vaLewee I know!  Saw it on the news!</td>\n",
       "      <td>valewee i know saw it on the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>very sad that http://www.fabchannel.com/ has c...</td>\n",
       "      <td>very sad that httpwwwfabchannelcom ha closed d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment_label                                         tweet_text  \\\n",
       "0                1  @elephantbird Hey dear, Happy Friday to You  A...   \n",
       "1                1  Ughhh layin downnnn    Waiting for zeina to co...   \n",
       "2                0  @greeniebach I reckon he'll play, even if he's...   \n",
       "3                0              @vaLewee I know!  Saw it on the news!   \n",
       "4                0  very sad that http://www.fabchannel.com/ has c...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  elephantbird hey dear happy friday to you alre...  \n",
       "1  ughhh layin downnnn waiting for zeina to cook ...  \n",
       "2  greeniebach i reckon hell play even if he not ...  \n",
       "3                  valewee i know saw it on the news  \n",
       "4  very sad that httpwwwfabchannelcom ha closed d...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's sometimes helpful to profile such functions to find the main culprits and see if we can do anything to speed them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         46229947 function calls (46229944 primitive calls) in 18.434 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(copyto)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1009(_handle_fromlist)\n",
      "   160000    0.925    0.000   18.115    0.000 <ipython-input-13-0f7b3a1f02b1>:1(preprocess)\n",
      " 11257197    1.311    0.000    1.311    0.000 <ipython-input-13-0f7b3a1f02b1>:10(<genexpr>)\n",
      "   160000    0.596    0.000   13.329    0.000 <ipython-input-13-0f7b3a1f02b1>:23(<listcomp>)\n",
      "   160000    0.230    0.000   18.345    0.000 <string>:1(<lambda>)\n",
      "        1    0.005    0.005   18.434   18.434 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 _dtype.py:319(_name_includes_bit_suffix)\n",
      "        2    0.000    0.000    0.000    0.000 _dtype.py:333(_name_get)\n",
      "        2    0.000    0.000    0.000    0.000 _dtype.py:36(_kind_name)\n",
      "        2    0.000    0.000    0.000    0.000 _internal.py:830(npy_ctypes_check)\n",
      "        3    0.000    0.000    0.000    0.000 abc.py:137(__instancecheck__)\n",
      "        1    0.000    0.000   18.422   18.422 base.py:1078(_map_values)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1374(nlevels)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1642(is_unique)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:256(is_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4032(__contains__)\n",
      "        7    0.000    0.000    0.000    0.000 base.py:413(find)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5553(ensure_index)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5650(maybe_extract_name)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:123(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:134(_check_ndim)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:200(internal_values)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:232(mgr_locs)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:236(mgr_locs)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:2371(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:255(make_block_same_class)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:2652(get_block_type)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:2698(make_block)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:2725(_extend_blocks)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:314(dtype)\n",
      "        1    0.000    0.000    0.003    0.003 blocks.py:513(astype)\n",
      "        1    0.000    0.000    0.003    0.003 blocks.py:674(copy)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1180(maybe_castable)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1194(maybe_infer_to_datetimelike)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1303(maybe_cast_to_datetime)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1588(construct_1d_ndarray_preserving_na)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1460(is_extension_array_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1565(_get_dtype)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:1600(_is_dtype_type)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:1733(pandas_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:178(classes)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:180(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:183(classes_and_not_datetimelike)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:188(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:194(is_object_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:224(is_sparse)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:329(apply_if_callable)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:381(is_datetime64tz_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:456(is_period_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:492(is_interval_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:530(is_categorical_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:608(is_dtype_equal)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:696(is_integer_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:339(extract_array)\n",
      "        1    0.000    0.000    0.004    0.004 construction.py:390(sanitize_array)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:520(_try_cast)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:580(is_empty_data)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:1116(is_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:903(is_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:2869(__getitem__)\n",
      "       26    0.000    0.000    0.000    0.000 generic.py:10(_check)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:195(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:232(attrs)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:3529(_get_item_cache)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:5092(__finalize__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:5120(__getattr__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:5138(__setattr__)\n",
      "        1    0.000    0.000    0.003    0.003 generic.py:5390(astype)\n",
      "        2    0.000    0.000    0.000    0.000 inference.py:263(is_dict_like)\n",
      "        4    0.000    0.000    0.000    0.000 inference.py:289(<genexpr>)\n",
      "        7    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:72(isclass)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1532(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1553(from_blocks)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1564(from_array)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1575(_block)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1602(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1613(internal_values)\n",
      "        1    0.000    0.000    0.003    0.003 managers.py:366(apply)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:385(<dictcomp>)\n",
      "        1    0.000    0.000    0.003    0.003 managers.py:592(astype)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:1043(copyto)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:150(is_all_dates)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:283(full)\n",
      "        3    0.000    0.000    0.000    0.000 range.py:687(__len__)\n",
      "   160000    0.100    0.000    0.719    0.000 re.py:185(sub)\n",
      "   160000    0.135    0.000    0.192    0.000 re.py:271(_compile)\n",
      "        2    0.000    0.000    0.005    0.002 series.py:201(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:381(_constructor)\n",
      "        1    0.002    0.002   18.428   18.428 series.py:3895(map)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:398(_set_axis)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:427(dtype)\n",
      "        4    0.000    0.000    0.000    0.000 series.py:442(name)\n",
      "        4    0.000    0.000    0.000    0.000 series.py:492(name)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:540(_values)\n",
      "  2070416    2.268    0.000   10.933    0.000 wordnet.py:1873(_morphy)\n",
      "  2092191    0.815    0.000    6.385    0.000 wordnet.py:1884(apply_rules)\n",
      "  2092191    2.961    0.000    5.570    0.000 wordnet.py:1886(<listcomp>)\n",
      "  2119667    2.023    0.000    2.280    0.000 wordnet.py:1892(filter_forms)\n",
      "   160000    0.024    0.000    0.024    0.000 wordnet.py:37(__init__)\n",
      "  2070416    1.322    0.000   12.732    0.000 wordnet.py:40(lemmatize)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000   18.434   18.434 {built-in method builtins.exec}\n",
      "       42    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "   160078    0.058    0.000    0.058    0.000 {built-in method builtins.isinstance}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "185220/185217    0.025    0.000    0.025    0.000 {built-in method builtins.len}\n",
      "  1069232    0.478    0.000    0.478    0.000 {built-in method builtins.min}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "  1092023    0.120    0.000    0.120    0.000 {method 'add' of 'set' objects}\n",
      "  1092024    0.137    0.000    0.137    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.003    0.003    0.003    0.003 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      " 18848997    2.584    0.000    2.584    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "   480000    1.468    0.000    2.779    0.000 {method 'join' of 'str' objects}\n",
      "   160000    0.042    0.000    0.042    0.000 {method 'lower' of 'str' objects}\n",
      "   320000    0.298    0.000    0.298    0.000 {method 'split' of 'str' objects}\n",
      "   160000    0.426    0.000    0.426    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
      "        1    0.004    0.004    0.004    0.004 {pandas._libs.lib.infer_dtype}\n",
      "        3    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "        1    0.074    0.074   18.419   18.419 {pandas._libs.lib.map_infer}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "cProfile.run(\"tweet_df['tweet_text'].map(lambda s: preprocess(s, steps))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** To help us understand TF-IDF in great detail, we learn about TF-IDF in two different ways:\n",
    "\n",
    "- We first run through the steps \"manually\", so that we can see talk about implementation details. \n",
    "- We then apply TF-IDF using `sklearn` in a few lines of code, which will hide all of that detail.\n",
    "\n",
    "## Computing TF-IDF\n",
    "\n",
    "Computing the TF-IDF values manually consist of several steps:\n",
    "1. We obtain the term-document matirx. \n",
    "1. We calculate the **term-frequency (TF)** matirx, where $\\text{TF(doc, term)}$ is the term frequencies from the term document matrix divided by the total number of terms in the document. In other words, we turn the frequencies into percentages (also called relative frequencies).\n",
    "1. We trim the term-document matrix if needed. This gets rid of useless words that frequently appear across documents.\n",
    "1. We can also derive the **inverse document frequencies (IDF)** matrix:\n",
    "\n",
    "   $$\\text{IDF(term)} = \\log(\\frac{\\text{number of documents}}{\\text{number of documents with term in it} })$$\n",
    "\n",
    "   Note that TF is a function of both term and document, but the IDF is just a function of the terms.\n",
    "1. We multiply the TF with IDF values to get TF-IDF values. This results in **term frequency inverse document frequency (TF-IDF) maxtrix**. \n",
    "   \n",
    "   $$\\text{TF-IDF} = \\text{TF(term, doc)} \\cdot \\text{IDF(term)}$$\n",
    "\n",
    "To get an intuition behind what's happening, here's what the IDF function looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0, 100, num = 80)\n",
    "sns.lineplot(x = x, y = np.log(100 / (x + 1)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFs give us the relative frequency terms in the documents. We use the IDFs to then dampen the TFs for terms that appear frequently across documents by virtue of being common terms. This will make it so rarer terms get to exert more influence during the machine learning phase.\n",
    "\n",
    "Applications of TF-IDF include\n",
    "\n",
    "- Characterize writing styles\n",
    "- Comparing authors\n",
    "- Determining original authors\n",
    "- Finding plagiarism\n",
    "\n",
    "Let's now implement this for the tweet data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get the term-document matrix\n",
    "\n",
    "We first break up the words in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry: ['family', 'day', 'target', 'buying', 'som', 'silverware', 'n', 'plate', 'da', 'loft', 'gotta', 'upgrade', 'why', 'not', 'lol']\n"
     ]
    }
   ],
   "source": [
    "clean_texts = tweet_df['clean_tweet']\n",
    "docs = {}\n",
    "labels = []\n",
    "for ix, row in enumerate(clean_texts):\n",
    "    labels = tweet_data[ix][0]\n",
    "    docs[ix] = row.split(' ')\n",
    "\n",
    "print('Example entry: {}'.format(docs[np.random.choice(ix)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our corpus, keeping track of its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tweet-vocabulary has 146496 distinct words.\n"
     ]
    }
   ],
   "source": [
    "num_nonzero = 0\n",
    "vocab = set()\n",
    "\n",
    "for word_list in docs.values():\n",
    "    unique_terms = set(word_list)    # all unique terms of this tweet\n",
    "    vocab.update(unique_terms)       # set union: add unique terms of this tweet\n",
    "    num_nonzero += len(unique_terms) # add count of unique terms in this tweet\n",
    "\n",
    "doc_key_list = list(docs.keys())\n",
    "\n",
    "print('Our tweet-vocabulary has {} distinct words.'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now convert everything to a numpy array. We should keep track of how the vocab/term indices map to the matrix so that we can look them up later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['sweenyuk' 'succumbed' 'carlita' 'esco' 'raywj']\n",
      "Sorted Vocab: ['a' 'aa' 'aaa' 'aaaa' 'aaaaa' 'aaaaaa' 'aaaaaaa' 'aaaaaaaa' 'aaaaaaaaaa'\n",
      " 'aaaaaaaaaaaa' 'aaaaaaaaaaaaa' 'aaaaaaaaaaaaaa' 'aaaaaaaaaaaaaaaa'\n",
      " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa' 'aaaaaaaaaaaaaaaaaaaaaaah'\n",
      " 'aaaaaaaaaaaaaaaaaaaah' 'aaaaaaaaaaaaaaaaand' 'aaaaaaaaaaaaaaah'\n",
      " 'aaaaaaaaaaaaaaahmmmmmmmmmm' 'aaaaaaaaaaaaaah']\n"
     ]
    }
   ],
   "source": [
    "doc_key_list = np.array(doc_key_list)\n",
    "vocab = np.array(list(vocab))\n",
    "\n",
    "vocab_sorter = np.argsort(vocab)\n",
    "\n",
    "print('Vocab: {}'.format(vocab[:5]))\n",
    "print('Sorted Vocab: {}'.format(vocab[vocab_sorter[:20]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize the **term-document matrix**. This is a matrix where each row $i$ is a document and each column $j$ is a word. The entriy $(i, j)$ of the matrix shows the frequency of the word $j$ in document $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = len(doc_key_list)\n",
    "vocab_size = len(vocab)\n",
    "data = np.empty(num_nonzero, dtype = np.intc)     # all non-zero\n",
    "rows = np.empty(num_nonzero, dtype = np.intc)     # row index\n",
    "cols = np.empty(num_nonzero, dtype = np.intc)     # column index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now populate the term-document matrix: Each row $i$ is a document and each column $j$ is a word. The entriy $(i, j)$ of the matrix shows the frequency of the word $j$ in document $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing, please wait!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "# go through all documents with their terms\n",
    "print('Computing, please wait!')\n",
    "for doc_key, terms in docs.items():\n",
    "    # find indices to insert-into such that, if the corresponding elements were\n",
    "    # inserted before the indices, the order would be preserved\n",
    "    term_indices = vocab_sorter[np.searchsorted(vocab, terms, sorter = vocab_sorter)]\n",
    "\n",
    "    # count the unique terms of the document and get their vocabulary indices\n",
    "    uniq_indices, counts = np.unique(term_indices, return_counts = True)\n",
    "    n_vals = len(uniq_indices)  # number of unique terms\n",
    "    ix_end = ix + n_vals # add count to index\n",
    "\n",
    "    data[ix:ix_end] = counts                  # save the counts (term frequencies)\n",
    "    cols[ix:ix_end] = uniq_indices            # save the column index: index in \n",
    "    doc_ix = np.where(doc_key_list == doc_key)   # get the document index for the document name\n",
    "    rows[ix:ix_end] = np.repeat(doc_ix, n_vals)  # save it as repeated value\n",
    "\n",
    "    ix = ix_end  # resume with next document -> will add future data on the end\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our sorted vocabulary again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five terms alphabetically: ['a' 'aa' 'aaa' 'aaaa' 'aaaaa']\n"
     ]
    }
   ],
   "source": [
    "print('First five terms alphabetically: {}'.format(vocab[vocab_sorter[:5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we probably need to do some trimming, as the word 'aaaaa' probably doesn't occur often enough, and having 151,670 unique words may be too much.  We will address this later on. For now, let's keep the corpus we have. We now initialize a sparse matrix that will store the term-document matirx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<160000x146496 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 1957413 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_mat = coo_matrix((data, (rows, cols)), shape = (num_docs, vocab_size), dtype = np.intc)\n",
    "\n",
    "doc_term_mat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now populate the matrix with the term frequencies. We can see an example of this for the word \"python\" in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab index of python : 129414\n",
      "\n",
      "1st document index containing said word: 14592\n",
      "\n",
      "Tweet: [1, \"omg, I just found my old vid of monty python's life of brian. it's brilliant, I just can't get enough stan today\"]\n"
     ]
    }
   ],
   "source": [
    "# let's check to make sure!\n",
    "vocab_list = list(vocab)\n",
    "word_of_interest = 'python'\n",
    "vocab_interesting_ix = list(vocab).index(word_of_interest)\n",
    "print('vocab index of {} : {}'.format(word_of_interest, vocab_interesting_ix))\n",
    "# find which tweets contain word\n",
    "doc_ix_with_word = []\n",
    "for ix, row in enumerate(tweet_data): # note on this line later\n",
    "    if word_of_interest in row[1]:\n",
    "        doc_ix_with_word.append(ix)\n",
    "\n",
    "print('\\n1st document index containing said word: {}'.format(doc_ix_with_word[0]))\n",
    "print('\\nTweet: {}'.format(tweet_data[doc_ix_with_word[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the word \"python\" appears once in the first document (tweet).\n",
    "\n",
    "**Note:** The term-document matirx `doc_term_mat` is a sparse matirx. So we can't index it using row and column index. Here we don't really need to do that, but if we did we would first need to convert it into an array. We can use the `toarray` method to do that, but if the matrix is large we can easily run out of memory (that's why we're using a spares matrix in the first place!). So instead we can use the `tocrs` method shown below, which uses compression to avoid the memory problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 14592 and column 129414 of document-term matrix has entry 1\n"
     ]
    }
   ],
   "source": [
    "# document - term matrix relevant entry\n",
    "document_row = doc_ix_with_word[0]\n",
    "vocab_col = vocab_interesting_ix\n",
    "mat_entry = doc_term_mat.tocsr()[document_row, vocab_col]\n",
    "\n",
    "print('\\nRow {} and column {} of document-term matrix has entry {}'.format(document_row, vocab_col, mat_entry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Trimming the document-term matrix\n",
    "\n",
    "We saw above that we are including terms like 'aaaaa' and 'aaaa', which probably occur very few times. These terms generally occur with unstructured text fields because we allow users to input whatever they feel like and that includes typos.  But be aware that they can also be artifacts of our cleaning process (unintentionally and intentionally).\n",
    "\n",
    "Since our document-term matrix is a matrix of counts of words (columns) in each document (rows), we want to remove words that don't occur very frequently across our corpus. The count of how frequent a word is in all of our corpus is just the sum of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 5 1 ... 2 1 5]]\n"
     ]
    }
   ],
   "source": [
    "word_counts = doc_term_mat.sum(axis = 0)\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how many words are above a specific cutoff, such as 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words w/counts above 15 : 5856\n"
     ]
    }
   ],
   "source": [
    "cutoff = 15\n",
    "word_count_list = word_counts.tolist()[0]\n",
    "col_cutoff_ix = [ix for ix, count in enumerate(word_count_list) if count > cutoff]\n",
    "\n",
    "print('Number of words w/counts above {} : {}'.format(cutoff, len(col_cutoff_ix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now trim our vocabulary and document term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of document-term matrix before trimming: (160000, 146496)\n",
      "Shape of document-term matrix after trimming: (160000, 5856)\n"
     ]
    }
   ],
   "source": [
    "vocab_trimmed = np.array([vocab[x] for x in col_cutoff_ix])\n",
    "vocab_sorter_trimmed = np.argsort(vocab_trimmed)\n",
    "\n",
    "print('Shape of document-term matrix before trimming: {}'.format(doc_term_mat.shape))\n",
    "\n",
    "doc_term_mat_trimmed = doc_term_mat.tocsc()[:, col_cutoff_ix]\n",
    "print('Shape of document-term matrix after trimming: {}'.format(doc_term_mat_trimmed.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'aa', 'aaa', 'aaaah', 'aaah', 'aah', 'aaron', 'ab',\n",
       "       'abandoned', 'abby'], dtype='<U37')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first 10 words alphabetically\n",
    "vocab_trimmed[vocab_sorter_trimmed[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we know what cutoff we should use? Let's look at a bar plot words in descending frequency before and after we trimmed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = pd.value_counts(word_count_list, normalize = True)[:20]\n",
    "words = [vocab[x] for x in counts.index][:20]\n",
    "g = sns.barplot(x = words, y = counts, color = 'lightblue')\n",
    "g.set_xticklabels(rotation = 90, labels = words);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the bar plot is very skewed. There are too many words that appear few times. Let's check out the trimmed list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trimmed_word_counts = doc_term_mat_trimmed.sum(axis = 0)\n",
    "trimmed_word_list = trimmed_word_counts.tolist()[0]\n",
    "\n",
    "counts = pd.value_counts(trimmed_word_list, normalize = True)[:20]\n",
    "counts = counts.reset_index(drop = True)\n",
    "words = [vocab[x] for x in counts.index][:20]\n",
    "g = sns.barplot(x = words, y = counts, color = 'lightblue')\n",
    "g.set_xticklabels(rotation = 90, labels = words);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 15 might be a good cutoff because we get a visible drop off and around 6000 features, but these types of **hyperparameters** for the model will probably need tuning. We will learn about tuning such values in future lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compute IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Term Frequency\n",
    "\n",
    "Now that we have computed a document-term matrix, how can we understand it? Recall that the simple **Bag of Words model** is just based on **Term Frequency (TF)**. In this case, the weighting of a document for a given term is just the frequency of that term in the document. \n",
    "\n",
    "In other cases we will used the **Inverse Document Frequency (IDF)** weighting. IDF weighting accounts for cases where only a few documents contain certain terms. The formula for the IDF weighting can be written as:\n",
    "\n",
    "$$IDF = log(\\frac{Number\\ Documents}{Number\\ Documents\\ with\\ Word})$$\n",
    "\n",
    "The IDF can exhibit a problem however. When there are a few documents with very frequent terms, the weighting is skewed toward those documents.  To solve this problem, we reweight IDF by the overall frequency of the word to create a **term frequency-inverse document frequency (TF-IDF)** matrix. The formula for computing TFIDF is: \n",
    "\n",
    "$$TF - IDF = frequency(word) \\cdot log(\\frac{Number\\ Documents}{Number\\ Documents\\ with\\ Word})\\ $$\n",
    "\n",
    "The code in the cell below computes both simple TF and the cumulative of the term frequencies, starting from the most frequent terms to the least.\n",
    "\n",
    "Scikit-Learn has a built in TF-IDF transformation function that we will use to calculate this and prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_texts = tweet_df['clean_tweet']\n",
    "# Declare the TFIDF vectorizer.\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, max_features=5856, stop_words='english')\n",
    "\n",
    "# Fit the vectorizer over the dataset\n",
    "tf_idf_tweets = vectorizer.fit_transform(clean_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<160000x5856 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 873392 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit learn prefers the 'csr' format instead (Compressed Sparse Row format)\n",
    "tf_idf_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and sentiment analysis\n",
    "\n",
    "It's hard to talk about feature engineering without moving on to the next step: training a machine learning model. Although we cover this topic on a future lesson, we include here an example in case you can't wait any longer!\n",
    "\n",
    "Now that we have a prepared TDM of the 160,000 tweets, let's build and evaluate models to classify the sentiment of these tweets. The idea is simple: We use the TF-IDF features for training the model. Since our data also has a column that says if the tweet expresses a positive or negative sentiment, we will train a model to predict the sentiment from the TF-IDF features. So first let's obtain the TF-IDF features once more:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the featurized data into training and test sets. We will explain why in a future lecture. For training we will use 120,000 tweets to predict the 0,1 sentiment. The remaining 40,000 cases will be used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_targets = np.array([y[0] for y in tweet_data])\n",
    "y_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tf_idf_tweets, y_targets, test_size = 40000, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a logistic classifier on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs = lr.predict_proba(X_train)\n",
    "train_results = np.argmax(train_probs, axis=1)\n",
    "\n",
    "test_probs = lr.predict_proba(X_test)\n",
    "test_results = np.argmax(test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7793333333333333\n",
      "Test accuracy: 0.75625\n"
     ]
    }
   ],
   "source": [
    "train_logical_correct = [pred == actual for pred, actual in zip(train_results, y_train)]\n",
    "train_acc = np.mean(train_logical_correct)\n",
    "\n",
    "test_logical_correct = [pred == actual for pred, actual in zip(test_results, y_test)]\n",
    "test_acc = np.mean(test_logical_correct)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute the precision, recall and Fscore of the model for positive and negative tweets.\n",
    "\n",
    "Recall that a positive prediction here means a positive review, and so **precision** is the proportion of correct predictions among all positive predictions and **recall** is the proportion of correct predictions among all true positives. **F1** is the harmonic average of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14624  5432]\n",
      " [ 4318 15626]]\n",
      "===================================\n",
      "             Class 1   -   Class 0\n",
      "Precision: [0.77204097 0.74204578]\n",
      "Recall   : [0.72915836 0.78349378]\n",
      "F1       : [0.74998718 0.76220672]\n",
      "Support  : [20056 19944]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, support = precision_recall_fscore_support(y_test, test_results)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, test_results).ravel()\n",
    "\n",
    "print(confusion_matrix(y_test, test_results))\n",
    "print('='*35)\n",
    "print('             Class 1   -   Class 0')\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall   : {}'.format(recall))\n",
    "print('F1       : {}'.format(f1))\n",
    "print('Support  : {}'.format(support))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary\n",
    "\n",
    "NLP applications extend far and wide, so we only stratched the surface here. Many of the modern breakthroughs in deep learning for example have been in NLP. One reason for this is that language data is abundant and the lack of structure in the data presents us with many challenges and learning opportunities. We hope this notebook exposed you to just some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
